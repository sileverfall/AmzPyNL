{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time            \n",
    "import re            \n",
    "import os    \n",
    "import sys  \n",
    "import codecs  \n",
    "import shutil  \n",
    "import nltk\n",
    "import numpy as np  \n",
    "import matplotlib  \n",
    "import scipy  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn import feature_extraction    \n",
    "from sklearn.feature_extraction.text import TfidfTransformer    \n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7640"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#title\n",
    "asins = open('../CategoryCluster/C10/UK/pre/ASIN.csv').read().split('\\n')\n",
    "ASINs=[]\n",
    "for item in asins:\n",
    "    a = item.split(',')\n",
    "    ASINs += a\n",
    "# ASINs = ASINs[:-1]\n",
    "len(ASINs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7640"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#synopses\n",
    "review = open('../CategoryCluster/C10/UK/pre/review.csv').read().split('\\n')\n",
    "review[0]\n",
    "Reviews=[]\n",
    "for rev in review:\n",
    "    a = rev.split('|')\n",
    "    Reviews += a \n",
    "Reviews = Reviews[:-1]\n",
    "len(Reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7640"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ranks\n",
    "ranks = open('../CategoryCluster/C10/UK/pre/ranks.csv').read().split('\\n')\n",
    "ranks[0] = ranks[0].replace('\\ufeff','')\n",
    "Rank =[]\n",
    "for rank in ranks:\n",
    "    a = rank.split(',')\n",
    "    Rank += a\n",
    "    \n",
    "Ranks =[float(i) for i in Rank]  \n",
    "Ranks[0]\n",
    "len(Ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 载入 nltk 的英文停用词作为“stopwords”变量\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 载入 nltk 的 SnowballStemmer 作为“stemmer”变量\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 这里我定义了一个分词器（tokenizer）和词干分析器（stemmer），它们会输出给定文本词干化后的词集合\n",
    " \n",
    "def tokenize_and_stem(text):\n",
    "    # 首先分句，接着分词，而标点也会作为词例存在\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # 过滤所有不含字母的词例（例如：数字、纯标点）\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    " \n",
    "def tokenize_only(text):\n",
    "    # 首先分句，接着分词，而标点也会作为词例存在\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # 过滤所有不含字母的词例（例如：数字、纯标点）\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 非常不 pythonic，一点也不！\n",
    "# 扩充列表后变成了非常庞大的二维（flat）词汇表\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in Reviews:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #对每个评价进行分词和词干化\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) # 扩充“totalvocab_stemmed”列表\n",
    " \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf and document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.95 s, sys: 94.5 ms, total: 7.05 s\n",
      "Wall time: 7.27 s\n",
      "CPU times: user 2.08 ms, sys: 357 µs, total: 2.44 ms\n",
      "Wall time: 2.3 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    " \n",
    "# 定义向量化参数\n",
    "#将文本中的词语转换为词频矩阵 矩阵元素a[i][j] 表示j词在第i类评论下的词频  \n",
    "vectorizer = CountVectorizer(max_df=0.98, max_features=200000,\n",
    "                                 min_df=0.02, stop_words='english',\n",
    "                                 tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "#该类会统计每个词语的tf-idf权值  \n",
    "transformer = TfidfTransformer() \n",
    "\n",
    "#第一个fit_transform是计算tf-idf 第二个fit_transform是将文本转为词频矩阵  \n",
    "%time tf =  vectorizer.fit_transform(Reviews)\n",
    "%time tfidf = transformer.fit_transform(tf) # 向量化\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'s\", 'absolut', 'ador', 'amaz', 'ani', 'arriv', 'babi', 'big', 'birthday', 'bit']\n"
     ]
    }
   ],
   "source": [
    "#获取词袋模型中的前10个词语 \n",
    "word = vectorizer.get_feature_names()\n",
    "print(word[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词袋模型中共有几个词语\n",
    "len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.27828497,  0.29361554],\n",
       "       ..., \n",
       "       [ 0.31325465,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.60004637,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将tf-idf矩阵抽取出来，元素w[i][j]表示j词在第i类评论中的tf-idf权重  \n",
    "weight = tfidf.toarray()  \n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7640, 105)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#词频矩阵\n",
    "tfidframe = pd.DataFrame(np.round(weight, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3     4     5    6    7    8    9    ...   95    96   97   \\\n",
       "0  0.0  0.0  0.0  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...   0.0  0.00  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...   0.0  0.30  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...   0.0  0.22  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...   0.0  0.00  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.53  0.00  0.0  0.0  0.0  0.0  ...   0.0  0.34  0.0   \n",
       "5  0.0  0.0  0.0  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...   0.0  0.00  0.0   \n",
       "6  0.0  0.0  0.0  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...   0.0  0.00  0.0   \n",
       "7  0.0  0.0  0.0  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...   0.0  0.00  0.0   \n",
       "8  0.0  0.0  0.0  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...   0.0  0.00  0.0   \n",
       "9  0.0  0.0  0.0  0.0  0.00  0.55  0.0  0.0  0.0  0.0  ...   0.0  0.00  0.0   \n",
       "\n",
       "    98   99    100  101  102   103   104  \n",
       "0  0.00  0.0  0.00  0.0  0.0  0.00  0.00  \n",
       "1  0.00  0.0  0.00  0.0  0.0  0.00  0.00  \n",
       "2  0.00  0.0  0.00  0.0  0.0  0.28  0.29  \n",
       "3  0.00  0.0  0.00  0.0  0.0  0.00  0.00  \n",
       "4  0.00  0.0  0.00  0.0  0.0  0.00  0.00  \n",
       "5  0.00  0.0  0.00  0.0  0.0  0.00  0.00  \n",
       "6  0.35  0.0  0.00  0.0  0.0  0.00  0.00  \n",
       "7  0.00  0.0  0.00  0.0  0.0  0.00  0.00  \n",
       "8  0.26  0.0  0.46  0.0  0.0  0.00  0.00  \n",
       "9  0.00  0.0  0.00  0.0  0.0  0.00  0.00  \n",
       "\n",
       "[10 rows x 105 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidframe[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(tfidf)\n",
    "dist = 1 - similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.22044605e-16   1.00000000e+00   6.84754295e-01 ...,   8.32061968e-01\n",
      "    9.48478351e-01   8.45575011e-01]\n",
      " [  1.00000000e+00   0.00000000e+00   9.33648233e-01 ...,   8.56515977e-01\n",
      "    8.61784014e-01   6.89722658e-01]\n",
      " [  6.84754295e-01   9.33648233e-01  -2.22044605e-16 ...,   8.11144872e-01\n",
      "    8.03198079e-01   8.33989995e-01]\n",
      " ..., \n",
      " [  8.32061968e-01   8.56515977e-01   8.11144872e-01 ...,   0.00000000e+00\n",
      "    2.51704483e-01   5.18331101e-01]\n",
      " [  9.48478351e-01   8.61784014e-01   8.03198079e-01 ...,   2.51704483e-01\n",
      "   -2.22044605e-16   5.64963330e-01]\n",
      " [  8.45575011e-01   6.89722658e-01   8.33989995e-01 ...,   5.18331101e-01\n",
      "    5.64963330e-01  -2.22044605e-16]]\n"
     ]
    }
   ],
   "source": [
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7630</th>\n",
       "      <th>7631</th>\n",
       "      <th>7632</th>\n",
       "      <th>7633</th>\n",
       "      <th>7634</th>\n",
       "      <th>7635</th>\n",
       "      <th>7636</th>\n",
       "      <th>7637</th>\n",
       "      <th>7638</th>\n",
       "      <th>7639</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315246</td>\n",
       "      <td>0.252964</td>\n",
       "      <td>0.148946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086754</td>\n",
       "      <td>0.274034</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204332</td>\n",
       "      <td>0.039199</td>\n",
       "      <td>0.020965</td>\n",
       "      <td>0.122771</td>\n",
       "      <td>0.032713</td>\n",
       "      <td>0.149790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167938</td>\n",
       "      <td>0.051522</td>\n",
       "      <td>0.154425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102843</td>\n",
       "      <td>0.256754</td>\n",
       "      <td>0.102597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.373741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>0.106872</td>\n",
       "      <td>0.146901</td>\n",
       "      <td>0.245437</td>\n",
       "      <td>0.172469</td>\n",
       "      <td>0.183057</td>\n",
       "      <td>0.146491</td>\n",
       "      <td>0.143484</td>\n",
       "      <td>0.138216</td>\n",
       "      <td>0.310277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.315246</td>\n",
       "      <td>0.066352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.092127</td>\n",
       "      <td>0.188785</td>\n",
       "      <td>0.076113</td>\n",
       "      <td>0.297893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.07035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267288</td>\n",
       "      <td>0.293487</td>\n",
       "      <td>0.143060</td>\n",
       "      <td>0.231424</td>\n",
       "      <td>0.167167</td>\n",
       "      <td>0.291850</td>\n",
       "      <td>0.150084</td>\n",
       "      <td>0.188855</td>\n",
       "      <td>0.196802</td>\n",
       "      <td>0.166010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.252964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131486</td>\n",
       "      <td>0.058049</td>\n",
       "      <td>0.573697</td>\n",
       "      <td>0.12153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033317</td>\n",
       "      <td>0.026229</td>\n",
       "      <td>0.053710</td>\n",
       "      <td>0.097904</td>\n",
       "      <td>0.145723</td>\n",
       "      <td>0.057299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044912</td>\n",
       "      <td>0.025542</td>\n",
       "      <td>0.083645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.148946</td>\n",
       "      <td>0.102843</td>\n",
       "      <td>0.188785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399614</td>\n",
       "      <td>0.118227</td>\n",
       "      <td>0.174922</td>\n",
       "      <td>0.115261</td>\n",
       "      <td>0.235134</td>\n",
       "      <td>0.129138</td>\n",
       "      <td>0.224838</td>\n",
       "      <td>0.101221</td>\n",
       "      <td>0.130348</td>\n",
       "      <td>0.341532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256754</td>\n",
       "      <td>0.076113</td>\n",
       "      <td>0.131486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.23915</td>\n",
       "      <td>0.190354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070051</td>\n",
       "      <td>0.387503</td>\n",
       "      <td>0.146827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136907</td>\n",
       "      <td>0.180424</td>\n",
       "      <td>0.050551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.086754</td>\n",
       "      <td>0.102597</td>\n",
       "      <td>0.297893</td>\n",
       "      <td>0.058049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062884</td>\n",
       "      <td>0.09271</td>\n",
       "      <td>0.359971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164326</td>\n",
       "      <td>0.027062</td>\n",
       "      <td>0.099191</td>\n",
       "      <td>0.123317</td>\n",
       "      <td>0.071798</td>\n",
       "      <td>0.059118</td>\n",
       "      <td>0.090135</td>\n",
       "      <td>0.046338</td>\n",
       "      <td>0.164624</td>\n",
       "      <td>0.144016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.274034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062884</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191307</td>\n",
       "      <td>0.015197</td>\n",
       "      <td>0.027701</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.062072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048653</td>\n",
       "      <td>0.062668</td>\n",
       "      <td>0.208787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070350</td>\n",
       "      <td>0.121530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239150</td>\n",
       "      <td>0.092710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030301</td>\n",
       "      <td>0.138348</td>\n",
       "      <td>0.094562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058532</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190354</td>\n",
       "      <td>0.359971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045953</td>\n",
       "      <td>0.117998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 7640 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  1.000000  0.000000  0.315246  0.252964  0.148946  0.000000  0.086754   \n",
       "1  0.000000  1.000000  0.066352  0.000000  0.102843  0.256754  0.102597   \n",
       "2  0.315246  0.066352  1.000000  0.092127  0.188785  0.076113  0.297893   \n",
       "3  0.252964  0.000000  0.092127  1.000000  0.000000  0.131486  0.058049   \n",
       "4  0.148946  0.102843  0.188785  0.000000  1.000000  0.000000  0.000000   \n",
       "5  0.000000  0.256754  0.076113  0.131486  0.000000  1.000000  0.000000   \n",
       "6  0.086754  0.102597  0.297893  0.058049  0.000000  0.000000  1.000000   \n",
       "7  0.274034  0.000000  0.000000  0.573697  0.000000  0.000000  0.062884   \n",
       "8  0.000000  0.000000  0.070350  0.121530  0.000000  0.239150  0.092710   \n",
       "9  0.000000  0.373741  0.000000  0.000000  0.000000  0.190354  0.359971   \n",
       "\n",
       "       7        8         9       ...         7630      7631      7632  \\\n",
       "0  0.274034  0.00000  0.000000    ...     0.204332  0.039199  0.020965   \n",
       "1  0.000000  0.00000  0.373741    ...     0.167969  0.106872  0.146901   \n",
       "2  0.000000  0.07035  0.000000    ...     0.267288  0.293487  0.143060   \n",
       "3  0.573697  0.12153  0.000000    ...     0.033317  0.026229  0.053710   \n",
       "4  0.000000  0.00000  0.000000    ...     0.399614  0.118227  0.174922   \n",
       "5  0.000000  0.23915  0.190354    ...     0.027526  0.000000  0.070051   \n",
       "6  0.062884  0.09271  0.359971    ...     0.164326  0.027062  0.099191   \n",
       "7  1.000000  0.00000  0.000000    ...     0.000000  0.191307  0.015197   \n",
       "8  0.000000  1.00000  0.000000    ...     0.188630  0.000000  0.030301   \n",
       "9  0.000000  0.00000  1.000000    ...     0.073039  0.000000  0.000000   \n",
       "\n",
       "       7633      7634      7635      7636      7637      7638      7639  \n",
       "0  0.122771  0.032713  0.149790  0.000000  0.167938  0.051522  0.154425  \n",
       "1  0.245437  0.172469  0.183057  0.146491  0.143484  0.138216  0.310277  \n",
       "2  0.231424  0.167167  0.291850  0.150084  0.188855  0.196802  0.166010  \n",
       "3  0.097904  0.145723  0.057299  0.000000  0.044912  0.025542  0.083645  \n",
       "4  0.115261  0.235134  0.129138  0.224838  0.101221  0.130348  0.341532  \n",
       "5  0.387503  0.146827  0.000000  0.000000  0.136907  0.180424  0.050551  \n",
       "6  0.123317  0.071798  0.059118  0.090135  0.046338  0.164624  0.144016  \n",
       "7  0.027701  0.023712  0.062072  0.000000  0.048653  0.062668  0.208787  \n",
       "8  0.138348  0.094562  0.000000  0.000000  0.000000  0.058532  0.000000  \n",
       "9  0.104718  0.000000  0.000000  0.000000  0.000000  0.045953  0.117998  \n",
       "\n",
       "[10 rows x 7640 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df = pd.DataFrame(similarity)\n",
    "similarity_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 67.8 ms, total: 1.08 s\n",
      "Wall time: 990 ms\n",
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=10, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans  \n",
    "num_clusters = 10\n",
    "km = KMeans(n_clusters=10)   \n",
    "%time s = km.fit(weight)  \n",
    "clusters = km.labels_.tolist()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "# 注释语句用来存储你的模型\n",
    "# 因为我已经从 pickle 载入过模型了\n",
    " \n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    " \n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toys = { 'title': ASINs, 'rank': Ranks, 'review': Reviews, 'cluster': clusters}\n",
    " \n",
    "frame = pd.DataFrame(toys , index = [clusters] , columns = ['rank', 'title', 'cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# frame[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frame['cluster'].value_counts() #number of review per cluster (clusters from 0 to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# km.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grouped = frame['rank'].groupby(frame['cluster']) # 为了凝聚（aggregation），由聚类分类。\n",
    " \n",
    "# grouped.mean() # 每个聚类的平均排名（0 到 5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    " \n",
    "# print(\"Top terms per cluster:\")\n",
    "# print()\n",
    "# # 按离质心的距离排列聚类中心，由近到远\n",
    "# order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    " \n",
    "# for i in range(num_clusters):\n",
    "#     print(\"Cluster %d titles:\" % i, end='')\n",
    "#     for title in frame.ix[i]['title'].values.tolist():\n",
    "#         print(' %s,' % title, end='')\n",
    "#     print() # 空行\n",
    "#     print() # 空行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    " \n",
    "# print(\"Top terms per cluster:\")\n",
    "# print()\n",
    "# # 按离质心的距离排列聚类中心，由近到远\n",
    "# order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "# # print(order_centroids)\n",
    "# for i in range(num_clusters):\n",
    "#     print(\"Cluster %d:\" % i, end='')\n",
    "#     time.sleep(1)\n",
    "#     for ind in order_centroids[i, :50]: # 每个聚类选 10 个词\n",
    "#         print(' %s' % word[ind]  , end=',')\n",
    "#     print() # 空行\n",
    "#     print() # 空行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_topics = 10\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=50,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.4 s, sys: 595 ms, total: 55 s\n",
      "Wall time: 57.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=50, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=1, n_topics=10, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lda.fit(tf) #tf 为向量化后的语料词集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 s, sys: 232 ms, total: 52.2 s\n",
      "Wall time: 53.1 s\n"
     ]
    }
   ],
   "source": [
    "%time lda_matrix = lda.fit_transform(tf) #tf 为向量化后的语料词集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01111374,  0.22230756,  0.0111145 , ...,  0.0111127 ,\n",
       "         0.48173756,  0.21816941],\n",
       "       [ 0.01428817,  0.01428854,  0.18991668, ...,  0.01428601,\n",
       "         0.21199854,  0.014294  ],\n",
       "       [ 0.00714289,  0.47154482,  0.0071437 , ...,  0.25746871,\n",
       "         0.00714367,  0.13417729],\n",
       "       ..., \n",
       "       [ 0.005264  ,  0.67213262,  0.00526354, ...,  0.00526483,\n",
       "         0.00526423,  0.00526316],\n",
       "       [ 0.00075194,  0.41997452,  0.00075201, ...,  0.00075202,\n",
       "         0.02148779,  0.00075209],\n",
       "       [ 0.00526316,  0.40907557,  0.00526454, ...,  0.00526362,\n",
       "         0.37408554,  0.00526595]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_matrix #表示每一個文檔屬於每一個聚類的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(lda_matrix, columns=['T1', 'T2', 'T3','T4','T5','T6','T7','T8','T9','T10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011114</td>\n",
       "      <td>0.222308</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.011113</td>\n",
       "      <td>0.481738</td>\n",
       "      <td>0.218169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.189917</td>\n",
       "      <td>0.498070</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.211999</td>\n",
       "      <td>0.014294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.471545</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>0.093949</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.257469</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>0.134177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016670</td>\n",
       "      <td>0.016669</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.349995</td>\n",
       "      <td>0.016668</td>\n",
       "      <td>0.016669</td>\n",
       "      <td>0.516661</td>\n",
       "      <td>0.016668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016668</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.235550</td>\n",
       "      <td>0.212015</td>\n",
       "      <td>0.016670</td>\n",
       "      <td>0.231816</td>\n",
       "      <td>0.220603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         T1        T2        T3        T4        T5        T6        T7  \\\n",
       "0  0.011114  0.222308  0.011115  0.011111  0.011111  0.011111  0.011111   \n",
       "1  0.014288  0.014289  0.189917  0.498070  0.014287  0.014286  0.014286   \n",
       "2  0.007143  0.471545  0.007144  0.093949  0.007144  0.007143  0.007143   \n",
       "3  0.016670  0.016669  0.016667  0.016667  0.016667  0.349995  0.016668   \n",
       "4  0.016668  0.016671  0.016667  0.016667  0.016673  0.235550  0.212015   \n",
       "\n",
       "         T8        T9       T10  \n",
       "0  0.011113  0.481738  0.218169  \n",
       "1  0.014286  0.211999  0.014294  \n",
       "2  0.257469  0.007144  0.134177  \n",
       "3  0.016669  0.516661  0.016668  \n",
       "4  0.016670  0.231816  0.220603  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 278 ms, sys: 15.4 ms, total: 293 ms\n",
      "Wall time: 308 ms\n"
     ]
    }
   ],
   "source": [
    "%time km_lda =km.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_labels = km.labels_\n",
    "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rank</th>\n",
       "      <th>review</th>\n",
       "      <th>ClusterLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000284ZNI_1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Our Granddaughter who is 14 months loves it , ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000284ZNI_2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Toy itself looks ok, but as mentioned by many ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000284ZNI_3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I had this toy for my two little ones and have...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000284ZNI_4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bought for Xmas present for my granddaughter s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000284ZNI_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Briliant child/infant toy.  Its squashy and ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          title  rank                                             review  \\\n",
       "0  B000284ZNI_1   5.0  Our Granddaughter who is 14 months loves it , ...   \n",
       "1  B000284ZNI_2   3.0  Toy itself looks ok, but as mentioned by many ...   \n",
       "2  B000284ZNI_3   5.0  I had this toy for my two little ones and have...   \n",
       "3  B000284ZNI_4   5.0  Bought for Xmas present for my granddaughter s...   \n",
       "4  B000284ZNI_5   5.0  Briliant child/infant toy.  Its squashy and ha...   \n",
       "\n",
       "   ClusterLabel  \n",
       "0             0  \n",
       "1             8  \n",
       "2             2  \n",
       "3             0  \n",
       "4             1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaframe = pd.DataFrame({ 'title': ASINs, 'rank': Ranks, 'review': Reviews})\n",
    "ldaframe = ldaframe[['title','rank','review']]\n",
    "ldaClusterframe = pd.concat([ldaframe, cluster_labels], axis=1)\n",
    "ldaClusterframe[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1285\n",
       "2     822\n",
       "6     818\n",
       "5     815\n",
       "0     801\n",
       "8     776\n",
       "9     652\n",
       "3     605\n",
       "4     605\n",
       "7     461\n",
       "Name: ClusterLabel, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaClusterframe['ClusterLabel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClusterLabel\n",
       "0    4.672909\n",
       "1    2.617899\n",
       "2    4.575426\n",
       "3    4.089256\n",
       "4    4.732231\n",
       "5    4.387730\n",
       "6    4.298289\n",
       "7    4.555315\n",
       "8    3.675258\n",
       "9    4.656442\n",
       "Name: rank, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rankgrouped = ldaClusterframe['rank'].groupby(ldaClusterframe['ClusterLabel']) # 为了凝聚（aggregation），由聚类分类。\n",
    " \n",
    "Rankgrouped.mean() # 每个聚类的平均排名（0 到 5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7640.000000\n",
       "mean        4.094895\n",
       "std         1.517373\n",
       "min         0.000000\n",
       "25%         4.000000\n",
       "50%         5.000000\n",
       "75%         5.000000\n",
       "max         5.000000\n",
       "Name: rank, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaClusterframe['rank'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rank</th>\n",
       "      <th>review</th>\n",
       "      <th>ClusterLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000284ZNI_1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Our Granddaughter who is 14 months loves it , ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>B01MFCMO1M_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My granddaughter loves this doll. Trolls is he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4950</th>\n",
       "      <td>B018S366RQ_1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My niece absolutely loves Teletubbies so she a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>B018S366RQ_9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Classic toy and my Grandaught loves it.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>B00RY3C6MQ_2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This was purchased as a gift.  They are a litt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>B071CV6KWH_3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>My granddaughter loves it but it has already s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>B074J57L4L_1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My granddaughter loves this toy.  It is big an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>B000WNZ1SQ_2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>good soft stuffing perfect for toy knitting</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>B00XSPEW9O_8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>my son loves him</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>B00XSPEW9O_7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Granddaughter loves it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title  rank                                             review  \\\n",
       "0     B000284ZNI_1   5.0  Our Granddaughter who is 14 months loves it , ...   \n",
       "1374  B01MFCMO1M_5   5.0  My granddaughter loves this doll. Trolls is he...   \n",
       "4950  B018S366RQ_1   5.0  My niece absolutely loves Teletubbies so she a...   \n",
       "4958  B018S366RQ_9   5.0            Classic toy and my Grandaught loves it.   \n",
       "1351  B00RY3C6MQ_2   4.0  This was purchased as a gift.  They are a litt...   \n",
       "4982  B071CV6KWH_3   2.0  My granddaughter loves it but it has already s...   \n",
       "5010  B074J57L4L_1   5.0  My granddaughter loves this toy.  It is big an...   \n",
       "5021  B000WNZ1SQ_2   4.0        good soft stuffing perfect for toy knitting   \n",
       "1337  B00XSPEW9O_8   5.0                                   my son loves him   \n",
       "1336  B00XSPEW9O_7   5.0                             Granddaughter loves it   \n",
       "\n",
       "      ClusterLabel  \n",
       "0                0  \n",
       "1374             0  \n",
       "4950             0  \n",
       "4958             0  \n",
       "1351             0  \n",
       "4982             0  \n",
       "5010             0  \n",
       "5021             0  \n",
       "1337             0  \n",
       "1336             0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#排序\n",
    "ldaClusterframe.sort_values(by = 'ClusterLabel')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love, daughter, daughter love, deliveri, look, children, packag, teddi, s, play, bit, t, excel, littl, ani, bought, product, use, item, arriv, came, say, friend, thing, nice, think, birthday, day, buy, absolut,\n",
      "\n",
      " love, littl, toy, babi, kid, great, girl, play, month, absolut, bought, sound, make, colour, use, old, think, ador, buy, s, fun, recommend, like, realli, product, onli, quit, price, gift, lot,\n",
      "\n",
      " squishi, smell, realli, rise, nice, slow, came, slow rise, veri, super, like, recommend, soft, amaz, packag, definit, good, fun, bit, expect, day, 's, price, colour, size, bought, play, come, great, love,\n",
      "\n",
      " like, just, n't, doe, look, time, arriv, realli, onli, pictur, doe n't, 's, good, t, thing, say, s, money, got, play, want, come, bit, order, sound, expect, item, disappoint, use, worth,\n",
      "\n",
      " 's, cute, veri, littl, small, friend, soft, veri cute, size, bit, look, come, big, say, ani, like, perfect, teddi, just, birthday, want, quit, love, child, got, son, niec, think, nice, make,\n",
      "\n",
      " christma, n't, present, day, bought, did, perfect, disappoint, want, children, got, daughter, birthday, ani, purchas, big, come, absolut, came, expect, deliveri, quit, t, price, gift, packag, think, niec, look, veri,\n",
      "\n",
      " great, happi, veri, product, gift, thank, veri happi, bought, buy, niec, deliveri, purchas, absolut, son, ador, present, teddi, love, packag, recommend, arriv, expect, price, realli, want, look, ani, friend, definit, excel,\n",
      "\n",
      " love, old, year, year old, grandson, expect, thought, smaller, lot, bought, cute, purchas, thing, time, realli, price, colour, think, make, super, good, ador, arriv, recommend, niec, small, say, son, littl, size,\n",
      "\n",
      " love, toy, granddaught, soft, granddaught love, cudd, littl, son, worth, money, child, nice, good, buy, colour, look, definit, purchas, veri, order, recommend, niec, big, children, amaz, pictur, item, price, lot, expect,\n",
      "\n",
      " good, qualiti, veri, price, size, good qualiti, quick, excel, pleas, arriv, item, deliveri, bought, good size, nice, realli, son, small, s, gift, quit, expect, packag, order, purchas, niec, love, birthday, thought, recommend,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    " \n",
    "order_centroids =  lda.components_.argsort()[:, ::-1] \n",
    "# print(order_centroids)\n",
    "\n",
    "for i in range(num_clusters):\n",
    "#     print(\"Cluster %d:\" % i, end='\\n')\n",
    "    time.sleep(1)\n",
    "    for ind in order_centroids[i, :30]: # 每个聚类选 30 个词\n",
    "        print(' %s' % word[ind], end=',')\n",
    "        \n",
    "        \n",
    "    print() # 空行\n",
    "    print() # 空行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 51,  20,  21, ...,  82,  27,  39],\n",
       "       [ 51,  48,  96, ...,  91,  75,  80],\n",
       "       [ 87,  83,  73, ...,  99,   6,  40],\n",
       "       ..., \n",
       "       [ 51,  58, 103, ..., 100,  75,  80],\n",
       "       [ 51,  96,  39, ...,  79,  80,  75],\n",
       "       [ 35,  70,  98, ...,  28,  75,  80]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ftf = transformer.fit_transform(order_centroids)\n",
    "ftf = ftf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2     3     4     5     6     7     8     9    ...    95   \\\n",
       "0  0.09  0.03  0.03  0.04  0.08  0.02  0.10  0.14  0.12  0.10  ...   0.17   \n",
       "1  0.09  0.08  0.15  0.01  0.07  0.07  0.05  0.10  0.09  0.00  ...   0.14   \n",
       "2  0.15  0.13  0.12  0.12  0.09  0.13  0.02  0.13  0.16  0.14  ...   0.14   \n",
       "3  0.08  0.07  0.09  0.04  0.08  0.15  0.01  0.12  0.10  0.10  ...   0.05   \n",
       "4  0.00  0.03  0.16  0.08  0.13  0.05  0.13  0.16  0.13  0.01  ...   0.17   \n",
       "\n",
       "    96    97    98    99    100   101   102   103   104  \n",
       "0  0.17  0.13  0.07  0.06  0.05  0.12  0.13  0.04  0.06  \n",
       "1  0.16  0.13  0.17  0.16  0.03  0.06  0.15  0.12  0.13  \n",
       "2  0.17  0.14  0.06  0.03  0.06  0.17  0.16  0.01  0.06  \n",
       "3  0.17  0.12  0.13  0.13  0.03  0.16  0.16  0.17  0.06  \n",
       "4  0.07  0.17  0.03  0.15  0.16  0.13  0.13  0.12  0.06  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#词频矩阵\n",
    "tfidMMframe = pd.DataFrame(np.round(ftf, 2))\n",
    "tfidMMframe[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " love, 0.100013, 0.000000, 1.000000, 0.000000\n",
      " daughter, 0.100008, 0.020000, 1.000000, 0.020000\n",
      " daughter love, 1123.789727, 0.140000, 0.720000, 0.194444\n",
      " deliveri, 0.100005, 0.090000, 0.910000, 0.098901\n",
      " look, 11.443411, 0.120000, 0.880000, 0.136364\n",
      " children, 0.100009, 0.010000, 0.920000, 0.010870\n",
      " packag, 0.100016, 0.020000, 1.000000, 0.020000\n",
      " teddi, 14.635696, 0.100000, 1.000000, 0.100000\n",
      " s, 0.100002, 0.050000, 1.000000, 0.050000\n",
      " play, 0.100003, 0.020000, 1.000000, 0.020000\n",
      " bit, 0.100018, 0.100000, 1.000000, 0.100000\n",
      " t, 0.100004, 0.090000, 0.850000, 0.105882\n",
      " excel, 0.100003, 0.000000, 1.000000, 0.000000\n",
      " littl, 0.100014, 0.060000, 1.000000, 0.060000\n",
      " ani, 0.100004, 0.080000, 0.690000, 0.115942\n",
      " bought, 22.526277, 0.010000, 1.000000, 0.010000\n",
      " product, 0.100009, 0.140000, 1.000000, 0.140000\n",
      " use, 0.100012, 0.130000, 0.780000, 0.166667\n",
      " item, 0.100009, 0.150000, 1.000000, 0.150000\n",
      " arriv, 9.964675, 0.020000, 0.890000, 0.022472\n",
      " came, 0.100017, 0.050000, 1.000000, 0.050000\n",
      " say, 27.531393, 0.040000, 0.840000, 0.047619\n",
      " friend, 0.100009, 0.160000, 0.920000, 0.173913\n",
      " thing, 0.100006, 0.040000, 1.000000, 0.040000\n",
      " nice, 0.100009, 0.050000, 1.000000, 0.050000\n",
      " think, 0.100023, 0.160000, 0.950000, 0.168421\n",
      " birthday, 0.100010, 0.120000, 0.800000, 0.150000\n",
      " day, 557.466932, 0.050000, 1.000000, 0.050000\n",
      " buy, 5.326320, 0.160000, 0.910000, 0.175824\n",
      " absolut, 0.100014, 0.030000, 1.000000, 0.030000\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      " love, 50.713701, 0.130000, 1.000000, 0.130000\n",
      " littl, 88.906398, 0.030000, 1.000000, 0.030000\n",
      " toy, 0.100034, 0.160000, 1.000000, 0.160000\n",
      " babi, 0.100009, 0.050000, 0.910000, 0.054945\n",
      " kid, 0.100015, 0.000000, 1.000000, 0.000000\n",
      " great, 0.100006, 0.150000, 1.000000, 0.150000\n",
      " girl, 51.393311, 0.010000, 0.830000, 0.012048\n",
      " play, 0.100008, 0.130000, 1.000000, 0.130000\n",
      " month, 0.100008, 0.120000, 1.000000, 0.120000\n",
      " absolut, 0.100027, 0.080000, 1.000000, 0.080000\n",
      " bought, 0.100013, 0.020000, 1.000000, 0.020000\n",
      " sound, 42.481528, 0.060000, 0.800000, 0.075000\n",
      " make, 738.407684, 0.060000, 0.920000, 0.065217\n",
      " colour, 0.100011, 0.150000, 0.730000, 0.205479\n",
      " use, 629.883562, 0.130000, 0.780000, 0.166667\n",
      " old, 0.100023, 0.050000, 0.880000, 0.056818\n",
      " think, 0.100030, 0.110000, 0.950000, 0.115789\n",
      " ador, 167.049865, 0.150000, 1.000000, 0.150000\n",
      " buy, 162.357865, 0.150000, 0.910000, 0.164835\n",
      " s, 0.100001, 0.040000, 1.000000, 0.040000\n",
      " fun, 0.100042, 0.070000, 1.000000, 0.070000\n",
      " recommend, 82.180355, 0.110000, 1.000000, 0.110000\n",
      " like, 264.854973, 0.010000, 1.000000, 0.010000\n",
      " realli, 63.093653, 0.140000, 1.000000, 0.140000\n",
      " product, 61.139856, 0.050000, 1.000000, 0.050000\n",
      " onli, 138.022105, 0.070000, 1.000000, 0.070000\n",
      " quit, 0.100005, 0.120000, 0.820000, 0.146341\n",
      " price, 0.100011, 0.160000, 0.810000, 0.197531\n",
      " gift, 104.371657, 0.090000, 1.000000, 0.090000\n",
      " lot, 0.100014, 0.110000, 0.770000, 0.142857\n",
      "\n",
      "\n",
      "Cluster 2:\n",
      " squishi, 0.100001, 0.070000, 1.000000, 0.070000\n",
      " smell, 12.218047, 0.010000, 1.000000, 0.010000\n",
      " realli, 0.100023, 0.110000, 1.000000, 0.110000\n",
      " rise, 220.421174, 0.040000, 0.620000, 0.064516\n",
      " nice, 0.100019, 0.030000, 1.000000, 0.030000\n",
      " slow, 42.562258, 0.090000, 0.590000, 0.152542\n",
      " came, 0.100040, 0.140000, 1.000000, 0.140000\n",
      " slow rise, 325.972111, 0.140000, 0.550000, 0.254545\n",
      " veri, 0.100012, 0.060000, 1.000000, 0.060000\n",
      " super, 564.857468, 0.110000, 1.000000, 0.110000\n",
      " like, 0.100010, 0.090000, 1.000000, 0.090000\n",
      " recommend, 350.802741, 0.090000, 1.000000, 0.090000\n",
      " soft, 530.180254, 0.000000, 0.860000, 0.000000\n",
      " amaz, 0.100005, 0.120000, 0.870000, 0.137931\n",
      " packag, 12.592474, 0.100000, 1.000000, 0.100000\n",
      " definit, 57.970445, 0.030000, 0.620000, 0.048387\n",
      " good, 0.100005, 0.040000, 1.000000, 0.040000\n",
      " fun, 0.100003, 0.100000, 1.000000, 0.100000\n",
      " bit, 0.100005, 0.140000, 1.000000, 0.140000\n",
      " expect, 0.100006, 0.160000, 1.000000, 0.160000\n",
      " day, 0.100003, 0.110000, 1.000000, 0.110000\n",
      " 's, 0.100001, 0.150000, 1.000000, 0.150000\n",
      " price, 0.100004, 0.150000, 0.810000, 0.185185\n",
      " colour, 0.100003, 0.060000, 0.730000, 0.082192\n",
      " size, 0.100021, 0.050000, 0.750000, 0.066667\n",
      " bought, 69.303937, 0.080000, 1.000000, 0.080000\n",
      " play, 0.100022, 0.070000, 1.000000, 0.070000\n",
      " come, 45.881638, 0.050000, 1.000000, 0.050000\n",
      " great, 0.100004, 0.030000, 1.000000, 0.030000\n",
      " love, 0.100047, 0.070000, 1.000000, 0.070000\n",
      "\n",
      "\n",
      "Cluster 3:\n",
      " like, 0.100009, 0.050000, 1.000000, 0.050000\n",
      " just, 43.863392, 0.140000, 1.000000, 0.140000\n",
      " n't, 0.100016, 0.020000, 1.000000, 0.020000\n",
      " doe, 43.183149, 0.040000, 1.000000, 0.040000\n",
      " look, 0.100014, 0.130000, 0.880000, 0.147727\n",
      " time, 0.100009, 0.050000, 0.820000, 0.060976\n",
      " arriv, 0.100016, 0.150000, 0.890000, 0.168539\n",
      " realli, 0.100023, 0.110000, 1.000000, 0.110000\n",
      " onli, 0.100014, 0.040000, 1.000000, 0.040000\n",
      " pictur, 0.100017, 0.140000, 0.730000, 0.191781\n",
      " doe n't, 367.017907, 0.160000, 0.660000, 0.242424\n",
      " 's, 0.100002, 0.080000, 1.000000, 0.080000\n",
      " good, 0.100013, 0.080000, 1.000000, 0.080000\n",
      " t, 0.100008, 0.010000, 0.850000, 0.011765\n",
      " thing, 0.100007, 0.060000, 1.000000, 0.060000\n",
      " say, 104.030872, 0.070000, 0.840000, 0.083333\n",
      " s, 0.100005, 0.110000, 1.000000, 0.110000\n",
      " money, 0.100018, 0.080000, 0.850000, 0.094118\n",
      " got, 0.100006, 0.040000, 0.830000, 0.048193\n",
      " play, 199.404502, 0.070000, 1.000000, 0.070000\n",
      " want, 0.100002, 0.160000, 0.760000, 0.210526\n",
      " come, 0.100029, 0.090000, 1.000000, 0.090000\n",
      " bit, 0.100007, 0.100000, 1.000000, 0.100000\n",
      " order, 231.866534, 0.010000, 0.930000, 0.010753\n",
      " sound, 0.100020, 0.150000, 0.800000, 0.187500\n",
      " expect, 0.100005, 0.020000, 1.000000, 0.020000\n",
      " item, 0.100014, 0.160000, 1.000000, 0.160000\n",
      " disappoint, 0.100016, 0.070000, 0.930000, 0.075269\n",
      " use, 0.100021, 0.120000, 0.780000, 0.153846\n",
      " worth, 83.451774, 0.160000, 0.730000, 0.219178\n",
      "\n",
      "\n",
      "Cluster 4:\n",
      " 's, 0.100004, 0.000000, 1.000000, 0.000000\n",
      " cute, 0.100036, 0.010000, 1.000000, 0.010000\n",
      " veri, 0.382303, 0.030000, 1.000000, 0.030000\n",
      " littl, 128.539883, 0.100000, 1.000000, 0.100000\n",
      " small, 0.100002, 0.160000, 1.000000, 0.160000\n",
      " friend, 0.100024, 0.080000, 0.920000, 0.086957\n",
      " soft, 0.100007, 0.110000, 0.860000, 0.127907\n",
      " veri cute, 414.124530, 0.150000, 0.740000, 0.202703\n",
      " size, 145.741526, 0.140000, 0.750000, 0.186667\n",
      " bit, 106.103739, 0.010000, 1.000000, 0.010000\n",
      " look, 305.909507, 0.090000, 0.880000, 0.102273\n",
      " come, 0.100022, 0.140000, 1.000000, 0.140000\n",
      " big, 0.100013, 0.160000, 0.840000, 0.190476\n",
      " say, 0.100013, 0.050000, 0.840000, 0.059524\n",
      " ani, 0.100006, 0.130000, 0.690000, 0.188406\n",
      " like, 0.100010, 0.170000, 1.000000, 0.170000\n",
      " perfect, 0.100007, 0.090000, 1.000000, 0.090000\n",
      " teddi, 0.100010, 0.130000, 1.000000, 0.130000\n",
      " just, 0.100006, 0.050000, 1.000000, 0.050000\n",
      " birthday, 147.185293, 0.130000, 0.800000, 0.162500\n",
      " want, 0.100002, 0.130000, 0.760000, 0.171053\n",
      " quit, 0.100008, 0.170000, 0.820000, 0.207317\n",
      " love, 33.974529, 0.100000, 1.000000, 0.100000\n",
      " child, 0.100038, 0.120000, 0.920000, 0.130435\n",
      " got, 0.100024, 0.130000, 0.830000, 0.156627\n",
      " son, 205.731326, 0.150000, 0.900000, 0.166667\n",
      " niec, 47.732557, 0.110000, 0.920000, 0.119565\n",
      " think, 0.100009, 0.070000, 0.950000, 0.073684\n",
      " nice, 0.100018, 0.100000, 1.000000, 0.100000\n",
      " make, 79.446765, 0.070000, 0.920000, 0.076087\n",
      "\n",
      "\n",
      "Cluster 5:\n",
      " christma, 121.896428, 0.010000, 1.000000, 0.010000\n",
      " n't, 0.100007, 0.110000, 1.000000, 0.110000\n",
      " present, 0.100019, 0.160000, 0.900000, 0.177778\n",
      " day, 0.100003, 0.140000, 1.000000, 0.140000\n",
      " bought, 0.100018, 0.060000, 1.000000, 0.060000\n",
      " did, 12.448461, 0.100000, 1.000000, 0.100000\n",
      " perfect, 0.100030, 0.090000, 1.000000, 0.090000\n",
      " disappoint, 264.984533, 0.150000, 0.930000, 0.161290\n",
      " want, 0.100002, 0.160000, 0.760000, 0.210526\n",
      " children, 0.100014, 0.110000, 0.920000, 0.119565\n",
      " got, 0.100007, 0.110000, 0.830000, 0.132530\n",
      " daughter, 0.100008, 0.040000, 1.000000, 0.040000\n",
      " birthday, 50.076757, 0.160000, 0.800000, 0.200000\n",
      " ani, 0.100009, 0.020000, 0.690000, 0.028986\n",
      " purchas, 0.100017, 0.050000, 0.820000, 0.060976\n",
      " big, 0.100009, 0.040000, 0.840000, 0.047619\n",
      " come, 0.100022, 0.000000, 1.000000, 0.000000\n",
      " absolut, 0.100019, 0.090000, 1.000000, 0.090000\n",
      " came, 0.100017, 0.010000, 1.000000, 0.010000\n",
      " expect, 0.100006, 0.140000, 1.000000, 0.140000\n",
      " deliveri, 0.100012, 0.050000, 0.910000, 0.054945\n",
      " quit, 0.100007, 0.170000, 0.820000, 0.207317\n",
      " t, 0.100013, 0.100000, 0.850000, 0.117647\n",
      " price, 354.144010, 0.040000, 0.810000, 0.049383\n",
      " gift, 0.100012, 0.080000, 1.000000, 0.080000\n",
      " packag, 0.100018, 0.150000, 1.000000, 0.150000\n",
      " think, 0.100013, 0.130000, 0.950000, 0.136842\n",
      " niec, 0.100021, 0.140000, 0.920000, 0.152174\n",
      " look, 0.100024, 0.130000, 0.880000, 0.147727\n",
      " veri, 0.100010, 0.140000, 1.000000, 0.140000\n",
      "\n",
      "\n",
      "Cluster 6:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " great, 0.100006, 0.020000, 1.000000, 0.020000\n",
      " happi, 869.547729, 0.040000, 1.000000, 0.040000\n",
      " veri, 0.100016, 0.130000, 1.000000, 0.130000\n",
      " product, 0.100023, 0.070000, 1.000000, 0.070000\n",
      " gift, 0.100015, 0.100000, 1.000000, 0.100000\n",
      " thank, 25.013868, 0.170000, 1.000000, 0.170000\n",
      " veri happi, 0.100005, 0.130000, 0.710000, 0.183099\n",
      " bought, 0.100015, 0.040000, 1.000000, 0.040000\n",
      " buy, 144.160164, 0.120000, 0.910000, 0.131868\n",
      " niec, 0.100014, 0.120000, 0.920000, 0.130435\n",
      " deliveri, 0.100019, 0.160000, 0.910000, 0.175824\n",
      " purchas, 359.626035, 0.090000, 0.820000, 0.109756\n",
      " absolut, 0.100009, 0.070000, 1.000000, 0.070000\n",
      " son, 0.100014, 0.090000, 0.900000, 0.100000\n",
      " ador, 38.354523, 0.160000, 1.000000, 0.160000\n",
      " present, 0.100013, 0.090000, 0.900000, 0.100000\n",
      " teddi, 0.100007, 0.130000, 1.000000, 0.130000\n",
      " love, 0.100017, 0.100000, 1.000000, 0.100000\n",
      " packag, 0.100019, 0.080000, 1.000000, 0.080000\n",
      " recommend, 0.100023, 0.040000, 1.000000, 0.040000\n",
      " arriv, 0.100020, 0.150000, 0.890000, 0.168539\n",
      " expect, 0.100019, 0.100000, 1.000000, 0.100000\n",
      " price, 27.422234, 0.020000, 0.810000, 0.024691\n",
      " realli, 0.100011, 0.120000, 1.000000, 0.120000\n",
      " want, 161.388882, 0.030000, 0.760000, 0.039474\n",
      " look, 0.100014, 0.130000, 0.880000, 0.147727\n",
      " ani, 0.100014, 0.050000, 0.690000, 0.072464\n",
      " friend, 0.100024, 0.150000, 0.920000, 0.163043\n",
      " definit, 0.100005, 0.120000, 0.620000, 0.193548\n",
      " excel, 0.100002, 0.050000, 1.000000, 0.050000\n",
      "\n",
      "\n",
      "Cluster 7:\n",
      " love, 95.178715, 0.100000, 1.000000, 0.100000\n",
      " old, 11.105368, 0.140000, 0.880000, 0.159091\n",
      " year, 0.100006, 0.120000, 0.760000, 0.157895\n",
      " year old, 462.162674, 0.130000, 0.590000, 0.220339\n",
      " grandson, 0.100006, 0.010000, 0.920000, 0.010870\n",
      " expect, 0.100008, 0.070000, 1.000000, 0.070000\n",
      " thought, 45.412676, 0.160000, 0.780000, 0.205128\n",
      " smaller, 0.100238, 0.110000, 0.770000, 0.142857\n",
      " lot, 0.100009, 0.120000, 0.770000, 0.155844\n",
      " bought, 0.100019, 0.030000, 1.000000, 0.030000\n",
      " cute, 0.100013, 0.140000, 1.000000, 0.140000\n",
      " purchas, 0.100015, 0.090000, 0.820000, 0.109756\n",
      " thing, 0.100009, 0.060000, 1.000000, 0.060000\n",
      " time, 202.267952, 0.050000, 0.820000, 0.060976\n",
      " realli, 0.100019, 0.100000, 1.000000, 0.100000\n",
      " price, 0.100008, 0.160000, 0.810000, 0.197531\n",
      " colour, 0.100012, 0.030000, 0.730000, 0.041096\n",
      " think, 64.553966, 0.110000, 0.950000, 0.115789\n",
      " make, 479.657758, 0.060000, 0.920000, 0.065217\n",
      " super, 0.100014, 0.020000, 1.000000, 0.020000\n",
      " good, 0.100003, 0.000000, 1.000000, 0.000000\n",
      " ador, 0.100023, 0.170000, 1.000000, 0.170000\n",
      " arriv, 0.100015, 0.050000, 0.890000, 0.056180\n",
      " recommend, 53.016438, 0.060000, 1.000000, 0.060000\n",
      " niec, 0.100021, 0.010000, 0.920000, 0.010870\n",
      " small, 0.100001, 0.100000, 1.000000, 0.100000\n",
      " say, 0.100013, 0.000000, 0.840000, 0.000000\n",
      " son, 0.100018, 0.070000, 0.900000, 0.077778\n",
      " littl, 0.100012, 0.150000, 1.000000, 0.150000\n",
      " size, 0.100055, 0.080000, 0.750000, 0.106667\n",
      "\n",
      "\n",
      "Cluster 8:\n",
      " love, 0.102825, 0.050000, 1.000000, 0.050000\n",
      " toy, 0.100011, 0.060000, 1.000000, 0.060000\n",
      " granddaught, 0.100008, 0.000000, 1.000000, 0.000000\n",
      " soft, 0.100003, 0.140000, 0.860000, 0.162791\n",
      " granddaught love, 451.887867, 0.150000, 0.720000, 0.208333\n",
      " cudd, 0.100035, 0.160000, 1.000000, 0.160000\n",
      " littl, 0.100019, 0.020000, 1.000000, 0.020000\n",
      " son, 449.291712, 0.050000, 0.900000, 0.055556\n",
      " worth, 0.100021, 0.130000, 0.730000, 0.178082\n",
      " money, 0.100011, 0.100000, 0.850000, 0.117647\n",
      " child, 0.100005, 0.020000, 0.920000, 0.021739\n",
      " nice, 0.100010, 0.110000, 1.000000, 0.110000\n",
      " good, 0.100005, 0.160000, 1.000000, 0.160000\n",
      " buy, 0.100018, 0.100000, 0.910000, 0.109890\n",
      " colour, 0.100015, 0.040000, 0.730000, 0.054795\n",
      " look, 186.139009, 0.010000, 0.880000, 0.011364\n",
      " definit, 0.100009, 0.020000, 0.620000, 0.032258\n",
      " purchas, 0.100004, 0.060000, 0.820000, 0.073171\n",
      " veri, 0.100006, 0.130000, 1.000000, 0.130000\n",
      " order, 0.100005, 0.100000, 0.930000, 0.107527\n",
      " recommend, 0.100031, 0.070000, 1.000000, 0.070000\n",
      " niec, 117.344701, 0.080000, 0.920000, 0.086957\n",
      " big, 0.100004, 0.140000, 0.840000, 0.166667\n",
      " children, 118.941107, 0.030000, 0.920000, 0.032609\n",
      " amaz, 0.100019, 0.140000, 0.870000, 0.160920\n",
      " pictur, 0.100017, 0.090000, 0.730000, 0.123288\n",
      " item, 0.100008, 0.010000, 1.000000, 0.010000\n",
      " price, 0.100011, 0.130000, 0.810000, 0.160494\n",
      " lot, 84.070559, 0.000000, 0.770000, 0.000000\n",
      " expect, 0.100011, 0.130000, 1.000000, 0.130000\n",
      "\n",
      "\n",
      "Cluster 9:\n",
      " good, 0.100006, 0.150000, 1.000000, 0.150000\n",
      " qualiti, 36.982813, 0.140000, 1.000000, 0.140000\n",
      " veri, 0.100007, 0.010000, 1.000000, 0.010000\n",
      " price, 0.100010, 0.060000, 0.810000, 0.074074\n",
      " size, 0.100030, 0.050000, 0.750000, 0.066667\n",
      " good qualiti, 965.346049, 0.040000, 0.700000, 0.057143\n",
      " quick, 770.956743, 0.160000, 0.840000, 0.190476\n",
      " excel, 0.100002, 0.120000, 1.000000, 0.120000\n",
      " pleas, 0.100012, 0.090000, 0.860000, 0.104651\n",
      " arriv, 0.100007, 0.060000, 0.890000, 0.067416\n",
      " item, 0.100006, 0.040000, 1.000000, 0.040000\n",
      " deliveri, 0.100023, 0.110000, 0.910000, 0.120879\n",
      " bought, 0.100018, 0.070000, 1.000000, 0.070000\n",
      " good size, 281.224088, 0.140000, 0.720000, 0.194444\n",
      " nice, 0.100010, 0.100000, 1.000000, 0.100000\n",
      " realli, 43.939820, 0.020000, 1.000000, 0.020000\n",
      " son, 0.100014, 0.090000, 0.900000, 0.100000\n",
      " small, 0.100001, 0.130000, 1.000000, 0.130000\n",
      " s, 0.100001, 0.070000, 1.000000, 0.070000\n",
      " gift, 0.100005, 0.080000, 1.000000, 0.080000\n",
      " quit, 280.831649, 0.090000, 0.820000, 0.109756\n",
      " expect, 215.383147, 0.120000, 1.000000, 0.120000\n",
      " packag, 38.151668, 0.080000, 1.000000, 0.080000\n",
      " order, 0.100006, 0.140000, 0.930000, 0.150538\n",
      " purchas, 0.100016, 0.110000, 0.820000, 0.134146\n",
      " niec, 135.380129, 0.100000, 0.920000, 0.108696\n",
      " love, 0.100018, 0.080000, 1.000000, 0.080000\n",
      " birthday, 0.100012, 0.100000, 0.800000, 0.125000\n",
      " thought, 0.100014, 0.060000, 0.780000, 0.076923\n",
      " recommend, 127.716781, 0.090000, 1.000000, 0.090000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    " \n",
    "order_centroids =  lda.components_.argsort()[:, ::-1] \n",
    "# print(order_centroids)\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d:\" % i, end='\\n')\n",
    "    time.sleep(1)\n",
    "    for ind in order_centroids[i, :30]: # 每个聚类选 30 个词\n",
    "        print(' %s' % word[ind], end=',')\n",
    "        print(' %f' % lda.components_[i][ind-1], end=',')\n",
    "        print(' %f' % (tfidMMframe[i:i+1][ind]), end=',')#a词在所属群中出现的频率\n",
    "        print(' %f' % max(tfidframe[:][ind]), end=',') #a词与所有顾客评论中出现最高词频的相对指数\n",
    "        print(' %f' % (tfidMMframe[i:i+1][ind]/max(tfidframe[:][ind])), end='\\n')\n",
    "        \n",
    "    print('') # 空行\n",
    "    print() # 空行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pyLDAvis/_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el300346146157127785845589\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el300346146157127785845589_data = {\"mdsDat\": {\"Freq\": [13.238755152078818, 12.740477934078005, 11.612849324150499, 11.274389677168493, 11.257898453255507, 10.145674400450904, 7.723774323512453, 7.49103415276775, 7.31670260712432, 7.198443975413252], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"x\": [0.19873080048455988, -0.1157937486998666, -0.16921227096532157, -0.1132554802450538, -0.19462361982913828, 0.22168989728377173, 0.18076747796204357, -0.18679335862748186, -0.0887548159206172, 0.2672451185571041], \"y\": [-0.08612649851345804, 0.046473080905853406, -0.180265556432304, -0.07508664883968819, 0.21197471530624076, -0.038336882396124566, 0.04033869499349325, 0.2282570060618407, -0.30318897912323084, 0.15596106803737833]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"Freq\": [3582.0, 1236.0, 1173.0, 1370.0, 1342.0, 752.0, 903.0, 907.0, 1286.0, 561.0, 1611.0, 637.0, 503.0, 486.0, 552.0, 1135.0, 518.0, 555.0, 419.0, 605.0, 448.0, 869.0, 446.0, 951.0, 371.0, 400.0, 367.0, 362.0, 381.0, 905.0, 554.876288659054, 260.87830203418, 218.658775024846, 192.20913145124305, 140.55076764682445, 159.35411304039158, 164.54169164496335, 128.93376725085395, 158.42736361550666, 131.8078276637096, 102.8045666056162, 637.0270356664597, 197.84656051792354, 155.3941279154056, 620.4261620715502, 103.34895805823336, 124.91798778982178, 62.1463319577352, 49.95225880201908, 94.53575131689732, 67.02275649003062, 43.11792732744618, 257.22174901657814, 135.9497690710295, 727.3208458110267, 79.94263286189549, 159.9201394543874, 50.621665106989, 60.22187016852985, 41.843688034078355, 80.94645632680762, 87.5715105253789, 223.62537700156813, 194.88148769148955, 827.3627087105864, 1130.5597262645913, 299.81659484413484, 115.36370958967184, 128.49603818399257, 145.29133210288575, 143.86614310470534, 104.73840936341607, 145.4797778582646, 153.3905415768074, 79.6100248921938, 75.79678700302638, 119.81532279062304, 175.76204209256917, 91.83352918485582, 301.9731029747251, 408.79562929727336, 71.2158724263173, 203.08400212054815, 152.35721303610632, 49.93308874773362, 47.831842629624184, 112.35396817778722, 33.53734877411907, 39.76779467119556, 63.15994817208759, 33.575192278417546, 126.88584815526006, 47.11834028786317, 78.42445453566118, 752.0517183251322, 274.3280481504824, 273.94523268898445, 209.58922280559287, 210.10162706989777, 147.04148385987176, 941.6743040902509, 347.71328934667093, 192.22196609995257, 305.3740177928815, 166.21361301707253, 192.92388598012494, 464.69821523316415, 37.216131225448045, 90.2649323186135, 42.86234918772633, 84.3816604535806, 61.31883470172784, 132.0604031575063, 41.416080752212785, 164.22808648489607, 124.58497258652604, 52.17557649585018, 31.400722920169216, 36.07593852590083, 42.333717800807975, 0.09755311478817587, 0.09757046446189659, 0.09755459348503817, 0.0975579006283786, 0.7626293261508045, 0.09761215342107536, 0.09758279701893981, 0.09757733284644898, 551.4220382191585, 517.5696406115432, 325.61078326889793, 318.2186944969235, 288.08929344715335, 304.8923371284128, 231.18875995083332, 156.74340397600167, 145.48244698818036, 215.1783414660427, 85.30065421916724, 325.3104793925857, 78.85554106769924, 342.45871475411735, 203.56179433859697, 219.8855021837198, 67.65550646888666, 257.06049772982544, 56.59158765287205, 59.10345416574283, 44.79031951411583, 34.350206902454865, 20.27315801746241, 37.34694127741433, 47.78278075147637, 41.54989262412054, 12.29295526158076, 14.222063309677962, 78.89837980861894, 11.094864296106342, 56.45579117976448, 40.098045541518815, 32.21993703390694, 28.076792076865804, 367.07330463249633, 180.65117439354995, 199.43460018786828, 350.5575680485338, 492.31018448059103, 231.90153249765683, 123.50304617126093, 312.89541301706276, 120.98837767700972, 356.63970645022886, 516.973335033191, 436.8114131823497, 101.93468967848209, 115.78719529087971, 62.344849044100236, 104.04657478043389, 95.51211549906935, 261.0456962244872, 83.46437006812971, 92.03956542234368, 73.81800797616887, 45.28141416484026, 43.18966745094574, 62.60133292263596, 29.17009665714578, 43.870012626257726, 155.07024277013588, 44.226036251904006, 16.897223989992124, 125.10314478349265, 447.8753213675953, 226.66841614018935, 213.84425416163415, 134.97923815792947, 117.8849680514054, 123.97673175345159, 749.2097951306467, 445.30221943902734, 81.17171541598478, 161.9835171809892, 46.4654880531873, 962.4121146038742, 83.83845830619946, 73.57007764746719, 84.58877857802665, 116.30273661109118, 41.19478989783867, 37.18537193474265, 184.48618520602, 38.11814173439786, 83.3240535905001, 45.05101737890024, 20.824192153981965, 19.842888350825127, 112.20831730554934, 18.45266834384862, 61.78241958718064, 0.7915289109518499, 0.09911611898596016, 0.09911436165389063, 0.1019118765117425, 0.10051552950011476, 485.35482608839067, 370.52614579847665, 275.0725684371152, 212.4181207808665, 178.50276791407856, 500.4149885648627, 230.65452492052069, 99.95495412498401, 67.79340027844975, 77.98893211370368, 47.691565864228586, 38.277936926403264, 49.404536169954866, 503.7278446935567, 56.25892224422185, 25.301218898027443, 34.28136562370822, 51.946790448507855, 88.97476553286347, 79.02886732837214, 55.67689803389116, 11.662655269928038, 13.332896628629909, 18.746871862427945, 27.84527897236138, 0.10504728796289983, 0.10503471607843377, 0.10501949956442173, 0.10502117510347754, 0.1050315971643301, 0.10526798375253561, 0.10507578375246489, 0.10506299888772509, 0.10506139717758274, 0.10505434337310364, 502.28814079249173, 278.518651772419, 372.23195995879047, 304.78091779961807, 163.0597872822699, 216.6654551640366, 128.12230302354794, 466.0012698058706, 91.1690436790981, 126.83447589588414, 129.8457921401079, 292.5244124403197, 62.273987814505034, 52.63443396856561, 57.660743385464706, 30.917518798343643, 36.56616415593726, 104.7576943336046, 27.47042400306807, 25.421938015891868, 8.930851552790877, 13.084267648317411, 0.10512614853270279, 0.10511490522179234, 0.10510921017833107, 0.10511981420319555, 0.10511829930214082, 0.10512292870641152, 0.10511776932973026, 0.10511279516782139, 0.10511962758507623, 0.10514374814158911, 0.1051428533239215, 0.10514079993890205, 0.10513929863149683, 0.10513815979205586, 0.10513713511950595, 0.10513608310423503, 0.10513454158523322, 418.7006473126539, 200.78183447039902, 163.92636599728152, 365.2803597337614, 883.2194462848064, 277.5295171328223, 101.96851948246473, 145.06238393378624, 418.34390327626045, 71.70906682095153, 58.94798391479674, 31.641057760259507, 38.957563166291095, 146.42676394558976, 25.40715548293569, 34.326161762804624, 27.85338808391725, 0.10159192855145698, 0.10157402987905652, 0.10159196869998353, 0.1015888428097821, 0.10157911845242303, 0.10157460769631825, 0.1015877374350034, 0.10158946228694711, 0.10157972635909357, 0.10158207894660086, 0.10158646012467219, 0.10158314227454522, 0.10158970226141997, 0.10203486514507625, 0.10160488699121073, 0.10160215339073367, 0.10159932319392086, 0.10159697429495597, 0.10159550965181983, 0.1015951952761919, 0.10159487305078449, 0.1015945767272676, 0.10159308088007632, 0.10159285329722437, 0.10159195306825887, 561.0584170226213, 1131.0297509643644, 1281.2363641857846, 58.87920955606759, 64.42089058172884, 30.670215438043407, 33.54109092521102, 62.872071101338335, 27.708763725133704, 14.729986919093918, 26.90512708267925, 22.671402742945194, 12.130735631089594, 10.028872705262975, 11.51713509120549, 5.36063492273284, 0.10066064461319295, 0.10065083472294917, 0.10475311623391259, 0.1006467335354257, 0.1006497771013458, 0.10064794756326942, 0.10064690918600816, 0.10065019513069781, 0.10065727546916903, 0.10065483640314403, 0.10064776823727124, 0.10064833415303552, 0.10065502437602333, 0.10065307842094809, 0.13820965403201343, 0.10087038251977337, 0.1007908857700126, 0.10069456016402303, 0.10068150898611945, 0.10066969814284596, 0.10066789667485095, 0.10066502142260406, 0.10066207708316148, 0.10066198975949044, 0.10066132538713993, 0.10066124465219863, 0.10066102966250177], \"Term\": [\"love\", \"daughter\", \"great\", \"toy\", \"'s\", \"qualiti\", \"n't\", \"cute\", \"good\", \"daughter love\", \"veri\", \"old\", \"christma\", \"year\", \"squishi\", \"littl\", \"smell\", \"babi\", \"happi\", \"just\", \"granddaught\", \"soft\", \"product\", \"like\", \"year old\", \"present\", \"doe\", \"day\", \"gift\", \"bought\", \"babi\", \"kid\", \"girl\", \"month\", \"use\", \"sound\", \"absolut\", \"ador\", \"make\", \"think\", \"fun\", \"littl\", \"play\", \"colour\", \"toy\", \"s\", \"buy\", \"quit\", \"lot\", \"recommend\", \"onli\", \"t\", \"great\", \"old\", \"love\", \"product\", \"bought\", \"gift\", \"price\", \"son\", \"realli\", \"like\", \"friend\", \"veri cute\", \"cute\", \"'s\", \"small\", \"teddi\", \"ani\", \"big\", \"say\", \"birthday\", \"come\", \"bit\", \"quit\", \"child\", \"perfect\", \"size\", \"want\", \"littl\", \"veri\", \"got\", \"soft\", \"look\", \"niec\", \"think\", \"just\", \"lot\", \"make\", \"son\", \"smaller\", \"like\", \"nice\", \"love\", \"qualiti\", \"good qualiti\", \"quick\", \"pleas\", \"excel\", \"good size\", \"good\", \"price\", \"item\", \"size\", \"deliveri\", \"arriv\", \"veri\", \"order\", \"son\", \"quit\", \"small\", \"s\", \"nice\", \"packag\", \"bought\", \"realli\", \"gift\", \"niec\", \"purchas\", \"expect\", \"veri happi\", \"definit\", \"use\", \"teddi\", \"love\", \"birthday\", \"thought\", \"recommend\", \"squishi\", \"smell\", \"rise\", \"slow\", \"slow rise\", \"came\", \"super\", \"amaz\", \"packag\", \"recommend\", \"definit\", \"nice\", \"fun\", \"realli\", \"soft\", \"like\", \"bit\", \"veri\", \"day\", \"expect\", \"colour\", \"come\", \"worth\", \"play\", \"price\", \"size\", \"order\", \"thing\", \"good\", \"t\", \"'s\", \"bought\", \"great\", \"love\", \"doe\", \"doe n't\", \"pictur\", \"time\", \"just\", \"onli\", \"t\", \"arriv\", \"thing\", \"look\", \"like\", \"n't\", \"money\", \"say\", \"order\", \"s\", \"got\", \"realli\", \"want\", \"play\", \"come\", \"sound\", \"disappoint\", \"bit\", \"use\", \"item\", \"'s\", \"expect\", \"worth\", \"good\", \"granddaught\", \"granddaught love\", \"cudd\", \"worth\", \"child\", \"money\", \"toy\", \"soft\", \"definit\", \"son\", \"order\", \"love\", \"colour\", \"purchas\", \"buy\", \"nice\", \"niec\", \"children\", \"littl\", \"big\", \"look\", \"recommend\", \"amaz\", \"pictur\", \"good\", \"item\", \"veri\", \"price\", \"good size\", \"veri happi\", \"lot\", \"expect\", \"year\", \"year old\", \"grandson\", \"thought\", \"smaller\", \"old\", \"expect\", \"lot\", \"thing\", \"purchas\", \"think\", \"make\", \"colour\", \"love\", \"time\", \"ador\", \"super\", \"price\", \"bought\", \"cute\", \"realli\", \"niec\", \"recommend\", \"arriv\", \"good\", \"order\", \"good size\", \"veri happi\", \"definit\", \"use\", \"small\", \"say\", \"son\", \"littl\", \"size\", \"christma\", \"did\", \"present\", \"day\", \"disappoint\", \"perfect\", \"children\", \"n't\", \"birthday\", \"got\", \"want\", \"bought\", \"ani\", \"big\", \"purchas\", \"absolut\", \"come\", \"daughter\", \"came\", \"expect\", \"quit\", \"deliveri\", \"order\", \"good size\", \"veri happi\", \"definit\", \"use\", \"teddi\", \"worth\", \"doe n't\", \"fun\", \"t\", \"price\", \"gift\", \"packag\", \"think\", \"niec\", \"look\", \"veri\", \"happi\", \"thank\", \"veri happi\", \"product\", \"great\", \"gift\", \"niec\", \"buy\", \"veri\", \"deliveri\", \"purchas\", \"ador\", \"absolut\", \"bought\", \"teddi\", \"son\", \"present\", \"order\", \"good size\", \"definit\", \"use\", \"worth\", \"doe n't\", \"fun\", \"lot\", \"t\", \"month\", \"amaz\", \"quit\", \"child\", \"love\", \"packag\", \"recommend\", \"arriv\", \"expect\", \"price\", \"realli\", \"want\", \"look\", \"ani\", \"friend\", \"excel\", \"daughter love\", \"daughter\", \"love\", \"children\", \"deliveri\", \"teddi\", \"packag\", \"look\", \"s\", \"t\", \"play\", \"bit\", \"excel\", \"ani\", \"littl\", \"bought\", \"order\", \"good size\", \"use\", \"veri happi\", \"definit\", \"worth\", \"doe n't\", \"fun\", \"lot\", \"ador\", \"month\", \"amaz\", \"quit\", \"child\", \"product\", \"item\", \"arriv\", \"came\", \"say\", \"friend\", \"thing\", \"nice\", \"think\", \"birthday\", \"day\", \"buy\", \"absolut\"], \"Total\": [3582.0, 1236.0, 1173.0, 1370.0, 1342.0, 752.0, 903.0, 907.0, 1286.0, 561.0, 1611.0, 637.0, 503.0, 486.0, 552.0, 1135.0, 518.0, 555.0, 419.0, 605.0, 448.0, 869.0, 446.0, 951.0, 371.0, 400.0, 367.0, 362.0, 381.0, 905.0, 555.7818260280335, 261.7837206099959, 219.56419629037532, 193.1145747838577, 170.8090457699801, 205.4792408639746, 235.11556504181002, 186.57488521137927, 237.17480263803768, 228.0330108485381, 182.46792147892646, 1135.610464859508, 354.74536056876406, 334.0311621253016, 1370.442305543347, 297.0303572494402, 375.54475065762085, 194.15363845435976, 184.14911853287154, 368.7017323039339, 299.7297129063169, 193.05300504565304, 1173.3673782752128, 637.1651608473547, 3582.2682397536814, 446.06522451001484, 905.8899109265908, 381.0331169771984, 508.9624178940392, 392.0867582315202, 865.2180006662261, 951.9252852777165, 224.53065172098542, 195.78665702689094, 907.1917812863621, 1342.7933746013252, 385.0062015662699, 172.14407811406105, 201.4984052081357, 256.2059487575139, 260.4586516741097, 196.70764047488038, 290.81667924845016, 306.9257388857615, 194.15363845435976, 194.48788761472989, 337.28091632879597, 523.3960397286045, 305.8513254421431, 1135.610464859508, 1611.190044128994, 294.26258710674, 869.4306607799979, 655.7985292855049, 236.66175863300916, 228.0330108485381, 605.4693860946094, 184.14911853287154, 237.17480263803768, 392.0867582315202, 224.7081037389689, 951.9252852777165, 646.4576963495281, 3582.2682397536814, 752.9581255883843, 275.2343972755456, 274.85161527085637, 210.49565060409853, 223.03810364511705, 162.5775558231747, 1286.2352100209766, 508.9624178940392, 283.03378584475905, 523.3960397286045, 316.04235721530364, 525.2676843700806, 1611.190044128994, 158.9290847820005, 392.0867582315202, 194.15363845435976, 385.0062015662699, 297.0303572494402, 646.4576963495281, 221.14778858628003, 905.8899109265908, 865.2180006662261, 381.0331169771984, 236.66175863300916, 304.7392380041662, 402.2396851308993, 164.82866544113872, 167.27957950020806, 170.8090457699801, 172.14407811406105, 3582.2682397536814, 196.70764047488038, 213.3171411909384, 368.7017323039339, 552.3283346025348, 518.4759319566764, 326.51702719477606, 319.1249463790882, 288.9955372479295, 333.16403469662833, 276.30325999720793, 193.4408362940511, 221.14778858628003, 368.7017323039339, 167.27957950020806, 646.4576963495281, 182.46792147892646, 865.2180006662261, 869.4306607799979, 951.9252852777165, 306.9257388857615, 1611.190044128994, 362.17371599113875, 402.2396851308993, 334.0311621253016, 290.81667924845016, 172.85678138649095, 354.74536056876406, 508.9624178940392, 523.3960397286045, 158.9290847820005, 203.7051567777849, 1286.2352100209766, 193.05300504565304, 1342.7933746013252, 905.8899109265908, 1173.3673782752128, 3582.2682397536814, 367.97720906119895, 181.55505357155255, 220.08232035726778, 407.6154434759871, 605.4693860946094, 299.7297129063169, 193.05300504565304, 525.2676843700806, 203.7051567777849, 655.7985292855049, 951.9252852777165, 903.6115265491945, 226.7162333153459, 260.4586516741097, 158.9290847820005, 297.0303572494402, 294.26258710674, 865.2180006662261, 305.8513254421431, 354.74536056876406, 290.81667924845016, 205.4792408639746, 207.048274393086, 306.9257388857615, 170.8090457699801, 283.03378584475905, 1342.7933746013252, 402.2396851308993, 172.85678138649095, 1286.2352100209766, 448.78012191748905, 227.57317611090392, 214.7491231606807, 172.85678138649095, 194.48788761472989, 226.7162333153459, 1370.442305543347, 869.4306607799979, 167.27957950020806, 392.0867582315202, 158.9290847820005, 3582.2682397536814, 334.0311621253016, 304.7392380041662, 375.54475065762085, 646.4576963495281, 236.66175863300916, 224.88596369375318, 1135.610464859508, 256.2059487575139, 655.7985292855049, 368.7017323039339, 193.4408362940511, 220.08232035726778, 1286.2352100209766, 283.03378584475905, 1611.190044128994, 508.9624178940392, 162.5775558231747, 164.82866544113872, 184.14911853287154, 402.2396851308993, 486.25370179714116, 371.4250041279093, 275.97145691125746, 213.3171411909384, 224.7081037389689, 637.1651608473547, 402.2396851308993, 184.14911853287154, 203.7051567777849, 304.7392380041662, 228.0330108485381, 237.17480263803768, 334.0311621253016, 3582.2682397536814, 407.6154434759871, 186.57488521137927, 276.30325999720793, 508.9624178940392, 905.8899109265908, 907.1917812863621, 865.2180006662261, 236.66175863300916, 368.7017323039339, 525.2676843700806, 1286.2352100209766, 158.9290847820005, 162.5775558231747, 164.82866544113872, 167.27957950020806, 170.8090457699801, 385.0062015662699, 260.4586516741097, 392.0867582315202, 1135.610464859508, 523.3960397286045, 503.18696946318386, 279.41748599788644, 400.8825895102467, 362.17371599113875, 207.048274393086, 337.28091632879597, 224.88596369375318, 903.6115265491945, 196.70764047488038, 294.26258710674, 305.8513254421431, 905.8899109265908, 201.4984052081357, 256.2059487575139, 304.7392380041662, 235.11556504181002, 290.81667924845016, 1236.585641143953, 333.16403469662833, 402.2396851308993, 194.15363845435976, 316.04235721530364, 158.9290847820005, 162.5775558231747, 164.82866544113872, 167.27957950020806, 170.8090457699801, 172.14407811406105, 172.85678138649095, 181.55505357155255, 182.46792147892646, 193.05300504565304, 508.9624178940392, 381.0331169771984, 221.14778858628003, 228.0330108485381, 236.66175863300916, 655.7985292855049, 1611.190044128994, 419.6030130681082, 201.6841815543792, 164.82866544113872, 446.06522451001484, 1173.3673782752128, 381.0331169771984, 236.66175863300916, 375.54475065762085, 1611.190044128994, 316.04235721530364, 304.7392380041662, 186.57488521137927, 235.11556504181002, 905.8899109265908, 172.14407811406105, 392.0867582315202, 400.8825895102467, 158.9290847820005, 162.5775558231747, 167.27957950020806, 170.8090457699801, 172.85678138649095, 181.55505357155255, 182.46792147892646, 184.14911853287154, 193.05300504565304, 193.1145747838577, 193.4408362940511, 194.15363845435976, 194.48788761472989, 3582.2682397536814, 221.14778858628003, 368.7017323039339, 525.2676843700806, 402.2396851308993, 508.9624178940392, 865.2180006662261, 305.8513254421431, 655.7985292855049, 201.4984052081357, 224.53065172098542, 223.03810364511705, 561.9616450331843, 1236.585641143953, 3582.2682397536814, 224.88596369375318, 316.04235721530364, 172.14407811406105, 221.14778858628003, 655.7985292855049, 297.0303572494402, 193.05300504565304, 354.74536056876406, 306.9257388857615, 223.03810364511705, 201.4984052081357, 1135.610464859508, 905.8899109265908, 158.9290847820005, 162.5775558231747, 170.8090457699801, 164.82866544113872, 167.27957950020806, 172.85678138649095, 181.55505357155255, 182.46792147892646, 184.14911853287154, 186.57488521137927, 193.1145747838577, 193.4408362940511, 194.15363845435976, 194.48788761472989, 446.06522451001484, 283.03378584475905, 525.2676843700806, 333.16403469662833, 260.4586516741097, 224.53065172098542, 203.7051567777849, 646.4576963495281, 228.0330108485381, 196.70764047488038, 362.17371599113875, 375.54475065762085, 235.11556504181002], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.0204, 2.0186, 2.0179, 2.0173, 1.827, 1.7678, 1.6651, 1.6525, 1.6185, 1.4739, 1.4483, 1.4439, 1.4381, 1.2568, 1.2295, 0.9663, 0.9213, 0.8829, 0.7173, 0.661, 0.5242, 0.523, 0.5043, 0.4773, 0.4276, 0.3029, 0.2878, 0.0035, -0.1123, -0.2155, -0.3472, -0.364, 2.0563, 2.0558, 1.9683, 1.8883, 1.8103, 1.6601, 1.6105, 1.4931, 1.4668, 1.4301, 1.3677, 1.3668, 1.1689, 1.1181, 1.0254, 0.9692, 0.8573, 0.7358, 0.6889, 0.6416, 0.6062, 0.6008, 0.5044, 0.4986, 0.376, 0.3573, 0.2746, 0.2346, 0.1594, 0.0452, -0.5585, -1.7612, 2.1519, 2.1498, 2.1498, 2.1487, 2.0933, 2.0526, 1.8412, 1.7721, 1.7661, 1.6143, 1.5105, 1.1514, 0.9097, 0.7013, 0.6843, 0.6424, 0.6351, 0.5753, 0.5648, 0.4779, 0.4454, 0.2151, 0.1648, 0.1333, 0.0192, -0.0984, -5.2792, -5.2938, -5.3148, -5.3226, -6.3017, -5.4554, -5.5368, -6.084, 2.181, 2.1809, 2.1799, 2.1798, 2.1795, 2.094, 2.0044, 1.9723, 1.7639, 1.6441, 1.5092, 1.4959, 1.3437, 1.2558, 0.7308, 0.7173, 0.6705, 0.3472, 0.3264, 0.2649, 0.1734, 0.0466, 0.0395, -0.0685, -0.1831, -0.3508, -0.3768, -0.4792, -0.6087, -0.6738, -0.9864, -0.935, -1.4124, -2.6662, 2.1816, 2.1791, 2.0856, 2.0333, 1.9772, 1.9275, 1.7374, 1.6661, 1.6631, 1.575, 1.5736, 1.4572, 1.3847, 1.3734, 1.2483, 1.1351, 1.0589, 0.9858, 0.8854, 0.8349, 0.813, 0.6717, 0.6167, 0.5943, 0.4167, 0.3198, 0.0255, -0.0236, -0.1412, -0.1462, 2.2861, 2.2841, 2.2839, 2.0408, 1.7875, 1.6845, 1.6843, 1.619, 1.565, 1.4041, 1.0584, 0.9738, 0.9058, 0.8669, 0.7975, 0.5728, 0.5398, 0.4884, 0.4708, 0.3828, 0.225, 0.1859, 0.0593, -0.118, -0.151, -0.4422, -0.973, -4.178, -5.1145, -5.1283, -5.2113, -6.0064, 2.559, 2.5584, 2.5576, 2.5566, 2.3307, 2.3193, 2.0047, 1.9498, 1.4607, 1.198, 0.9961, 0.7369, 0.6497, 0.5992, 0.5805, 0.5629, 0.474, 0.2787, 0.2403, 0.1203, -0.1825, -0.4494, -0.7589, -0.772, -1.2719, -4.7609, -4.7838, -4.7976, -4.8124, -4.8332, -5.6436, -5.2547, -5.6638, -6.7273, -5.9527, 2.5897, 2.5882, 2.5173, 2.4189, 2.3526, 2.1489, 2.0289, 1.9293, 1.8225, 1.7499, 1.7347, 1.4611, 1.4172, 1.0089, 0.9266, 0.5627, 0.5179, 0.123, 0.0959, -0.17, -0.4877, -0.593, -4.7296, -4.7524, -4.7662, -4.7809, -4.8018, -4.8095, -4.8137, -4.8628, -4.8678, -4.9239, -5.8933, -5.6039, -5.0598, -5.0905, -5.1277, -6.1469, -7.0458, 2.6129, 2.6105, 2.6095, 2.4152, 2.331, 2.2981, 1.773, 1.6638, 1.2666, 1.1318, 0.9722, 0.8406, 0.8174, 0.7926, 0.7017, 0.1794, -0.0517, -4.7402, -4.7631, -4.7914, -4.8124, -4.8244, -4.8735, -4.8784, -4.8876, -4.9349, -4.9352, -4.9368, -4.9405, -4.9422, -7.8512, -5.0705, -5.5817, -5.9356, -5.6688, -5.9041, -6.4347, -5.3949, -6.1576, -4.9776, -5.0858, -5.0791, 2.6297, 2.5421, 1.6031, 1.2912, 1.0409, 0.9063, 0.7452, 0.2866, 0.2592, 0.0582, 0.0522, 0.0258, -0.2803, -0.369, -1.9598, -2.4985, -4.7332, -4.7559, -4.7654, -4.7697, -4.7845, -4.8173, -4.8664, -4.8714, -4.8805, -4.8936, -4.9281, -4.9298, -4.9334, -4.9351, -5.4481, -5.3082, -5.9273, -5.473, -5.2269, -5.0786, -4.9813, -6.1362, -5.0942, -4.9464, -5.5568, -5.5931, -5.1248], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.4114, -3.166, -3.3426, -3.4715, -3.7845, -3.659, -3.6269, -3.8708, -3.6648, -3.8488, -4.0973, -2.2733, -3.4426, -3.6841, -2.2997, -4.092, -3.9024, -4.6006, -4.819, -4.1811, -4.5251, -4.9662, -3.1802, -3.8178, -2.1407, -4.3488, -3.6554, -4.8057, -4.6321, -4.9962, -4.3363, -4.2576, -3.2818, -3.4193, -1.9735, -1.6613, -2.9886, -3.9436, -3.8358, -3.713, -3.7229, -4.0403, -3.7117, -3.6587, -4.3146, -4.3637, -3.9058, -3.5226, -4.1718, -2.9814, -2.6785, -4.426, -3.3781, -3.6655, -4.7811, -4.824, -3.9701, -5.1791, -5.0087, -4.5461, -5.1779, -3.8484, -4.8391, -4.3296, -1.9763, -2.9847, -2.9861, -3.2539, -3.2515, -3.6083, -1.7514, -2.7477, -3.3404, -2.8775, -3.4858, -3.3368, -2.4577, -4.9823, -4.0963, -4.8411, -4.1637, -4.483, -3.7158, -4.8754, -3.4978, -3.7741, -4.6444, -5.1522, -5.0134, -4.8535, -10.9264, -10.9262, -10.9264, -10.9264, -8.87, -10.9258, -10.9261, -10.9262, -2.257, -2.3203, -2.7838, -2.8067, -2.9062, -2.8495, -3.1262, -3.5149, -3.5894, -3.198, -4.1233, -2.7847, -4.2019, -2.7333, -3.2535, -3.1764, -4.3551, -3.0202, -4.5336, -4.4902, -4.7675, -5.0329, -5.5602, -4.9492, -4.7028, -4.8426, -6.0605, -5.9147, -4.2013, -6.163, -4.536, -4.8782, -5.0969, -5.2345, -2.6625, -3.3715, -3.2725, -2.7085, -2.3689, -3.1217, -3.7518, -2.8222, -3.7723, -2.6913, -2.32, -2.4885, -3.9437, -3.8163, -4.4353, -3.9232, -4.0088, -3.0033, -4.1436, -4.0458, -4.2664, -4.7551, -4.8024, -4.4312, -5.1949, -4.7868, -3.5241, -4.7787, -5.7409, -3.7389, -2.3595, -3.0405, -3.0987, -3.5589, -3.6943, -3.6439, -1.845, -2.3652, -4.0674, -3.3765, -4.6253, -1.5946, -4.0351, -4.1658, -4.0262, -3.7078, -4.7457, -4.8481, -3.2464, -4.8233, -4.0413, -4.6562, -5.4279, -5.4762, -3.7436, -5.5488, -4.3404, -8.6978, -10.7755, -10.7755, -10.7476, -10.7614, -2.0064, -2.2763, -2.5742, -2.8327, -3.0066, -1.9758, -2.7503, -3.5865, -3.9748, -3.8347, -4.3265, -4.5464, -4.2912, -1.9692, -4.1613, -4.9604, -4.6567, -4.241, -3.7029, -3.8214, -4.1717, -5.7349, -5.601, -5.2602, -4.8646, -10.4446, -10.4447, -10.4449, -10.4448, -10.4447, -10.4425, -10.4443, -10.4444, -10.4445, -10.4445, -1.9415, -2.5312, -2.2411, -2.4411, -3.0665, -2.7823, -3.3077, -2.0165, -3.6479, -3.3178, -3.2943, -2.4821, -4.0291, -4.1973, -4.1061, -4.7293, -4.5615, -3.509, -4.8475, -4.925, -5.9711, -5.5892, -10.4133, -10.4134, -10.4134, -10.4133, -10.4133, -10.4133, -10.4133, -10.4134, -10.4133, -10.4131, -10.4131, -10.4131, -10.4131, -10.4131, -10.4131, -10.4132, -10.4132, -2.1, -2.8349, -3.0377, -2.2364, -1.3535, -2.5112, -3.5124, -3.1599, -2.1008, -3.8645, -4.0605, -4.6827, -4.4746, -3.1506, -4.9021, -4.6012, -4.8102, -10.4239, -10.4241, -10.4239, -10.4239, -10.424, -10.4241, -10.4239, -10.4239, -10.424, -10.424, -10.424, -10.424, -10.4239, -10.4196, -10.4238, -10.4238, -10.4238, -10.4239, -10.4239, -10.4239, -10.4239, -10.4239, -10.4239, -10.4239, -10.4239, -1.791, -1.0899, -0.9652, -4.0453, -3.9554, -4.6975, -4.608, -3.9797, -4.7991, -5.4309, -4.8285, -4.9997, -5.6251, -5.8153, -5.677, -6.4417, -10.4168, -10.4169, -10.377, -10.417, -10.4169, -10.4169, -10.417, -10.4169, -10.4168, -10.4169, -10.4169, -10.4169, -10.4169, -10.4169, -10.0998, -10.4147, -10.4155, -10.4165, -10.4166, -10.4167, -10.4167, -10.4168, -10.4168, -10.4168, -10.4168, -10.4168, -10.4168]}, \"token.table\": {\"Topic\": [2, 4, 5, 1, 8, 9, 1, 7, 9, 1, 4, 6, 2, 8, 10, 3, 5, 7, 1, 1, 2, 6, 8, 2, 8, 2, 4, 5, 10, 1, 3, 4, 5, 7, 8, 9, 10, 1, 2, 6, 9, 4, 8, 2, 6, 6, 8, 10, 8, 1, 4, 6, 7, 2, 4, 5, 8, 6, 2, 7, 8, 10, 10, 4, 8, 4, 6, 3, 8, 9, 10, 8, 5, 8, 5, 5, 3, 10, 3, 4, 5, 7, 8, 2, 1, 4, 1, 3, 9, 1, 3, 4, 5, 6, 7, 3, 1, 3, 2, 5, 8, 6, 6, 7, 1, 4, 9, 9, 1, 3, 5, 6, 2, 5, 1, 1, 2, 4, 5, 1, 2, 6, 10, 2, 5, 6, 10, 1, 2, 7, 1, 2, 3, 4, 6, 7, 10, 1, 2, 7, 5, 6, 1, 5, 8, 1, 2, 3, 4, 6, 2, 3, 6, 7, 9, 1, 7, 1, 5, 3, 4, 5, 6, 3, 4, 10, 2, 8, 5, 6, 1, 4, 5, 10, 3, 8, 9, 1, 3, 4, 6, 7, 1, 9, 3, 6, 7, 8, 9, 3, 3, 1, 2, 3, 8, 1, 3, 4, 5, 7, 1, 4, 6, 7, 4, 1, 3, 5, 10, 2, 5, 2, 3, 4, 4, 4, 2, 3, 2, 4, 7, 4, 1, 2, 4, 6, 1, 2, 3, 6, 9, 1, 5, 4, 1, 4, 7, 1, 4, 5, 10, 2, 9, 10, 9, 4, 5, 7, 1, 2, 7, 7, 5, 7, 1, 6, 1, 5, 2, 3, 4, 6, 9, 2, 9, 2, 5, 8, 4, 5, 6, 7, 7], \"Freq\": [0.8422740396196797, 0.041704108062512874, 0.11543101338731242, 0.7017825466836212, 0.1318500542254076, 0.16587587467067408, 0.691411386124397, 0.13399445467527074, 0.17151290198434654, 0.07754308907762562, 0.8116176656791482, 0.10856032470867587, 0.6352407596863296, 0.3076947429730659, 0.0496281843504945, 0.3674317033827283, 0.5958866484911604, 0.03617203297550175, 0.9985932860856194, 0.07806219994887394, 0.565950949629336, 0.14831817990286048, 0.20686482986451593, 0.5337870951352728, 0.4626154824505697, 0.49849191715050967, 0.2215519631780043, 0.20526137765020988, 0.0749366934278544, 0.17662190302610145, 0.181037450601754, 0.04415547575652536, 0.008831095151305073, 0.09824593355826892, 0.3234388599165483, 0.16116748651131757, 0.00551943446956567, 0.33284981292139226, 0.05325597006742276, 0.22633787278654674, 0.386105782988815, 0.9154649609094995, 0.0810411604739557, 0.39076983627151085, 0.6067215878952406, 0.16452783176092806, 0.5691773639296971, 0.26235519118634476, 0.9976410965799648, 0.46402856252632046, 0.13471796976570594, 0.2514735435626511, 0.14669290041154648, 0.49859588650389536, 0.11691213890436167, 0.25445583173302244, 0.12722791586651122, 0.9965116357652357, 0.9116043785442441, 0.08708191766021195, 0.08491122370049968, 0.914615181002525, 0.998288771054602, 0.15738303881056517, 0.842137312933726, 0.50813135861508, 0.48421929468025265, 0.5252460507593057, 0.041133726866692616, 0.2278175641847591, 0.20250450149756363, 0.9985058701806171, 0.20768103538193947, 0.7872560178431658, 0.9973443761267388, 0.9969427809326509, 0.9415431559359813, 0.05380246605348465, 0.10441535619821327, 0.14667871465939483, 0.1093875160171758, 0.574284459090173, 0.06215199773703171, 0.9976366179097683, 0.5644827823168669, 0.4329528136216746, 0.13384663360652696, 0.13647107740273337, 0.7295953753453822, 0.9974303811827809, 0.7323699372097249, 0.06141955948998755, 0.09718284729428409, 0.08707583117567855, 0.021768957793919637, 0.995515105351059, 0.09226365794497828, 0.9041838478607871, 0.2412810976009181, 0.32623923055898785, 0.43158731542699436, 0.9982616834405325, 0.9974813546978639, 0.9964798645405932, 0.21902773569329687, 0.027271935961811284, 0.7525349829462301, 0.9985628962392357, 0.0989281188336918, 0.6783642434310295, 0.15545847245294425, 0.06359664782165901, 0.1849804508241464, 0.812592694691786, 0.997006228621972, 0.09244422998421216, 0.13341383190903347, 0.23111057496053042, 0.5431098511572465, 0.5609317804928879, 0.26593626013948535, 0.16202739028365995, 0.010567003714151734, 0.23177850088441737, 0.5443745053666909, 0.12656326035135948, 0.0960660891823572, 0.27151908408985814, 0.18463297718110352, 0.5430381681797163, 0.20294404308762454, 0.021773913838837294, 0.0002791527415235551, 0.007816276762659542, 0.26854493734566, 0.14069298172787176, 0.35759466189167405, 0.666175319817301, 0.16865197970058254, 0.16021938071555342, 0.44990161713795485, 0.5469392208343765, 0.9942284274239519, 0.4836149021569711, 0.5157083395998822, 0.03867229076422496, 0.07270390663674293, 0.2041896952351078, 0.5027397799349245, 0.17943942914600383, 0.21127198702826713, 0.13098863195752564, 0.17324302936317906, 0.05070527688678411, 0.430994853537665, 0.21344544296668072, 0.7847258932598555, 0.22353472850701803, 0.774030701695943, 0.2328082367727221, 0.07550537408845041, 0.3901110994569938, 0.28943726733905994, 0.1853963824919913, 0.6556701332033839, 0.1537433415787245, 0.35578650967319725, 0.643380604992365, 0.9042071152146884, 0.0908750869562501, 0.558146834344912, 0.10430016601394819, 0.25934095333197926, 0.07611093195612435, 0.997645316648225, 0.9279524971500204, 0.0698458868822596, 0.11788689673446849, 0.6837440010599173, 0.09430951738757479, 0.0019647816122411415, 0.10216864383653936, 0.1793459691637627, 0.8182659843096672, 0.11813378623565314, 0.24283056059550925, 0.25595653684391517, 0.19032665560188564, 0.1936081496639871, 0.9987275180971908, 0.9969015453301334, 0.319334731471306, 0.41204481480168514, 0.22147408795590576, 0.04635504166518958, 0.09361802451824769, 0.14447226005902422, 0.39527610352149023, 0.30165807900324254, 0.06472357250644285, 0.2576608452755739, 0.5831271761499831, 0.12204987407790345, 0.03525885251139433, 0.9984165383373172, 0.34676590283161746, 0.20536621429833654, 0.35013256208240984, 0.09426645902218726, 0.5528708648164824, 0.445368196657722, 0.33626544077647386, 0.5827327240728666, 0.08024516200347671, 0.9964749030376588, 0.996555181241171, 0.779208227762435, 0.2181783037734818, 0.151307404736484, 0.053402613436406114, 0.7965889837597245, 0.9990820558345297, 0.01955302563720111, 0.23348612966775442, 0.23463630764641333, 0.5118292005032056, 0.10711914931643714, 0.1606787239746557, 0.22954103424950814, 0.4131738616491147, 0.08671550182759197, 0.7738007953088388, 0.2190002250874072, 0.9975950272341347, 0.03619211731378432, 0.8360379099484179, 0.12305319886686669, 0.2227367555860184, 0.05697917003363262, 0.642310644015495, 0.07769886822768084, 0.668045054235337, 0.14522718570333412, 0.18008171027213432, 0.996607658820309, 0.06872678248038722, 0.5939957628662038, 0.33381580061902366, 0.5788635579945737, 0.21049583927075408, 0.21049583927075408, 0.9938254320136447, 0.8611057446862355, 0.13738439231461308, 0.4524086840373664, 0.5465388779741733, 0.8254832135171435, 0.16978023540423517, 0.25384963213393275, 0.28860654998112156, 0.1595094265487059, 0.038480873330816213, 0.2594355653593738, 0.9959820702859088, 0.9949725647603775, 0.3007997427083354, 0.27137368092165043, 0.4250431146965609, 0.11570272129088152, 0.0983473130972493, 0.7809933687134503, 0.9974217125905518, 0.9988557471274526], \"Term\": [\"'s\", \"'s\", \"'s\", \"absolut\", \"absolut\", \"absolut\", \"ador\", \"ador\", \"ador\", \"amaz\", \"amaz\", \"amaz\", \"ani\", \"ani\", \"ani\", \"arriv\", \"arriv\", \"arriv\", \"babi\", \"big\", \"big\", \"big\", \"big\", \"birthday\", \"birthday\", \"bit\", \"bit\", \"bit\", \"bit\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"buy\", \"buy\", \"buy\", \"buy\", \"came\", \"came\", \"child\", \"child\", \"children\", \"children\", \"children\", \"christma\", \"colour\", \"colour\", \"colour\", \"colour\", \"come\", \"come\", \"come\", \"come\", \"cudd\", \"cute\", \"cute\", \"daughter\", \"daughter\", \"daughter love\", \"day\", \"day\", \"definit\", \"definit\", \"deliveri\", \"deliveri\", \"deliveri\", \"deliveri\", \"did\", \"disappoint\", \"disappoint\", \"doe\", \"doe n't\", \"excel\", \"excel\", \"expect\", \"expect\", \"expect\", \"expect\", \"expect\", \"friend\", \"fun\", \"fun\", \"gift\", \"gift\", \"gift\", \"girl\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good qualiti\", \"good size\", \"good size\", \"got\", \"got\", \"got\", \"granddaught\", \"granddaught love\", \"grandson\", \"great\", \"great\", \"great\", \"happi\", \"item\", \"item\", \"item\", \"item\", \"just\", \"just\", \"kid\", \"like\", \"like\", \"like\", \"like\", \"littl\", \"littl\", \"littl\", \"littl\", \"look\", \"look\", \"look\", \"look\", \"lot\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"make\", \"make\", \"make\", \"money\", \"money\", \"month\", \"n't\", \"n't\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"niec\", \"niec\", \"niec\", \"niec\", \"niec\", \"old\", \"old\", \"onli\", \"onli\", \"order\", \"order\", \"order\", \"order\", \"packag\", \"packag\", \"packag\", \"perfect\", \"perfect\", \"pictur\", \"pictur\", \"play\", \"play\", \"play\", \"play\", \"pleas\", \"present\", \"present\", \"price\", \"price\", \"price\", \"price\", \"price\", \"product\", \"product\", \"purchas\", \"purchas\", \"purchas\", \"purchas\", \"purchas\", \"qualiti\", \"quick\", \"quit\", \"quit\", \"quit\", \"quit\", \"realli\", \"realli\", \"realli\", \"realli\", \"realli\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"rise\", \"s\", \"s\", \"s\", \"s\", \"say\", \"say\", \"size\", \"size\", \"size\", \"slow\", \"slow rise\", \"small\", \"small\", \"smaller\", \"smaller\", \"smaller\", \"smell\", \"soft\", \"soft\", \"soft\", \"soft\", \"son\", \"son\", \"son\", \"son\", \"son\", \"sound\", \"sound\", \"squishi\", \"super\", \"super\", \"super\", \"t\", \"t\", \"t\", \"t\", \"teddi\", \"teddi\", \"teddi\", \"thank\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"thought\", \"time\", \"time\", \"toy\", \"toy\", \"use\", \"use\", \"veri\", \"veri\", \"veri\", \"veri\", \"veri\", \"veri cute\", \"veri happi\", \"want\", \"want\", \"want\", \"worth\", \"worth\", \"worth\", \"year\", \"year old\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 5, 10, 3, 4, 9, 8, 6, 7, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el300346146157127785845589\", ldavis_el300346146157127785845589_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el300346146157127785845589\", ldavis_el300346146157127785845589_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el300346146157127785845589\", ldavis_el300346146157127785845589_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "1      13.238755        1       1  0.198731 -0.086126\n",
       "4      12.740478        1       2 -0.115794  0.046473\n",
       "9      11.612849        1       3 -0.169212 -0.180266\n",
       "2      11.274390        1       4 -0.113255 -0.075087\n",
       "3      11.257898        1       5 -0.194624  0.211975\n",
       "8      10.145674        1       6  0.221690 -0.038337\n",
       "7       7.723774        1       7  0.180767  0.040339\n",
       "5       7.491034        1       8 -0.186793  0.228257\n",
       "6       7.316703        1       9 -0.088755 -0.303189\n",
       "0       7.198444        1      10  0.267245  0.155961, topic_info=     Category         Freq           Term        Total  loglift  logprob\n",
       "term                                                                    \n",
       "51    Default  3582.000000           love  3582.000000  30.0000  30.0000\n",
       "20    Default  1236.000000       daughter  1236.000000  29.0000  29.0000\n",
       "42    Default  1173.000000          great  1173.000000  28.0000  28.0000\n",
       "96    Default  1370.000000            toy  1370.000000  27.0000  27.0000\n",
       "0     Default  1342.000000             's  1342.000000  26.0000  26.0000\n",
       "70    Default   752.000000        qualiti   752.000000  25.0000  25.0000\n",
       "55    Default   903.000000            n't   903.000000  24.0000  24.0000\n",
       "19    Default   907.000000           cute   907.000000  23.0000  23.0000\n",
       "35    Default  1286.000000           good  1286.000000  22.0000  22.0000\n",
       "21    Default   561.000000  daughter love   561.000000  21.0000  21.0000\n",
       "98    Default  1611.000000           veri  1611.000000  20.0000  20.0000\n",
       "58    Default   637.000000            old   637.000000  19.0000  19.0000\n",
       "15    Default   503.000000       christma   503.000000  18.0000  18.0000\n",
       "103   Default   486.000000           year   486.000000  17.0000  17.0000\n",
       "87    Default   552.000000        squishi   552.000000  16.0000  16.0000\n",
       "48    Default  1135.000000          littl  1135.000000  15.0000  15.0000\n",
       "83    Default   518.000000          smell   518.000000  14.0000  14.0000\n",
       "6     Default   555.000000           babi   555.000000  13.0000  13.0000\n",
       "43    Default   419.000000          happi   419.000000  12.0000  12.0000\n",
       "45    Default   605.000000           just   605.000000  11.0000  11.0000\n",
       "39    Default   448.000000    granddaught   448.000000  10.0000  10.0000\n",
       "84    Default   869.000000           soft   869.000000   9.0000   9.0000\n",
       "68    Default   446.000000        product   446.000000   8.0000   8.0000\n",
       "47    Default   951.000000           like   951.000000   7.0000   7.0000\n",
       "104   Default   371.000000       year old   371.000000   6.0000   6.0000\n",
       "66    Default   400.000000        present   400.000000   5.0000   5.0000\n",
       "27    Default   367.000000            doe   367.000000   4.0000   4.0000\n",
       "22    Default   362.000000            day   362.000000   3.0000   3.0000\n",
       "33    Default   381.000000           gift   381.000000   2.0000   2.0000\n",
       "10    Default   905.000000         bought   905.000000   1.0000   1.0000\n",
       "...       ...          ...            ...          ...      ...      ...\n",
       "4     Topic10    10.028873            ani   201.498405  -0.3690  -5.8153\n",
       "48    Topic10    11.517135          littl  1135.610465  -1.9598  -5.6770\n",
       "10    Topic10     5.360635         bought   905.889911  -2.4985  -6.4417\n",
       "60    Topic10     0.100661          order   158.929085  -4.7332 -10.4168\n",
       "37    Topic10     0.100651      good size   162.577556  -4.7559 -10.4169\n",
       "97    Topic10     0.104753            use   170.809046  -4.7654 -10.3770\n",
       "100   Topic10     0.100647     veri happi   164.828665  -4.7697 -10.4170\n",
       "23    Topic10     0.100650        definit   167.279580  -4.7845 -10.4169\n",
       "102   Topic10     0.100648          worth   172.856781  -4.8173 -10.4169\n",
       "28    Topic10     0.100647        doe n't   181.555054  -4.8664 -10.4170\n",
       "32    Topic10     0.100650            fun   182.467921  -4.8714 -10.4169\n",
       "50    Topic10     0.100657            lot   184.149119  -4.8805 -10.4168\n",
       "2     Topic10     0.100655           ador   186.574885  -4.8936 -10.4169\n",
       "54    Topic10     0.100648          month   193.114575  -4.9281 -10.4169\n",
       "3     Topic10     0.100648           amaz   193.440836  -4.9298 -10.4169\n",
       "72    Topic10     0.100655           quit   194.153638  -4.9334 -10.4169\n",
       "13    Topic10     0.100653          child   194.487888  -4.9351 -10.4169\n",
       "68    Topic10     0.138210        product   446.065225  -5.4481 -10.0998\n",
       "44    Topic10     0.100870           item   283.033786  -5.3082 -10.4147\n",
       "5     Topic10     0.100791          arriv   525.267684  -5.9273 -10.4155\n",
       "12    Topic10     0.100695           came   333.164035  -5.4730 -10.4165\n",
       "77    Topic10     0.100682            say   260.458652  -5.2269 -10.4166\n",
       "31    Topic10     0.100670         friend   224.530652  -5.0786 -10.4167\n",
       "92    Topic10     0.100668          thing   203.705157  -4.9813 -10.4167\n",
       "56    Topic10     0.100665           nice   646.457696  -6.1362 -10.4168\n",
       "93    Topic10     0.100662          think   228.033011  -5.0942 -10.4168\n",
       "8     Topic10     0.100662       birthday   196.707640  -4.9464 -10.4168\n",
       "22    Topic10     0.100661            day   362.173716  -5.5568 -10.4168\n",
       "11    Topic10     0.100661            buy   375.544751  -5.5931 -10.4168\n",
       "1     Topic10     0.100661        absolut   235.115565  -5.1248 -10.4168\n",
       "\n",
       "[383 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "0         2  0.842274          's\n",
       "0         4  0.041704          's\n",
       "0         5  0.115431          's\n",
       "1         1  0.701783     absolut\n",
       "1         8  0.131850     absolut\n",
       "1         9  0.165876     absolut\n",
       "2         1  0.691411        ador\n",
       "2         7  0.133994        ador\n",
       "2         9  0.171513        ador\n",
       "3         1  0.077543        amaz\n",
       "3         4  0.811618        amaz\n",
       "3         6  0.108560        amaz\n",
       "4         2  0.635241         ani\n",
       "4         8  0.307695         ani\n",
       "4        10  0.049628         ani\n",
       "5         3  0.367432       arriv\n",
       "5         5  0.595887       arriv\n",
       "5         7  0.036172       arriv\n",
       "6         1  0.998593        babi\n",
       "7         1  0.078062         big\n",
       "7         2  0.565951         big\n",
       "7         6  0.148318         big\n",
       "7         8  0.206865         big\n",
       "8         2  0.533787    birthday\n",
       "8         8  0.462615    birthday\n",
       "9         2  0.498492         bit\n",
       "9         4  0.221552         bit\n",
       "9         5  0.205261         bit\n",
       "9        10  0.074937         bit\n",
       "10        1  0.176622      bought\n",
       "...     ...       ...         ...\n",
       "90       10  0.180082       teddi\n",
       "91        9  0.996608       thank\n",
       "92        4  0.068727       thing\n",
       "92        5  0.593996       thing\n",
       "92        7  0.333816       thing\n",
       "93        1  0.578864       think\n",
       "93        2  0.210496       think\n",
       "93        7  0.210496       think\n",
       "94        7  0.993825     thought\n",
       "95        5  0.861106        time\n",
       "95        7  0.137384        time\n",
       "96        1  0.452409         toy\n",
       "96        6  0.546539         toy\n",
       "97        1  0.825483         use\n",
       "97        5  0.169780         use\n",
       "98        2  0.253850        veri\n",
       "98        3  0.288607        veri\n",
       "98        4  0.159509        veri\n",
       "98        6  0.038481        veri\n",
       "98        9  0.259436        veri\n",
       "99        2  0.995982   veri cute\n",
       "100       9  0.994973  veri happi\n",
       "101       2  0.300800        want\n",
       "101       5  0.271374        want\n",
       "101       8  0.425043        want\n",
       "102       4  0.115703       worth\n",
       "102       5  0.098347       worth\n",
       "102       6  0.780993       worth\n",
       "103       7  0.997422        year\n",
       "104       7  0.998856    year old\n",
       "\n",
       "[273 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 5, 10, 3, 4, 9, 8, 6, 7, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2018-03-03 14:25:37.768915. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda, tf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2018-03-03 14:25:39.748119. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# #挑選特定條件(抽樣)\n",
    "# samples = ldaClusterframe[ldaClusterframe.loc[:,'ClusterLabel'] == 4][:441]\n",
    "# Rsamples = samples['review'].values\n",
    "# Rsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2018-03-03 14:25:39.758462. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# with open('../test.csv','w',encoding='utf-8') as f :\n",
    "#     f.write(str(Rsamples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
