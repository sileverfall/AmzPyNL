{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time            \n",
    "import re            \n",
    "import os    \n",
    "import sys  \n",
    "import codecs  \n",
    "import shutil  \n",
    "import nltk\n",
    "import numpy as np  \n",
    "import matplotlib  \n",
    "import scipy  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn import feature_extraction    \n",
    "from sklearn.feature_extraction.text import TfidfTransformer    \n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#title\n",
    "asins = open('../CategoryCluster/C10/In/pre/ASIN.csv').read().split('\\n')\n",
    "ASINs=[]\n",
    "for item in asins:\n",
    "    a = item.split(',')\n",
    "    ASINs += a\n",
    "# ASINs = ASINs[:-1]\n",
    "len(ASINs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#synopses\n",
    "review = open('../CategoryCluster/C10/In/pre/review.csv').read().split('\\n')\n",
    "review[0]\n",
    "Reviews=[]\n",
    "for rev in review:\n",
    "    a = rev.split('|')\n",
    "    Reviews += a \n",
    "Reviews = Reviews[:-1]\n",
    "len(Reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ranks\n",
    "ranks = open('../CategoryCluster/C10/In/pre/rank.csv').read().split('\\n')\n",
    "ranks[0] = ranks[0].replace('\\ufeff','')\n",
    "Rank =[]\n",
    "for rank in ranks:\n",
    "    a = rank.split(',')\n",
    "    Rank += a\n",
    "    \n",
    "Ranks =[float(i) for i in Rank]  \n",
    "Ranks[0]\n",
    "len(Ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 载入 nltk 的英文停用词作为“stopwords”变量\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 载入 nltk 的 SnowballStemmer 作为“stemmer”变量\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 这里我定义了一个分词器（tokenizer）和词干分析器（stemmer），它们会输出给定文本词干化后的词集合\n",
    " \n",
    "def tokenize_and_stem(text):\n",
    "    # 首先分句，接着分词，而标点也会作为词例存在\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # 过滤所有不含字母的词例（例如：数字、纯标点）\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    " \n",
    "def tokenize_only(text):\n",
    "    # 首先分句，接着分词，而标点也会作为词例存在\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # 过滤所有不含字母的词例（例如：数字、纯标点）\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 非常不 pythonic，一点也不！\n",
    "# 扩充列表后变成了非常庞大的二维（flat）词汇表\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in Reviews:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #对每个评价进行分词和词干化\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) # 扩充“totalvocab_stemmed”列表\n",
    " \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf and document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.6 s, sys: 34.9 ms, total: 3.64 s\n",
      "Wall time: 3.69 s\n",
      "CPU times: user 2.32 ms, sys: 463 µs, total: 2.78 ms\n",
      "Wall time: 2.5 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    " \n",
    "# 定义向量化参数\n",
    "#将文本中的词语转换为词频矩阵 矩阵元素a[i][j] 表示j词在第i类评论下的词频  \n",
    "vectorizer = CountVectorizer(max_df=0.98, max_features=200000,\n",
    "                                 min_df=0.02, stop_words='english',\n",
    "                                 tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "#该类会统计每个词语的tf-idf权值  \n",
    "transformer = TfidfTransformer() \n",
    "\n",
    "#第一个fit_transform是计算tf-idf 第二个fit_transform是将文本转为词频矩阵  \n",
    "%time tf =  vectorizer.fit_transform(Reviews)\n",
    "%time tfidf = transformer.fit_transform(tf) # 向量化\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'s\", 'amazon', 'awesom', 'babi', 'bad', 'bit', 'buy', 'color', 'colour', 'cute']\n"
     ]
    }
   ],
   "source": [
    "#获取词袋模型中的前10个词语 \n",
    "word = vectorizer.get_feature_names()\n",
    "print(word[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词袋模型中共有几个词语\n",
    "len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.20914305,  0.        ],\n",
       "       [ 0.41527425,  0.        ,  0.49553066, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.8747019 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将tf-idf矩阵抽取出来，元素w[i][j]表示j词在第i类评论中的tf-idf权重  \n",
    "weight = tfidf.toarray()  \n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7100, 56)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#词频矩阵\n",
    "tfidframe = pd.DataFrame(np.round(weight, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1     2    3    4     5    6     7    8    9  ...    46    47    48  \\\n",
       "0  0.00  0.0  0.00  0.0  0.0  0.23  0.2  0.22  0.0  0.0 ...   0.0  0.43  0.00   \n",
       "1  0.42  0.0  0.50  0.0  0.0  0.00  0.0  0.00  0.0  0.0 ...   0.0  0.00  0.00   \n",
       "2  0.00  0.0  0.87  0.0  0.0  0.00  0.0  0.00  0.0  0.0 ...   0.0  0.00  0.00   \n",
       "3  0.00  0.3  0.00  0.0  0.0  0.00  0.0  0.00  0.0  0.0 ...   0.0  0.33  0.65   \n",
       "4  0.00  0.0  0.00  0.0  0.0  0.00  0.0  0.00  0.0  0.0 ...   0.0  0.00  0.00   \n",
       "5  0.00  0.0  0.00  0.0  0.0  0.00  0.0  0.00  0.0  0.0 ...   0.0  0.00  0.00   \n",
       "6  0.00  0.0  0.00  0.0  0.0  0.00  0.0  0.00  0.0  0.0 ...   0.0  0.00  0.00   \n",
       "7  0.00  0.0  0.00  0.0  0.0  0.00  0.0  0.00  0.0  0.0 ...   0.0  0.00  0.00   \n",
       "8  0.00  0.0  0.00  0.0  0.0  0.00  0.0  0.00  0.0  0.0 ...   0.0  0.00  0.00   \n",
       "9  0.00  0.0  0.00  0.0  0.0  0.00  0.0  0.00  0.0  0.0 ...   0.0  0.00  0.00   \n",
       "\n",
       "    49   50    51    52   53    54   55  \n",
       "0  0.0  0.0  0.24  0.13  0.0  0.21  0.0  \n",
       "1  0.0  0.0  0.00  0.00  0.0  0.00  0.0  \n",
       "2  0.0  0.0  0.00  0.00  0.0  0.00  0.0  \n",
       "3  0.0  0.0  0.00  0.00  0.0  0.00  0.0  \n",
       "4  0.0  0.0  0.00  0.41  0.0  0.00  0.0  \n",
       "5  0.0  0.0  0.00  0.00  0.0  0.00  0.0  \n",
       "6  0.0  0.0  0.00  0.00  0.0  0.00  0.0  \n",
       "7  0.0  0.0  0.00  0.00  0.0  0.00  0.0  \n",
       "8  0.0  0.0  0.00  0.00  0.0  0.00  0.0  \n",
       "9  0.0  0.0  0.00  0.00  0.0  0.00  0.0  \n",
       "\n",
       "[10 rows x 56 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidframe[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(tfidf)\n",
    "dist = 1 - similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 1.          0.          0.43348624 ...,  1.          1.          1.        ]\n",
      " [ 1.          0.43348624  0.         ...,  1.          1.          1.        ]\n",
      " ..., \n",
      " [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 1.          1.          1.         ...,  1.          1.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7090</th>\n",
       "      <th>7091</th>\n",
       "      <th>7092</th>\n",
       "      <th>7093</th>\n",
       "      <th>7094</th>\n",
       "      <th>7095</th>\n",
       "      <th>7096</th>\n",
       "      <th>7097</th>\n",
       "      <th>7098</th>\n",
       "      <th>7099</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296496</td>\n",
       "      <td>0.143971</td>\n",
       "      <td>0.31469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.566514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102739</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181353</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.296496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.143971</td>\n",
       "      <td>0.102739</td>\n",
       "      <td>0.181353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.314690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 7100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4        5     6     7     \\\n",
       "0  1.000000  0.000000  0.000000  0.296496  0.143971  0.31469   0.0   0.0   \n",
       "1  0.000000  1.000000  0.566514  0.000000  0.102739  0.00000   0.0   0.0   \n",
       "2  0.000000  0.566514  1.000000  0.000000  0.181353  0.00000   0.0   0.0   \n",
       "3  0.296496  0.000000  0.000000  1.000000  0.000000  0.49780   0.0   0.0   \n",
       "4  0.143971  0.102739  0.181353  0.000000  1.000000  0.00000   0.0   0.0   \n",
       "5  0.314690  0.000000  0.000000  0.497800  0.000000  1.00000   0.0   0.0   \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   1.0   0.0   \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   0.0   0.0   \n",
       "8  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   0.0   0.0   \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   0.0   0.0   \n",
       "\n",
       "   8     9     ...       7090  7091  7092  7093  7094  7095  7096  7097  7098  \\\n",
       "0   0.0   0.0  ...   0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   0.0  ...   0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2   0.0   0.0  ...   0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3   0.0   0.0  ...   0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4   0.0   0.0  ...   0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "5   0.0   0.0  ...   0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "6   0.0   0.0  ...   0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "7   0.0   0.0  ...   0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "8   1.0   0.0  ...   0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "9   0.0   1.0  ...   0.600609   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   7099  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "5   0.0  \n",
       "6   0.0  \n",
       "7   0.0  \n",
       "8   0.0  \n",
       "9   0.0  \n",
       "\n",
       "[10 rows x 7100 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df = pd.DataFrame(similarity)\n",
    "similarity_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 416 ms, sys: 25.7 ms, total: 442 ms\n",
      "Wall time: 397 ms\n",
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=10, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans  \n",
    "num_clusters = 10\n",
    "km = KMeans(n_clusters=10)   \n",
    "%time s = km.fit(weight)  \n",
    "clusters = km.labels_.tolist()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "# 注释语句用来存储你的模型\n",
    "# 因为我已经从 pickle 载入过模型了\n",
    " \n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    " \n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toys = { 'title': ASINs, 'rank': Ranks, 'review': Reviews, 'cluster': clusters}\n",
    " \n",
    "frame = pd.DataFrame(toys , index = [clusters] , columns = ['rank', 'title', 'cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# frame[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frame['cluster'].value_counts() #number of review per cluster (clusters from 0 to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# km.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grouped = frame['rank'].groupby(frame['cluster']) # 为了凝聚（aggregation），由聚类分类。\n",
    " \n",
    "# grouped.mean() # 每个聚类的平均排名（0 到 5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    " \n",
    "# print(\"Top terms per cluster:\")\n",
    "# print()\n",
    "# # 按离质心的距离排列聚类中心，由近到远\n",
    "# order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    " \n",
    "# for i in range(num_clusters):\n",
    "#     print(\"Cluster %d titles:\" % i, end='')\n",
    "#     for title in frame.ix[i]['title'].values.tolist():\n",
    "#         print(' %s,' % title, end='')\n",
    "#     print() # 空行\n",
    "#     print() # 空行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    " \n",
    "# print(\"Top terms per cluster:\")\n",
    "# print()\n",
    "# # 按离质心的距离排列聚类中心，由近到远\n",
    "# order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "# # print(order_centroids)\n",
    "# for i in range(num_clusters):\n",
    "#     print(\"Cluster %d:\" % i, end='')\n",
    "#     time.sleep(1)\n",
    "#     for ind in order_centroids[i, :50]: # 每个聚类选 10 个词\n",
    "#         print(' %s' % word[ind]  , end=',')\n",
    "#     print() # 空行\n",
    "#     print() # 空行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_topics = 10\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=50,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.2 s, sys: 168 ms, total: 33.4 s\n",
      "Wall time: 33.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=50, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=1, n_topics=10, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lda.fit(tf) #tf 为向量化后的语料词集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.2 s, sys: 210 ms, total: 34.5 s\n",
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%time lda_matrix = lda.fit_transform(tf) #tf 为向量化后的语料词集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00500022,  0.00500001,  0.00500153, ...,  0.9549917 ,\n",
       "         0.00500105,  0.00500247],\n",
       "       [ 0.84998967,  0.01666667,  0.01666667, ...,  0.01666667,\n",
       "         0.0166678 ,  0.01666726],\n",
       "       [ 0.69997989,  0.03333333,  0.03333333, ...,  0.03333333,\n",
       "         0.03333828,  0.03333672],\n",
       "       ..., \n",
       "       [ 0.1       ,  0.1       ,  0.1       , ...,  0.1       ,\n",
       "         0.1       ,  0.1       ],\n",
       "       [ 0.1       ,  0.1       ,  0.1       , ...,  0.1       ,\n",
       "         0.1       ,  0.1       ],\n",
       "       [ 0.1       ,  0.1       ,  0.1       , ...,  0.1       ,\n",
       "         0.1       ,  0.1       ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_matrix #表示每一個文檔屬於每一個聚類的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(lda_matrix, columns=['T1', 'T2', 'T3','T4','T5','T6','T7','T8','T9','T10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.954992</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.005002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.849990</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.016669</td>\n",
       "      <td>0.016668</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016668</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.699980</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.033344</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.033337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.566666</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.011112</td>\n",
       "      <td>0.344443</td>\n",
       "      <td>0.011111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>0.819964</td>\n",
       "      <td>0.020013</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020006</td>\n",
       "      <td>0.020004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         T1        T2        T3        T4        T5        T6        T7  \\\n",
       "0  0.005000  0.005000  0.005002  0.005001  0.005001  0.005001  0.005000   \n",
       "1  0.849990  0.016667  0.016667  0.016667  0.016671  0.016669  0.016668   \n",
       "2  0.699980  0.033333  0.033333  0.033333  0.033333  0.033335  0.033344   \n",
       "3  0.011111  0.011111  0.011111  0.566666  0.011111  0.011111  0.011111   \n",
       "4  0.020007  0.020000  0.020000  0.020004  0.020001  0.819964  0.020013   \n",
       "\n",
       "         T8        T9       T10  \n",
       "0  0.954992  0.005001  0.005002  \n",
       "1  0.016667  0.016668  0.016667  \n",
       "2  0.033333  0.033338  0.033337  \n",
       "3  0.011112  0.344443  0.011111  \n",
       "4  0.020000  0.020006  0.020004  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 185 ms, sys: 14.1 ms, total: 199 ms\n",
      "Wall time: 189 ms\n"
     ]
    }
   ],
   "source": [
    "%time km_lda =km.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_labels = km.labels_\n",
    "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rank</th>\n",
       "      <th>review</th>\n",
       "      <th>ClusterLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B075BKMW23_1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>\" Very good quality teddy, soft and size is 3 ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B075BKMW23_2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It's awesome product, great value for the mone...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B075BKMW23_3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>mention proper description in product or else ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B075BKMW23_4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Awsome. I got the same teddy bear as shown in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B075BKMW23_5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The product was just as described. Very soft n...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          title  rank                                             review  \\\n",
       "0  B075BKMW23_1   5.0  \" Very good quality teddy, soft and size is 3 ...   \n",
       "1  B075BKMW23_2   5.0  It's awesome product, great value for the mone...   \n",
       "2  B075BKMW23_3   4.0  mention proper description in product or else ...   \n",
       "3  B075BKMW23_4   5.0  Awsome. I got the same teddy bear as shown in ...   \n",
       "4  B075BKMW23_5   4.0  The product was just as described. Very soft n...   \n",
       "\n",
       "   ClusterLabel  \n",
       "0             6  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             8  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaframe = pd.DataFrame({ 'title': ASINs, 'rank': Ranks, 'review': Reviews})\n",
    "ldaframe = ldaframe[['title','rank','review']]\n",
    "ldaClusterframe = pd.concat([ldaframe, cluster_labels], axis=1)\n",
    "ldaClusterframe[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1987\n",
       "4    1200\n",
       "3     670\n",
       "7     558\n",
       "2     534\n",
       "8     499\n",
       "6     416\n",
       "9     415\n",
       "5     411\n",
       "0     410\n",
       "Name: ClusterLabel, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaClusterframe['ClusterLabel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClusterLabel\n",
       "0    4.134146\n",
       "1    1.400101\n",
       "2    3.239700\n",
       "3    4.291045\n",
       "4    3.611667\n",
       "5    4.783455\n",
       "6    2.884615\n",
       "7    3.354839\n",
       "8    4.214429\n",
       "9    3.291566\n",
       "Name: rank, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rankgrouped = ldaClusterframe['rank'].groupby(ldaClusterframe['ClusterLabel']) # 为了凝聚（aggregation），由聚类分类。\n",
    " \n",
    "Rankgrouped.mean() # 每个聚类的平均排名（0 到 5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7100.000000\n",
       "mean        3.087746\n",
       "std         1.933838\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         4.000000\n",
       "75%         5.000000\n",
       "max         5.000000\n",
       "Name: rank, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaClusterframe['rank'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rank</th>\n",
       "      <th>review</th>\n",
       "      <th>ClusterLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4112</th>\n",
       "      <td>B0753JWCZD_3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>mention proper description in product or else ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>B01N00ZRE4_3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4701</th>\n",
       "      <td>B072DZ63LW_2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Too good....larger than expected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>B075P6RNTL_6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Wow awsm product I really like it 😁 thanks to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5125</th>\n",
       "      <td>B01GCPZOZM_6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good delivered as expected. Children happy.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4670</th>\n",
       "      <td>B01N0Z2TDI_1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great product and totally worth the price. Goo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4666</th>\n",
       "      <td>B072LCWMFR_7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Its good as i had expected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>B0716S97FM_8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Its good as i had expected</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6250</th>\n",
       "      <td>B072LCWMFR_1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gud job .!Delivery was 2 day before scheduled ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>B072LCWMFR_3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Reached the expectations</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title  rank                                             review  \\\n",
       "4112  B0753JWCZD_3   4.0  mention proper description in product or else ...   \n",
       "5112  B01N00ZRE4_3   5.0                                   It's really good   \n",
       "4701  B072DZ63LW_2   5.0                   Too good....larger than expected   \n",
       "1645  B075P6RNTL_6   5.0  Wow awsm product I really like it 😁 thanks to ...   \n",
       "5125  B01GCPZOZM_6   4.0        Good delivered as expected. Children happy.   \n",
       "4670  B01N0Z2TDI_1   5.0  Great product and totally worth the price. Goo...   \n",
       "4666  B072LCWMFR_7   4.0                         Its good as i had expected   \n",
       "2557  B0716S97FM_8   4.0                         Its good as i had expected   \n",
       "6250  B072LCWMFR_1   5.0  Gud job .!Delivery was 2 day before scheduled ...   \n",
       "6252  B072LCWMFR_3   4.0                           Reached the expectations   \n",
       "\n",
       "      ClusterLabel  \n",
       "4112             0  \n",
       "5112             0  \n",
       "4701             0  \n",
       "1645             0  \n",
       "5125             0  \n",
       "4670             0  \n",
       "4666             0  \n",
       "2557             0  \n",
       "6250             0  \n",
       "6252             0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#排序\n",
    "ldaClusterframe.sort_values(by = 'ClusterLabel')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " product, expect, realli, awesom, great, order, stitch, 's, good, deliv, price, money, got, happi, qualiti, like, veri, amazon, worth, bit, shown, differ, just, cute, look, good product, babi, bad, littl, size,\n",
      "\n",
      " love, gift, excel, littl, color, product, babi, veri, kid, buy, realli, qualiti, just, good, awesom, teddi, soft, price, worth, cute, veri good, thank, got, toy, amazon, great, time, size, like, look,\n",
      "\n",
      " small, kid, size, good, happi, babi, littl, use, bit, soft, veri, price, time, good product, product, like, look, 's, toy, just, qualiti, gift, worth, stitch, receiv, materi, thank, money, realli, amazon,\n",
      "\n",
      " amazon, thank, receiv, got, teddi, just, shown, excel, product, veri, deliv, shown pictur, time, pictur, 's, order, love, awesom, happi, good, look, like, bad, qualiti, realli, good qualiti, size, cute, great, gift,\n",
      "\n",
      " toy, like, worth, colour, veri, money, soft, look, babi, buy, price, got, bad, happi, good, 's, amazon, qualiti, product, kid, just, order, doe, deliv, stitch, n't, littl, size, cute, small,\n",
      "\n",
      " veri, cute, soft, 's, veri cute, just, product, realli, price, buy, kid, got, worth, look, good, doe, love, babi, size, use, good product, littl, toy, teddi, money, gift, colour, stitch, materi, veri good,\n",
      "\n",
      " nice, product, time, nice product, veri, amazon, deliv, price, excel, happi, kid, buy, soft, got, qualiti, good, qualiti product, colour, 's, gift, money, littl, differ, materi, size, good qualiti, color, shown, thank, order,\n",
      "\n",
      " n't, differ, buy, color, pictur, materi, look, qualiti, like, teddi, veri, bit, shown, good, use, soft, size, veri good, got, good qualiti, doe, deliv, product, 's, just, time, stitch, great, bad, toy,\n",
      "\n",
      " good, shown, product, look, pictur, doe, good product, shown pictur, price, 's, like, n't, colour, babi, veri, qualiti, littl, size, bit, great, veri good, got, differ, deliv, cute, receiv, color, worth, stitch, kid,\n",
      "\n",
      " good, qualiti, veri, product, good qualiti, bad, veri good, qualiti product, price, good product, buy, excel, materi, receiv, deliv, babi, stitch, money, gift, soft, just, use, look, great, order, got, toy, 's, realli, happi,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    " \n",
    "order_centroids =  lda.components_.argsort()[:, ::-1] \n",
    "# print(order_centroids)\n",
    "\n",
    "for i in range(num_clusters):\n",
    "#     print(\"Cluster %d:\" % i, end='\\n')\n",
    "    time.sleep(1)\n",
    "    for ind in order_centroids[i, :30]: # 每个聚类选 30 个词\n",
    "        print(' %s' % word[ind], end=',')\n",
    "        \n",
    "        \n",
    "    print() # 空行\n",
    "    print() # 空行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36, 14, 39,  2, 20, 33, 46,  0, 16, 10, 35, 29, 19, 21, 37, 24, 52,\n",
       "         1, 55,  5, 41, 11, 22,  9, 26, 17,  3,  4, 25, 43, 34,  7, 30, 15,\n",
       "        40, 44, 28,  8, 47,  6, 48, 38, 50, 45, 12, 49, 51, 18, 23, 31, 27,\n",
       "        13, 42, 54, 32, 53],\n",
       "       [27, 15, 13, 25,  7, 36,  3, 52, 23,  6, 39, 37, 22, 16,  2, 47, 45,\n",
       "        35, 55,  9, 54, 48, 19, 50,  1, 20, 49, 43, 24, 26, 28, 41, 21,  5,\n",
       "         0, 40, 31, 53, 46, 17, 12, 44, 18, 51, 34, 30, 38, 29, 32, 14, 33,\n",
       "        10,  4, 42,  8, 11],\n",
       "       [44, 23, 43, 16, 21,  3, 25, 51,  5, 45, 52, 35, 49, 17, 36, 24, 26,\n",
       "         0, 50, 22, 37, 15, 55, 46, 40, 28, 48, 29, 39,  1, 14,  9, 31, 12,\n",
       "        19, 30, 27, 38,  4, 47, 41, 18, 33, 20,  6,  8,  7,  2, 32, 13, 34,\n",
       "        10, 54, 53, 11, 42],\n",
       "       [ 1, 48, 40, 19, 47, 22, 41, 13, 36, 52, 10, 42, 49, 34,  0, 33, 27,\n",
       "         2, 21, 16, 26, 24,  4, 37, 39, 18, 43,  9, 20, 15,  7, 30, 35, 38,\n",
       "        25, 29, 12,  6,  3, 44, 28,  8, 50, 23, 45, 55, 46, 11, 17, 14, 31,\n",
       "        54, 51,  5, 53, 32],\n",
       "       [50, 24, 55,  8, 52, 29, 45, 26,  3,  6, 35, 19,  4, 21, 16,  0,  1,\n",
       "        37, 36, 23, 22, 33, 12, 10, 46, 30, 25, 43,  9, 44, 39, 28, 11, 31,\n",
       "        51,  5, 49, 41, 20, 27, 15, 53,  7, 48, 14, 40, 54, 34, 17, 13, 42,\n",
       "        18, 47, 32,  2, 38],\n",
       "       [52,  9, 45,  0, 53, 22, 36, 39, 35,  6, 23, 19, 55, 26, 16, 12, 27,\n",
       "         3, 43, 51, 17, 25, 50, 47, 29, 15,  8, 46, 28, 54, 37, 24, 31, 44,\n",
       "        30, 10,  1, 21,  7, 33, 34,  2, 41,  4, 20, 48, 49, 40, 18, 14, 38,\n",
       "        32, 11, 42,  5, 13],\n",
       "       [31, 36, 49, 32, 52,  1, 10, 35, 13, 21, 23,  6, 45, 19, 37, 16, 38,\n",
       "         8,  0, 15, 29, 25, 11, 28, 43, 18,  7, 41, 48, 33, 44, 50, 39, 26,\n",
       "         3, 27, 22,  2, 17, 12, 40, 55, 24, 47, 14, 30, 46,  9,  5, 53, 54,\n",
       "        20,  4, 34, 51, 42],\n",
       "       [30, 11,  6,  7, 34, 28, 26, 37, 24, 47, 52,  5, 41, 16, 51, 45, 43,\n",
       "        54, 19, 18, 12, 10, 36,  0, 22, 49, 46, 20,  4, 50,  8, 33, 39, 44,\n",
       "        35, 42,  1, 40,  3, 14,  9, 23, 38, 21, 31, 55, 29, 27,  2, 25, 15,\n",
       "        17, 13, 48, 53, 32],\n",
       "       [16, 41, 36, 26, 34, 12, 17, 42, 35,  0, 24, 30,  8,  3, 52, 37, 25,\n",
       "        43,  5, 20, 54, 19, 11, 10,  9, 40,  7, 55, 46, 23, 45, 44, 28, 14,\n",
       "        48, 39,  4, 49, 50, 51, 22, 47,  1,  6, 31, 29, 21, 33, 15, 27,  2,\n",
       "        13, 38, 18, 53, 32],\n",
       "       [16, 37, 52, 36, 18,  4, 54, 38, 35, 17,  6, 13, 28, 40, 10,  3, 46,\n",
       "        29, 15, 45, 22, 51, 26, 20, 33, 19, 50,  0, 39, 21,  1, 24, 14, 55,\n",
       "        43, 41, 44, 49, 23, 11, 53, 30,  7,  8, 27, 25,  2,  5, 47, 31, 12,\n",
       "        48,  9, 34, 42, 32]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ftf = transformer.fit_transform(order_centroids)\n",
    "ftf = ftf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9   ...     46  \\\n",
       "0  0.15  0.06  0.16  0.01  0.08  0.14  0.19  0.00  0.07  0.05  ...   0.21   \n",
       "1  0.11  0.06  0.05  0.11  0.03  0.15  0.01  0.23  0.09  0.03  ...   0.16   \n",
       "2  0.18  0.09  0.18  0.07  0.09  0.01  0.10  0.23  0.02  0.20  ...   0.03   \n",
       "3  0.00  0.20  0.17  0.09  0.19  0.09  0.17  0.06  0.15  0.24  ...   0.19   \n",
       "4  0.21  0.10  0.23  0.04  0.21  0.12  0.19  0.12  0.01  0.03  ...   0.22   \n",
       "\n",
       "     47    48    49    50    51    52    53    54    55  \n",
       "0  0.07  0.10  0.13  0.11  0.05  0.17  0.22  0.13  0.22  \n",
       "1  0.12  0.13  0.06  0.13  0.04  0.02  0.17  0.03  0.04  \n",
       "2  0.01  0.13  0.05  0.14  0.04  0.22  0.22  0.05  0.17  \n",
       "3  0.05  0.07  0.06  0.13  0.22  0.21  0.02  0.22  0.13  \n",
       "4  0.14  0.07  0.05  0.17  0.07  0.19  0.13  0.01  0.16  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#词频矩阵\n",
    "tfidMMframe = pd.DataFrame(np.round(ftf, 2))\n",
    "tfidMMframe[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " product, 48.302188, 0.120000, 1.000000, 0.120000\n",
      " expect, 0.100002, 0.170000, 1.000000, 0.170000\n",
      " realli, 0.100006, 0.020000, 1.000000, 0.020000\n",
      " awesom, 0.100012, 0.160000, 1.000000, 0.160000\n",
      " great, 0.100020, 0.170000, 1.000000, 0.170000\n",
      " order, 0.100001, 0.060000, 0.860000, 0.069767\n",
      " stitch, 0.100006, 0.210000, 1.000000, 0.210000\n",
      " 's, 0.100012, 0.150000, 1.000000, 0.150000\n",
      " good, 0.100008, 0.220000, 1.000000, 0.220000\n",
      " deliv, 0.100010, 0.140000, 1.000000, 0.140000\n",
      " price, 0.100008, 0.180000, 1.000000, 0.180000\n",
      " money, 0.100007, 0.180000, 1.000000, 0.180000\n",
      " got, 0.100004, 0.020000, 1.000000, 0.020000\n",
      " happi, 204.088632, 0.050000, 1.000000, 0.050000\n",
      " qualiti, 369.032063, 0.030000, 1.000000, 0.030000\n",
      " like, 0.100004, 0.110000, 1.000000, 0.110000\n",
      " veri, 0.100005, 0.170000, 1.000000, 0.170000\n",
      " amazon, 154.182994, 0.060000, 0.850000, 0.070588\n",
      " worth, 0.100002, 0.220000, 1.000000, 0.220000\n",
      " bit, 0.100009, 0.140000, 1.000000, 0.140000\n",
      " shown, 0.100008, 0.160000, 1.000000, 0.160000\n",
      " differ, 83.005694, 0.120000, 1.000000, 0.120000\n",
      " just, 0.100018, 0.090000, 1.000000, 0.090000\n",
      " cute, 0.100007, 0.050000, 1.000000, 0.050000\n",
      " look, 0.100009, 0.010000, 1.000000, 0.010000\n",
      " good product, 128.219630, 0.000000, 0.780000, 0.000000\n",
      " babi, 221.568225, 0.010000, 1.000000, 0.010000\n",
      " bad, 0.100009, 0.080000, 1.000000, 0.080000\n",
      " littl, 0.100014, 0.070000, 0.900000, 0.077778\n",
      " size, 0.100002, 0.190000, 1.000000, 0.190000\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      " love, 0.100006, 0.190000, 1.000000, 0.190000\n",
      " gift, 0.100002, 0.210000, 1.000000, 0.210000\n",
      " excel, 0.100003, 0.070000, 1.000000, 0.070000\n",
      " littl, 0.100006, 0.080000, 0.900000, 0.088889\n",
      " color, 0.100017, 0.230000, 1.000000, 0.230000\n",
      " product, 0.100010, 0.130000, 1.000000, 0.130000\n",
      " babi, 0.100011, 0.110000, 1.000000, 0.110000\n",
      " veri, 0.100003, 0.020000, 1.000000, 0.020000\n",
      " kid, 0.100016, 0.220000, 0.870000, 0.252874\n",
      " buy, 0.100006, 0.010000, 1.000000, 0.010000\n",
      " realli, 0.100002, 0.070000, 1.000000, 0.070000\n",
      " qualiti, 0.100658, 0.220000, 1.000000, 0.220000\n",
      " just, 0.100006, 0.080000, 1.000000, 0.080000\n",
      " good, 252.892268, 0.180000, 1.000000, 0.180000\n",
      " awesom, 0.100006, 0.050000, 1.000000, 0.050000\n",
      " teddi, 0.100004, 0.120000, 1.000000, 0.120000\n",
      " soft, 0.100003, 0.120000, 1.000000, 0.120000\n",
      " price, 0.100003, 0.160000, 1.000000, 0.160000\n",
      " worth, 0.100009, 0.040000, 1.000000, 0.040000\n",
      " cute, 0.100000, 0.030000, 1.000000, 0.030000\n",
      " veri good, 0.100005, 0.030000, 0.770000, 0.038961\n",
      " thank, 0.100011, 0.130000, 1.000000, 0.130000\n",
      " got, 0.100003, 0.040000, 1.000000, 0.040000\n",
      " toy, 0.100006, 0.130000, 1.000000, 0.130000\n",
      " amazon, 0.100006, 0.060000, 0.850000, 0.070588\n",
      " great, 0.100007, 0.220000, 1.000000, 0.220000\n",
      " time, 0.100008, 0.060000, 0.880000, 0.068182\n",
      " size, 0.100000, 0.210000, 1.000000, 0.210000\n",
      " like, 0.100017, 0.000000, 1.000000, 0.000000\n",
      " look, 36.364254, 0.200000, 1.000000, 0.200000\n",
      "\n",
      "\n",
      "Cluster 2:\n",
      " small, 339.647371, 0.020000, 1.000000, 0.020000\n",
      " kid, 0.100014, 0.210000, 0.870000, 0.241379\n",
      " size, 0.100001, 0.080000, 1.000000, 0.080000\n",
      " good, 0.100012, 0.110000, 1.000000, 0.110000\n",
      " happi, 0.100004, 0.060000, 1.000000, 0.060000\n",
      " babi, 0.100003, 0.070000, 1.000000, 0.070000\n",
      " littl, 0.100016, 0.110000, 0.900000, 0.122222\n",
      " use, 0.100015, 0.040000, 0.870000, 0.045977\n",
      " bit, 0.100005, 0.010000, 1.000000, 0.010000\n",
      " soft, 422.402588, 0.030000, 1.000000, 0.030000\n",
      " veri, 102.760867, 0.220000, 1.000000, 0.220000\n",
      " price, 0.100003, 0.120000, 1.000000, 0.120000\n",
      " time, 0.100010, 0.050000, 0.880000, 0.056818\n",
      " good product, 231.986529, 0.000000, 0.780000, 0.000000\n",
      " product, 0.100019, 0.110000, 1.000000, 0.110000\n",
      " like, 360.484748, 0.160000, 1.000000, 0.160000\n",
      " look, 114.556648, 0.200000, 1.000000, 0.200000\n",
      " 's, 0.100012, 0.180000, 1.000000, 0.180000\n",
      " toy, 0.100017, 0.140000, 1.000000, 0.140000\n",
      " just, 184.312477, 0.230000, 1.000000, 0.230000\n",
      " qualiti, 0.100016, 0.160000, 1.000000, 0.160000\n",
      " gift, 0.100008, 0.110000, 1.000000, 0.110000\n",
      " worth, 0.100002, 0.170000, 1.000000, 0.170000\n",
      " stitch, 75.993105, 0.030000, 1.000000, 0.030000\n",
      " receiv, 0.100008, 0.170000, 1.000000, 0.170000\n",
      " materi, 0.100006, 0.160000, 1.000000, 0.160000\n",
      " thank, 0.100005, 0.130000, 1.000000, 0.130000\n",
      " money, 0.100011, 0.000000, 1.000000, 0.000000\n",
      " realli, 0.100006, 0.190000, 1.000000, 0.190000\n",
      " amazon, 0.100015, 0.090000, 0.850000, 0.105882\n",
      "\n",
      "\n",
      "Cluster 3:\n",
      " amazon, 0.100013, 0.200000, 0.850000, 0.235294\n",
      " thank, 216.155080, 0.070000, 1.000000, 0.070000\n",
      " receiv, 0.100009, 0.120000, 1.000000, 0.120000\n",
      " got, 0.100009, 0.070000, 1.000000, 0.070000\n",
      " teddi, 0.100005, 0.050000, 1.000000, 0.050000\n",
      " just, 0.100012, 0.020000, 1.000000, 0.020000\n",
      " shown, 233.884122, 0.030000, 1.000000, 0.030000\n",
      " excel, 0.100007, 0.140000, 1.000000, 0.140000\n",
      " product, 0.100008, 0.050000, 1.000000, 0.050000\n",
      " veri, 0.100003, 0.210000, 1.000000, 0.210000\n",
      " deliv, 0.100009, 0.040000, 1.000000, 0.040000\n",
      " shown pictur, 0.100035, 0.210000, 0.650000, 0.323077\n",
      " time, 283.716908, 0.060000, 0.880000, 0.068182\n",
      " pictur, 0.100013, 0.110000, 1.000000, 0.110000\n",
      " 's, 0.100005, 0.000000, 1.000000, 0.000000\n",
      " order, 0.100001, 0.160000, 0.860000, 0.186047\n",
      " love, 0.100010, 0.040000, 1.000000, 0.040000\n",
      " awesom, 296.972793, 0.170000, 1.000000, 0.170000\n",
      " happi, 0.100009, 0.100000, 1.000000, 0.100000\n",
      " good, 0.100009, 0.110000, 1.000000, 0.110000\n",
      " look, 0.100008, 0.180000, 1.000000, 0.180000\n",
      " like, 0.100006, 0.160000, 1.000000, 0.160000\n",
      " bad, 0.100007, 0.190000, 1.000000, 0.190000\n",
      " qualiti, 0.100022, 0.020000, 1.000000, 0.020000\n",
      " realli, 0.100008, 0.180000, 1.000000, 0.180000\n",
      " good qualiti, 0.100005, 0.100000, 0.740000, 0.135135\n",
      " size, 0.100019, 0.100000, 1.000000, 0.100000\n",
      " cute, 0.100006, 0.240000, 1.000000, 0.240000\n",
      " great, 228.531508, 0.110000, 1.000000, 0.110000\n",
      " gift, 0.100003, 0.150000, 1.000000, 0.150000\n",
      "\n",
      "\n",
      "Cluster 4:\n",
      " toy, 0.100007, 0.170000, 1.000000, 0.170000\n",
      " like, 0.100015, 0.190000, 1.000000, 0.190000\n",
      " worth, 0.100003, 0.160000, 1.000000, 0.160000\n",
      " colour, 0.100004, 0.010000, 1.000000, 0.010000\n",
      " veri, 0.100008, 0.190000, 1.000000, 0.190000\n",
      " money, 0.100009, 0.180000, 1.000000, 0.180000\n",
      " soft, 0.100010, 0.170000, 1.000000, 0.170000\n",
      " look, 0.100011, 0.100000, 1.000000, 0.100000\n",
      " babi, 0.100001, 0.040000, 1.000000, 0.040000\n",
      " buy, 0.100008, 0.190000, 1.000000, 0.190000\n",
      " price, 0.100003, 0.020000, 1.000000, 0.020000\n",
      " got, 0.100003, 0.090000, 1.000000, 0.090000\n",
      " bad, 86.083260, 0.210000, 1.000000, 0.210000\n",
      " happi, 0.100007, 0.140000, 1.000000, 0.140000\n",
      " good, 0.100006, 0.000000, 1.000000, 0.000000\n",
      " 's, 301.677947, 0.210000, 1.000000, 0.210000\n",
      " amazon, 0.100016, 0.100000, 0.850000, 0.117647\n",
      " qualiti, 0.100015, 0.170000, 1.000000, 0.170000\n",
      " product, 0.122584, 0.200000, 1.000000, 0.200000\n",
      " kid, 0.100014, 0.050000, 0.870000, 0.057471\n",
      " just, 0.100019, 0.050000, 1.000000, 0.050000\n",
      " order, 0.100001, 0.130000, 0.860000, 0.151163\n",
      " doe, 0.100009, 0.020000, 1.000000, 0.020000\n",
      " deliv, 0.100010, 0.140000, 1.000000, 0.140000\n",
      " stitch, 145.983026, 0.220000, 1.000000, 0.220000\n",
      " n't, 171.133593, 0.160000, 1.000000, 0.160000\n",
      " littl, 349.785978, 0.120000, 0.900000, 0.133333\n",
      " size, 0.100003, 0.200000, 1.000000, 0.200000\n",
      " cute, 227.754676, 0.030000, 1.000000, 0.030000\n",
      " small, 0.100011, 0.060000, 1.000000, 0.060000\n",
      "\n",
      "\n",
      "Cluster 5:\n",
      " veri, 0.100011, 0.050000, 1.000000, 0.050000\n",
      " cute, 0.100009, 0.030000, 1.000000, 0.030000\n",
      " soft, 0.100008, 0.200000, 1.000000, 0.200000\n",
      " 's, 0.100020, 0.210000, 1.000000, 0.210000\n",
      " veri cute, 576.286692, 0.170000, 0.720000, 0.236111\n",
      " just, 0.100007, 0.210000, 1.000000, 0.210000\n",
      " product, 15.931134, 0.000000, 1.000000, 0.000000\n",
      " realli, 0.100002, 0.140000, 1.000000, 0.140000\n",
      " price, 0.100006, 0.040000, 1.000000, 0.040000\n",
      " buy, 0.100001, 0.150000, 1.000000, 0.150000\n",
      " kid, 107.627510, 0.210000, 0.870000, 0.241379\n",
      " got, 0.100002, 0.210000, 1.000000, 0.210000\n",
      " worth, 0.100008, 0.050000, 1.000000, 0.050000\n",
      " look, 0.100010, 0.030000, 1.000000, 0.030000\n",
      " good, 0.100010, 0.110000, 1.000000, 0.110000\n",
      " doe, 0.100002, 0.230000, 1.000000, 0.230000\n",
      " love, 0.100018, 0.210000, 1.000000, 0.210000\n",
      " babi, 0.100004, 0.000000, 1.000000, 0.000000\n",
      " size, 0.100001, 0.020000, 1.000000, 0.020000\n",
      " use, 0.100010, 0.130000, 0.870000, 0.149425\n",
      " good product, 0.100017, 0.010000, 0.780000, 0.012821\n",
      " littl, 0.100008, 0.060000, 0.900000, 0.066667\n",
      " toy, 0.100003, 0.160000, 1.000000, 0.160000\n",
      " teddi, 0.100009, 0.160000, 1.000000, 0.160000\n",
      " money, 0.100009, 0.220000, 1.000000, 0.220000\n",
      " gift, 0.100002, 0.050000, 1.000000, 0.050000\n",
      " colour, 0.100006, 0.140000, 1.000000, 0.140000\n",
      " stitch, 338.153624, 0.200000, 1.000000, 0.200000\n",
      " materi, 0.100013, 0.120000, 1.000000, 0.120000\n",
      " veri good, 159.562342, 0.020000, 0.770000, 0.025974\n",
      "\n",
      "\n",
      "Cluster 6:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nice, 0.100003, 0.210000, 1.000000, 0.210000\n",
      " product, 40.572881, 0.090000, 1.000000, 0.090000\n",
      " time, 0.100007, 0.220000, 0.880000, 0.250000\n",
      " nice product, 726.123654, 0.160000, 0.750000, 0.213333\n",
      " veri, 0.100002, 0.020000, 1.000000, 0.020000\n",
      " amazon, 0.100010, 0.150000, 0.850000, 0.176471\n",
      " deliv, 0.100003, 0.100000, 1.000000, 0.100000\n",
      " price, 0.100002, 0.110000, 1.000000, 0.110000\n",
      " excel, 0.100005, 0.080000, 1.000000, 0.080000\n",
      " happi, 0.100002, 0.100000, 1.000000, 0.100000\n",
      " kid, 0.100006, 0.130000, 0.870000, 0.149425\n",
      " buy, 0.100002, 0.040000, 1.000000, 0.040000\n",
      " soft, 0.100007, 0.120000, 1.000000, 0.120000\n",
      " got, 0.100008, 0.060000, 1.000000, 0.060000\n",
      " qualiti, 589.675490, 0.010000, 1.000000, 0.010000\n",
      " good, 0.100010, 0.160000, 1.000000, 0.160000\n",
      " qualiti product, 0.100012, 0.070000, 0.790000, 0.088608\n",
      " colour, 0.100008, 0.050000, 1.000000, 0.050000\n",
      " 's, 0.100005, 0.130000, 1.000000, 0.130000\n",
      " gift, 0.100004, 0.070000, 1.000000, 0.070000\n",
      " money, 0.100009, 0.140000, 1.000000, 0.140000\n",
      " littl, 0.100004, 0.070000, 0.900000, 0.077778\n",
      " differ, 69.178095, 0.020000, 1.000000, 0.020000\n",
      " materi, 0.100006, 0.200000, 1.000000, 0.200000\n",
      " size, 0.100000, 0.190000, 1.000000, 0.190000\n",
      " good qualiti, 0.100005, 0.000000, 0.740000, 0.000000\n",
      " color, 0.100016, 0.160000, 1.000000, 0.160000\n",
      " shown, 0.100005, 0.230000, 1.000000, 0.230000\n",
      " thank, 0.100004, 0.020000, 1.000000, 0.020000\n",
      " order, 179.145328, 0.110000, 0.860000, 0.127907\n",
      "\n",
      "\n",
      "Cluster 7:\n",
      " n't, 0.100004, 0.030000, 1.000000, 0.030000\n",
      " differ, 0.100020, 0.020000, 1.000000, 0.020000\n",
      " buy, 75.689870, 0.110000, 1.000000, 0.110000\n",
      " color, 237.616075, 0.170000, 1.000000, 0.170000\n",
      " pictur, 0.100009, 0.160000, 1.000000, 0.160000\n",
      " materi, 0.100004, 0.020000, 1.000000, 0.020000\n",
      " look, 0.100002, 0.190000, 1.000000, 0.190000\n",
      " qualiti, 0.100016, 0.160000, 1.000000, 0.160000\n",
      " like, 0.100005, 0.090000, 1.000000, 0.090000\n",
      " teddi, 0.100011, 0.110000, 1.000000, 0.110000\n",
      " veri, 58.142887, 0.050000, 1.000000, 0.050000\n",
      " bit, 0.100010, 0.110000, 1.000000, 0.110000\n",
      " shown, 0.100007, 0.090000, 1.000000, 0.090000\n",
      " good, 0.100002, 0.180000, 1.000000, 0.180000\n",
      " use, 0.100010, 0.070000, 0.870000, 0.080460\n",
      " soft, 0.100008, 0.230000, 1.000000, 0.230000\n",
      " size, 0.100007, 0.090000, 1.000000, 0.090000\n",
      " veri good, 0.100000, 0.220000, 0.770000, 0.285714\n",
      " got, 35.275643, 0.070000, 1.000000, 0.070000\n",
      " good qualiti, 0.100002, 0.090000, 0.740000, 0.121622\n",
      " doe, 260.075887, 0.170000, 1.000000, 0.170000\n",
      " deliv, 0.100005, 0.210000, 1.000000, 0.210000\n",
      " product, 0.100008, 0.000000, 1.000000, 0.000000\n",
      " 's, 0.100004, 0.120000, 1.000000, 0.120000\n",
      " just, 0.100004, 0.150000, 1.000000, 0.150000\n",
      " time, 0.100000, 0.100000, 0.880000, 0.113636\n",
      " stitch, 57.220176, 0.120000, 1.000000, 0.120000\n",
      " great, 38.218368, 0.050000, 1.000000, 0.050000\n",
      " bad, 0.100005, 0.140000, 1.000000, 0.140000\n",
      " toy, 0.100011, 0.060000, 1.000000, 0.060000\n",
      "\n",
      "\n",
      "Cluster 8:\n",
      " good, 0.100003, 0.100000, 1.000000, 0.100000\n",
      " shown, 0.100009, 0.190000, 1.000000, 0.190000\n",
      " product, 173.082251, 0.020000, 1.000000, 0.020000\n",
      " look, 0.100014, 0.030000, 1.000000, 0.030000\n",
      " pictur, 0.100003, 0.220000, 1.000000, 0.220000\n",
      " doe, 0.100010, 0.030000, 1.000000, 0.030000\n",
      " good product, 358.085329, 0.190000, 0.780000, 0.243590\n",
      " shown pictur, 357.250812, 0.000000, 0.650000, 0.000000\n",
      " price, 308.297914, 0.160000, 1.000000, 0.160000\n",
      " 's, 0.100009, 0.070000, 1.000000, 0.070000\n",
      " like, 0.100008, 0.040000, 1.000000, 0.040000\n",
      " n't, 0.100003, 0.180000, 1.000000, 0.180000\n",
      " colour, 0.100009, 0.140000, 1.000000, 0.140000\n",
      " babi, 0.100002, 0.120000, 1.000000, 0.120000\n",
      " veri, 0.100004, 0.160000, 1.000000, 0.160000\n",
      " qualiti, 354.878054, 0.200000, 1.000000, 0.200000\n",
      " littl, 0.100022, 0.160000, 0.900000, 0.177778\n",
      " size, 196.563586, 0.020000, 1.000000, 0.020000\n",
      " bit, 0.100006, 0.050000, 1.000000, 0.050000\n",
      " great, 0.100011, 0.220000, 1.000000, 0.220000\n",
      " veri good, 0.100001, 0.220000, 0.770000, 0.285714\n",
      " got, 0.100001, 0.080000, 1.000000, 0.080000\n",
      " differ, 0.100009, 0.120000, 1.000000, 0.120000\n",
      " deliv, 0.100009, 0.100000, 1.000000, 0.100000\n",
      " cute, 0.100018, 0.000000, 1.000000, 0.000000\n",
      " receiv, 0.100006, 0.090000, 1.000000, 0.090000\n",
      " color, 0.100004, 0.190000, 1.000000, 0.190000\n",
      " worth, 0.100011, 0.130000, 1.000000, 0.130000\n",
      " stitch, 0.100008, 0.090000, 1.000000, 0.090000\n",
      " kid, 0.100004, 0.040000, 0.870000, 0.045977\n",
      "\n",
      "\n",
      "Cluster 9:\n",
      " good, 0.100010, 0.190000, 1.000000, 0.190000\n",
      " qualiti, 432.214492, 0.200000, 1.000000, 0.200000\n",
      " veri, 0.100009, 0.040000, 1.000000, 0.040000\n",
      " product, 108.761051, 0.180000, 1.000000, 0.180000\n",
      " good qualiti, 62.394853, 0.070000, 0.740000, 0.094595\n",
      " bad, 0.100011, 0.070000, 1.000000, 0.070000\n",
      " veri good, 0.100005, 0.170000, 0.770000, 0.220779\n",
      " qualiti product, 1076.426453, 0.100000, 0.790000, 0.126582\n",
      " price, 0.100002, 0.170000, 1.000000, 0.170000\n",
      " good product, 1317.225810, 0.130000, 0.780000, 0.166667\n",
      " buy, 0.100004, 0.220000, 1.000000, 0.220000\n",
      " excel, 0.100003, 0.170000, 1.000000, 0.170000\n",
      " materi, 0.100004, 0.160000, 1.000000, 0.160000\n",
      " receiv, 0.100007, 0.220000, 1.000000, 0.220000\n",
      " deliv, 0.100002, 0.020000, 1.000000, 0.020000\n",
      " babi, 0.100004, 0.160000, 1.000000, 0.160000\n",
      " stitch, 0.100010, 0.010000, 1.000000, 0.010000\n",
      " money, 0.100015, 0.090000, 1.000000, 0.090000\n",
      " gift, 0.100006, 0.010000, 1.000000, 0.010000\n",
      " soft, 0.100005, 0.100000, 1.000000, 0.100000\n",
      " just, 0.100007, 0.110000, 1.000000, 0.110000\n",
      " use, 0.100007, 0.200000, 0.870000, 0.229885\n",
      " look, 0.100004, 0.210000, 1.000000, 0.210000\n",
      " great, 0.100007, 0.090000, 1.000000, 0.090000\n",
      " order, 0.100000, 0.230000, 0.860000, 0.267442\n",
      " got, 329.615238, 0.190000, 1.000000, 0.190000\n",
      " toy, 0.100005, 0.050000, 1.000000, 0.050000\n",
      " 's, 0.100006, 0.070000, 1.000000, 0.070000\n",
      " realli, 151.165567, 0.050000, 1.000000, 0.050000\n",
      " happi, 0.100008, 0.210000, 1.000000, 0.210000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    " \n",
    "order_centroids =  lda.components_.argsort()[:, ::-1] \n",
    "# print(order_centroids)\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d:\" % i, end='\\n')\n",
    "    time.sleep(1)\n",
    "    for ind in order_centroids[i, :30]: # 每个聚类选 30 个词\n",
    "        print(' %s' % word[ind], end=',')\n",
    "        print(' %f' % lda.components_[i][ind-1], end=',')\n",
    "        print(' %f' % (tfidMMframe[i:i+1][ind]), end=',')#a词在所属群中出现的频率\n",
    "        print(' %f' % max(tfidframe[:][ind]), end=',') #a词与所有顾客评论中出现最高词频的相对指数\n",
    "        print(' %f' % (tfidMMframe[i:i+1][ind]/max(tfidframe[:][ind])), end='\\n')\n",
    "        \n",
    "    print('') # 空行\n",
    "    print() # 空行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pyLDAvis/_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el335844995003927893358314\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el335844995003927893358314_data = {\"mdsDat\": {\"Freq\": [17.551897032868133, 11.831850100870927, 10.910887312962405, 9.572117455059757, 9.542851607944135, 9.374071991273695, 9.171595680887012, 8.929458589905085, 7.0379294320851935, 6.077340796143667], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"x\": [-0.18849601153259293, 0.1316136990976423, -0.19406650377614587, -0.0685578238875281, 0.14700960767534613, -0.2621655686359217, 0.1160025853755921, -0.18302951547370044, 0.2398267041823086, 0.26186282697499974], \"y\": [-0.09767960857937945, -0.25574306922141543, -0.0870443128880038, 0.02902039510090606, -0.19437853466298488, 0.12417290243035461, -0.15950843663243486, 0.18709486886465534, 0.21247124934713782, 0.24159454624116386]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"Freq\": [822.0, 714.0, 1132.0, 1783.0, 1959.0, 1487.0, 504.0, 465.0, 430.0, 401.0, 504.0, 369.0, 318.0, 400.0, 379.0, 532.0, 523.0, 276.0, 628.0, 425.0, 599.0, 308.0, 341.0, 262.0, 295.0, 290.0, 264.0, 309.0, 265.0, 310.0, 233.1495613013444, 135.4067423339212, 295.2532530972221, 964.2103147357856, 217.07415779752563, 1179.9066339680212, 457.8671265986827, 97.42284459241084, 55.89026649583497, 387.1566607612963, 0.08958668966866139, 0.08957860762716433, 0.08957935209636185, 0.08958274107080513, 0.08957533900687396, 0.08957832689214815, 0.08958483788167881, 0.0895817334618209, 0.08957973955579956, 0.08957590173362084, 0.08957739735328299, 0.08958212926803415, 0.08958104043698652, 0.0895843553797193, 0.08958869039081209, 0.08957842137962518, 0.0895851971150983, 0.08957903100277965, 0.08957920068108652, 0.08958680266569809, 0.08958940750970466, 0.08958924239242581, 0.08958390734455822, 0.08958366141794719, 0.08958306184532475, 0.08958261268089852, 0.08958166079919173, 0.08958157522985175, 0.08958149624572004, 0.08958114688440755, 378.77833320605555, 264.2808193480057, 217.51266503495515, 227.65138613038934, 241.45787502732384, 76.91363110443692, 217.70993995181215, 59.082946901031995, 175.93832656718706, 147.28783797280673, 98.35014631867121, 71.26789152453786, 40.94445610978749, 167.02004243985652, 54.76036203759368, 38.836286553953336, 35.84598325281728, 58.14531689580715, 80.18039608580814, 59.31320547250648, 0.10162109855347685, 0.10163685285397642, 0.10161934778733844, 0.10161690082767379, 0.10161687621783826, 0.1016277168964115, 0.1016256962762745, 0.10162816253119189, 0.10162432921937897, 0.10165205501091157, 0.10163290150159826, 0.10163060916564877, 0.10163023182989311, 0.10162763433041641, 0.10162718490154948, 0.10162688151167162, 204.3817887542724, 194.34761399254342, 353.22332340380973, 198.84026364800476, 304.82229899760085, 322.9502360288257, 171.13099786360374, 350.87731409953676, 354.04843181362463, 44.44144000493992, 0.09887425953931475, 0.09888196504315912, 0.09888633019404935, 0.09887396549151586, 0.09887705497965245, 0.09887326353752489, 0.0988843944413839, 0.0988807462083496, 0.09887549619254346, 0.09887842242788349, 0.09888376770792034, 0.09887549919215509, 0.09887590170836069, 0.09887952656462337, 0.09887475787883429, 0.09888941119280786, 0.09889006523275573, 0.09887867518578747, 0.0988812565167673, 0.09888353081207917, 0.09889431016453733, 0.09889314284377188, 0.09888828508849347, 0.09888659501025605, 0.09888579066171117, 0.09888317819153027, 0.09888247054584229, 0.09888170270026803, 0.09888145853163678, 0.09888117553025191, 0.09888050986958653, 464.31422726669604, 162.07594117340017, 332.23726062289285, 343.4805864481042, 585.3649836927103, 109.32297545397996, 74.78902140120562, 92.40097791024738, 16.182098846077682, 11.110630381511356, 0.5681046092708967, 0.10157723998987046, 0.10158269338276783, 0.10158596280191066, 0.10158676403834205, 0.10157718798350393, 0.10157610340755809, 0.10158443395677795, 0.10158153688125202, 0.10157862076488104, 0.10157662585444585, 0.10159018542848214, 0.10157915919760373, 0.10158265168240047, 0.10158547272398423, 0.10158416926032694, 0.10157987511630501, 0.10158826884297507, 0.10158491274368106, 0.1015792336185699, 0.1016112423025051, 0.10159583635867764, 0.10159332871008953, 0.10159223737003974, 0.10158862641951426, 0.10158707163187289, 0.10158613195785816, 0.10158579539777134, 0.10158578165319891, 0.10158527166002583, 0.10158393435806354, 503.91573389564803, 307.11212197465477, 231.857258890751, 174.21625061416051, 356.08673037354737, 87.63389158260368, 148.6126419264485, 75.34195907150287, 99.70379141229537, 200.51609012182783, 0.10180228774609557, 0.10181411233384413, 0.10181247787146246, 0.10180684040189479, 0.10180938550383528, 0.10180254074997024, 0.10180935154358729, 0.1018137746266083, 0.1018155502526319, 0.10180880541790774, 0.10180424153998283, 0.10181458341850357, 0.101808417165624, 0.10182037210039696, 0.10181054432412492, 0.10180239738193864, 0.10182111983035837, 0.10180575466612601, 0.10180438195558769, 0.10180486155236754, 0.12479233786865951, 0.10182271992260458, 0.10181843442723162, 0.10181780426508713, 0.10181726719041008, 0.10181660285202679, 0.10181634460835666, 0.10181614210267116, 0.1018155760842788, 0.10181292496169704, 0.10181215282657367, 0.10181190082193488, 0.10181147651594837, 289.4292611134196, 223.58807268659072, 205.949133132261, 182.16542233752955, 177.50148008177166, 234.78279770240803, 83.76238599849526, 155.58854829610289, 372.396212832263, 43.2397650730077, 48.74251726185631, 129.38849840810897, 0.10091794953700778, 0.10092019446906306, 0.10091181130187736, 0.10091616563117821, 0.10091256342119154, 0.10092323525541629, 0.10091662209667611, 0.10091403885485557, 0.10091706821954793, 0.10092962250000975, 0.10091894010621433, 0.10092039424376704, 0.10091870799475106, 0.10092031555354099, 0.10091973022829274, 0.10092089868418273, 0.10091318490414015, 0.10091933688679808, 0.10093217055147885, 0.10092960876396541, 0.10092586099293388, 0.10092395150320943, 0.10092348782960792, 0.10092344654680598, 0.10092288126457878, 0.1009223900360055, 0.1009218180688576, 0.10092173573503102, 0.10092100923146556, 0.10091999200443229, 429.576880876381, 366.6073974665956, 187.44293053139288, 345.4161082190438, 116.50233392697646, 104.50620787437522, 136.3344065891305, 100.23904751796094, 77.2838089714401, 235.92670210159903, 0.10170417151911301, 0.10170133366210743, 0.10170044551478657, 0.10170156164265236, 0.10170991891958887, 0.10170298645931172, 0.10171580916651517, 0.1016998826717783, 0.10170535171885656, 0.10170268199967945, 0.10170804987081686, 0.101709303471013, 0.10170195188387553, 0.10170234933731499, 0.10170377062255724, 0.10170200870410907, 0.1017153150526987, 0.10170077833859903, 0.1017098933074051, 0.10170147660539658, 0.10171988259182754, 0.10171744035215659, 0.10171508253787892, 0.10171487118491172, 0.10171368391732127, 0.10171335176537115, 0.10171330647371293, 0.1017129622170321, 0.10171080029949581, 0.10171034783187433, 0.10171014575074169, 0.10170906642497206, 0.10170690672792283, 0.10170669945543394, 713.8806374068856, 183.07625838900904, 176.12479643256816, 68.01169808362128, 579.7330972420261, 68.16291865044677, 162.75506211179743, 23.0508077981804, 28.6113641360295, 39.888790203357395, 1.2337182171082226, 0.09832459214578597, 0.09832276671241118, 0.09831629981686003, 0.09831544619086557, 0.09831636820448782, 0.09831689467924011, 0.09832117266675013, 0.09831417833854324, 0.09831870173787298, 0.09831574965169254, 0.09832364940346379, 0.09832259482235048, 0.09831905191234107, 0.09832039586544963, 0.0983239162280028, 0.09831566845041355, 0.0983219778153524, 0.09831881300033736, 0.09831583142906128, 0.09832983363818207, 0.09832813782458219, 0.098326647788689, 0.09832597906538194, 0.09832534231884439, 0.0983238057390579, 0.09832367672886864, 0.09832267407648662, 0.09832213483453521, 0.09832208818366339, 0.09832164601493532, 0.0983212426585666, 317.6954169148324, 261.89455650593567, 255.90090258494996, 332.538853736706, 242.04224842385855, 199.25196501166027, 0.11198497425472749, 0.1119976576856032, 0.11198479392954552, 0.11197882852953879, 0.11197908338488485, 0.11197680166263356, 0.11197905334014842, 0.11198178911202113, 0.11199087857540058, 0.11199357989952101, 0.11199693078338815, 0.11198381562174045, 0.11198582842560467, 0.11198922214882799, 0.1119839417584588, 0.11198355303137977, 0.11198968232369638, 0.1119837395584101, 0.11198307769755243, 0.11198690225948195, 0.11198579040328446, 0.11198140555479665, 0.1119794412022316, 0.1120063473951524, 0.11201494646080519, 0.11200121726260401, 0.11199902434604911, 0.11199312188821053, 0.11199101623532245, 0.1119896888827775, 0.11198764284816687, 0.11198750754591157, 0.11198703623910349, 0.11198623815079665, 0.11198621625304386, 0.11198616208663598, 0.11198602433345438, 0.11198600172785836, 0.11198582265036373, 822.0354650487375, 275.98611342862756, 235.37496702891397, 39.68499833821016, 15.858259802625465, 0.10913461843455374, 0.10913249594517985, 0.10913695720036724, 0.10913493377792594, 0.10913419374262284, 0.10913796405401383, 0.10913664125698111, 0.10913258761287324, 0.10913866470178067, 0.10913224192419838, 0.10913549897210992, 0.10913876863840523, 0.10913797992929838, 0.10913443227657288, 0.10913814161276113, 0.109143921633321, 0.10915197182189476, 0.1091320835644777, 0.10913234620785356, 0.10913572405298404, 0.1091415719156302, 0.10913747420871975, 0.10913198639707394, 0.10913408932062782, 0.10913977882221473, 0.10984990169624434, 0.10915194083932057, 0.10915062780299588, 0.1091502821843146, 0.10915003419769374, 0.10914993222070576, 0.1091492395190696, 0.10914466752665752, 0.10914365877232439, 0.10914329981010853, 0.10914285798535303, 0.10914222675942782, 0.10914202619228891, 0.1091405581556269, 0.10913935985329672, 0.10913882384276649, 0.10913859711046116, 0.10913855006058791, 0.10913847734306506], \"Term\": [\"love\", \"nice\", \"qualiti\", \"product\", \"good\", \"veri\", \"toy\", \"cute\", \"small\", \"amazon\", \"like\", \"kid\", \"thank\", \"size\", \"n't\", \"'s\", \"pictur\", \"gift\", \"soft\", \"shown\", \"look\", \"worth\", \"teddi\", \"receiv\", \"got\", \"expect\", \"excel\", \"just\", \"differ\", \"realli\", \"bad\", \"qualiti product\", \"good qualiti\", \"qualiti\", \"veri good\", \"good\", \"veri\", \"price\", \"good product\", \"product\", \"deliv\", \"littl\", \"veri cute\", \"use\", \"nice product\", \"bit\", \"stitch\", \"order\", \"time\", \"shown pictur\", \"doe\", \"great\", \"happi\", \"money\", \"materi\", \"awesom\", \"babi\", \"colour\", \"color\", \"receiv\", \"buy\", \"excel\", \"gift\", \"soft\", \"just\", \"look\", \"got\", \"toy\", \"'s\", \"realli\", \"n't\", \"differ\", \"materi\", \"color\", \"buy\", \"bit\", \"pictur\", \"use\", \"look\", \"like\", \"teddi\", \"shown\", \"veri good\", \"qualiti\", \"size\", \"got\", \"good qualiti\", \"soft\", \"veri\", \"good\", \"qualiti product\", \"deliv\", \"littl\", \"veri cute\", \"nice product\", \"stitch\", \"order\", \"time\", \"shown pictur\", \"doe\", \"product\", \"'s\", \"just\", \"great\", \"bad\", \"toy\", \"doe\", \"shown pictur\", \"shown\", \"good product\", \"pictur\", \"look\", \"price\", \"product\", \"good\", \"'s\", \"qualiti product\", \"deliv\", \"littl\", \"veri cute\", \"use\", \"nice product\", \"bit\", \"stitch\", \"order\", \"time\", \"great\", \"happi\", \"money\", \"materi\", \"awesom\", \"babi\", \"colour\", \"bad\", \"color\", \"veri good\", \"like\", \"n't\", \"veri\", \"qualiti\", \"size\", \"got\", \"differ\", \"cute\", \"receiv\", \"worth\", \"kid\", \"cute\", \"veri cute\", \"'s\", \"soft\", \"veri\", \"just\", \"realli\", \"product\", \"price\", \"buy\", \"kid\", \"qualiti product\", \"deliv\", \"littl\", \"use\", \"nice product\", \"bit\", \"stitch\", \"order\", \"time\", \"shown pictur\", \"doe\", \"great\", \"happi\", \"money\", \"materi\", \"awesom\", \"babi\", \"colour\", \"bad\", \"got\", \"worth\", \"look\", \"good\", \"love\", \"size\", \"good product\", \"toy\", \"teddi\", \"gift\", \"veri good\", \"toy\", \"worth\", \"colour\", \"money\", \"like\", \"babi\", \"soft\", \"buy\", \"look\", \"veri\", \"qualiti product\", \"deliv\", \"littl\", \"veri cute\", \"use\", \"nice product\", \"bit\", \"stitch\", \"order\", \"time\", \"shown pictur\", \"doe\", \"great\", \"happi\", \"materi\", \"awesom\", \"bad\", \"color\", \"good product\", \"veri good\", \"price\", \"got\", \"good\", \"'s\", \"amazon\", \"qualiti\", \"product\", \"kid\", \"just\", \"n't\", \"size\", \"cute\", \"small\", \"expect\", \"awesom\", \"great\", \"order\", \"stitch\", \"realli\", \"deliv\", \"'s\", \"product\", \"money\", \"price\", \"good\", \"qualiti product\", \"littl\", \"veri cute\", \"use\", \"nice product\", \"bit\", \"time\", \"shown pictur\", \"doe\", \"happi\", \"materi\", \"babi\", \"colour\", \"bad\", \"color\", \"good product\", \"veri good\", \"receiv\", \"got\", \"qualiti\", \"like\", \"veri\", \"amazon\", \"worth\", \"shown\", \"differ\", \"just\", \"cute\", \"look\", \"size\", \"small\", \"kid\", \"happi\", \"size\", \"littl\", \"use\", \"babi\", \"bit\", \"soft\", \"good\", \"qualiti product\", \"deliv\", \"veri cute\", \"nice product\", \"stitch\", \"order\", \"time\", \"shown pictur\", \"doe\", \"great\", \"money\", \"materi\", \"awesom\", \"colour\", \"bad\", \"color\", \"good product\", \"veri good\", \"receiv\", \"excel\", \"veri\", \"price\", \"product\", \"like\", \"look\", \"'s\", \"toy\", \"just\", \"qualiti\", \"gift\", \"worth\", \"thank\", \"realli\", \"amazon\", \"nice\", \"time\", \"nice product\", \"deliv\", \"product\", \"amazon\", \"veri\", \"happi\", \"excel\", \"price\", \"kid\", \"qualiti product\", \"littl\", \"veri cute\", \"use\", \"bit\", \"stitch\", \"order\", \"shown pictur\", \"doe\", \"great\", \"money\", \"materi\", \"awesom\", \"babi\", \"colour\", \"bad\", \"color\", \"good product\", \"veri good\", \"buy\", \"soft\", \"got\", \"qualiti\", \"good\", \"'s\", \"gift\", \"differ\", \"size\", \"good qualiti\", \"shown\", \"thank\", \"thank\", \"receiv\", \"got\", \"amazon\", \"teddi\", \"just\", \"qualiti product\", \"deliv\", \"littl\", \"veri cute\", \"use\", \"nice product\", \"bit\", \"stitch\", \"order\", \"time\", \"shown pictur\", \"doe\", \"great\", \"happi\", \"money\", \"materi\", \"awesom\", \"babi\", \"colour\", \"bad\", \"color\", \"good product\", \"veri good\", \"excel\", \"shown\", \"product\", \"veri\", \"pictur\", \"'s\", \"love\", \"good\", \"look\", \"like\", \"qualiti\", \"realli\", \"good qualiti\", \"size\", \"cute\", \"gift\", \"love\", \"gift\", \"excel\", \"littl\", \"color\", \"qualiti product\", \"deliv\", \"veri cute\", \"use\", \"nice product\", \"bit\", \"stitch\", \"order\", \"time\", \"shown pictur\", \"doe\", \"great\", \"happi\", \"money\", \"materi\", \"awesom\", \"babi\", \"colour\", \"bad\", \"good product\", \"veri good\", \"receiv\", \"differ\", \"expect\", \"got\", \"product\", \"veri\", \"kid\", \"buy\", \"realli\", \"qualiti\", \"just\", \"good\", \"teddi\", \"soft\", \"price\", \"worth\", \"cute\", \"thank\", \"toy\", \"amazon\", \"size\", \"like\", \"look\"], \"Total\": [822.0, 714.0, 1132.0, 1783.0, 1959.0, 1487.0, 504.0, 465.0, 430.0, 401.0, 504.0, 369.0, 318.0, 400.0, 379.0, 532.0, 523.0, 276.0, 628.0, 425.0, 599.0, 308.0, 341.0, 262.0, 295.0, 290.0, 264.0, 309.0, 265.0, 310.0, 234.0755265179745, 136.33268352564113, 331.923554723897, 1132.0547468590298, 258.8429370418253, 1959.1063400883513, 1487.2063416951953, 373.91651157418056, 255.557611298271, 1783.091278292976, 152.59041788269184, 156.99204274657959, 162.98986257458108, 164.40135634998472, 177.04196676053294, 177.9648834195366, 178.4161168353093, 183.0800499759084, 183.9934968155712, 195.26425236346358, 205.2984834117537, 206.86375726864603, 211.30927566401968, 218.26883194501704, 218.4266004985388, 224.50268279228217, 224.78035949342126, 232.7709991280888, 244.3144232625748, 262.7981174524104, 328.62101495535427, 264.7944135374312, 276.89252303407176, 628.1311896631104, 309.37695021592947, 599.3056110555078, 295.53919142604025, 504.8294801790612, 532.981444958094, 310.38487933426, 379.6922633414655, 265.1947277185943, 218.4266004985388, 244.3144232625748, 328.62101495535427, 177.9648834195366, 523.3472665975075, 164.40135634998472, 599.3056110555078, 504.1867113278833, 341.1943218527065, 425.3062846028627, 258.8429370418253, 1132.0547468590298, 400.988702434503, 295.53919142604025, 331.923554723897, 628.1311896631104, 1487.2063416951953, 1959.1063400883513, 136.33268352564113, 152.59041788269184, 156.99204274657959, 162.98986257458108, 177.04196676053294, 178.4161168353093, 183.0800499759084, 183.9934968155712, 195.26425236346358, 205.2984834117537, 1783.091278292976, 532.981444958094, 309.37695021592947, 206.86375726864603, 234.0755265179745, 504.8294801790612, 205.2984834117537, 195.26425236346358, 425.3062846028627, 255.557611298271, 523.3472665975075, 599.3056110555078, 373.91651157418056, 1783.091278292976, 1959.1063400883513, 532.981444958094, 136.33268352564113, 152.59041788269184, 156.99204274657959, 162.98986257458108, 164.40135634998472, 177.04196676053294, 177.9648834195366, 178.4161168353093, 183.0800499759084, 183.9934968155712, 206.86375726864603, 211.30927566401968, 218.26883194501704, 218.4266004985388, 224.50268279228217, 224.78035949342126, 232.7709991280888, 234.0755265179745, 244.3144232625748, 258.8429370418253, 504.1867113278833, 379.6922633414655, 1487.2063416951953, 1132.0547468590298, 400.988702434503, 295.53919142604025, 265.1947277185943, 465.22819264423504, 262.7981174524104, 308.0258764337104, 369.1231669570445, 465.22819264423504, 162.98986257458108, 532.981444958094, 628.1311896631104, 1487.2063416951953, 309.37695021592947, 310.38487933426, 1783.091278292976, 373.91651157418056, 328.62101495535427, 369.1231669570445, 136.33268352564113, 152.59041788269184, 156.99204274657959, 164.40135634998472, 177.04196676053294, 177.9648834195366, 178.4161168353093, 183.0800499759084, 183.9934968155712, 195.26425236346358, 205.2984834117537, 206.86375726864603, 211.30927566401968, 218.26883194501704, 218.4266004985388, 224.50268279228217, 224.78035949342126, 232.7709991280888, 234.0755265179745, 295.53919142604025, 308.0258764337104, 599.3056110555078, 1959.1063400883513, 822.9418648579846, 400.988702434503, 255.557611298271, 504.8294801790612, 341.1943218527065, 276.89252303407176, 258.8429370418253, 504.8294801790612, 308.0258764337104, 232.7709991280888, 218.26883194501704, 504.1867113278833, 224.78035949342126, 628.1311896631104, 328.62101495535427, 599.3056110555078, 1487.2063416951953, 136.33268352564113, 152.59041788269184, 156.99204274657959, 162.98986257458108, 164.40135634998472, 177.04196676053294, 177.9648834195366, 178.4161168353093, 183.0800499759084, 183.9934968155712, 195.26425236346358, 205.2984834117537, 206.86375726864603, 211.30927566401968, 218.4266004985388, 224.50268279228217, 234.0755265179745, 244.3144232625748, 255.557611298271, 258.8429370418253, 373.91651157418056, 295.53919142604025, 1959.1063400883513, 532.981444958094, 401.5070229143635, 1132.0547468590298, 1783.091278292976, 369.1231669570445, 309.37695021592947, 379.6922633414655, 400.988702434503, 465.22819264423504, 430.49071902066504, 290.3438645535831, 224.50268279228217, 206.86375726864603, 183.0800499759084, 178.4161168353093, 310.38487933426, 152.59041788269184, 532.981444958094, 1783.091278292976, 218.26883194501704, 373.91651157418056, 1959.1063400883513, 136.33268352564113, 156.99204274657959, 162.98986257458108, 164.40135634998472, 177.04196676053294, 177.9648834195366, 183.9934968155712, 195.26425236346358, 205.2984834117537, 211.30927566401968, 218.4266004985388, 224.78035949342126, 232.7709991280888, 234.0755265179745, 244.3144232625748, 255.557611298271, 258.8429370418253, 262.7981174524104, 295.53919142604025, 1132.0547468590298, 504.1867113278833, 1487.2063416951953, 401.5070229143635, 308.0258764337104, 425.3062846028627, 265.1947277185943, 309.37695021592947, 465.22819264423504, 599.3056110555078, 400.988702434503, 430.49071902066504, 369.1231669570445, 211.30927566401968, 400.988702434503, 156.99204274657959, 164.40135634998472, 224.78035949342126, 177.9648834195366, 628.1311896631104, 1959.1063400883513, 136.33268352564113, 152.59041788269184, 162.98986257458108, 177.04196676053294, 178.4161168353093, 183.0800499759084, 183.9934968155712, 195.26425236346358, 205.2984834117537, 206.86375726864603, 218.26883194501704, 218.4266004985388, 224.50268279228217, 232.7709991280888, 234.0755265179745, 244.3144232625748, 255.557611298271, 258.8429370418253, 262.7981174524104, 264.7944135374312, 1487.2063416951953, 373.91651157418056, 1783.091278292976, 504.1867113278833, 599.3056110555078, 532.981444958094, 504.8294801790612, 309.37695021592947, 1132.0547468590298, 276.89252303407176, 308.0258764337104, 318.59896445921345, 310.38487933426, 401.5070229143635, 714.7978436665757, 183.9934968155712, 177.04196676053294, 152.59041788269184, 1783.091278292976, 401.5070229143635, 1487.2063416951953, 211.30927566401968, 264.7944135374312, 373.91651157418056, 369.1231669570445, 136.33268352564113, 156.99204274657959, 162.98986257458108, 164.40135634998472, 177.9648834195366, 178.4161168353093, 183.0800499759084, 195.26425236346358, 205.2984834117537, 206.86375726864603, 218.26883194501704, 218.4266004985388, 224.50268279228217, 224.78035949342126, 232.7709991280888, 234.0755265179745, 244.3144232625748, 255.557611298271, 258.8429370418253, 328.62101495535427, 628.1311896631104, 295.53919142604025, 1132.0547468590298, 1959.1063400883513, 532.981444958094, 276.89252303407176, 265.1947277185943, 400.988702434503, 331.923554723897, 425.3062846028627, 318.59896445921345, 318.59896445921345, 262.7981174524104, 295.53919142604025, 401.5070229143635, 341.1943218527065, 309.37695021592947, 136.33268352564113, 152.59041788269184, 156.99204274657959, 162.98986257458108, 164.40135634998472, 177.04196676053294, 177.9648834195366, 178.4161168353093, 183.0800499759084, 183.9934968155712, 195.26425236346358, 205.2984834117537, 206.86375726864603, 211.30927566401968, 218.26883194501704, 218.4266004985388, 224.50268279228217, 224.78035949342126, 232.7709991280888, 234.0755265179745, 244.3144232625748, 255.557611298271, 258.8429370418253, 264.7944135374312, 425.3062846028627, 1783.091278292976, 1487.2063416951953, 523.3472665975075, 532.981444958094, 822.9418648579846, 1959.1063400883513, 599.3056110555078, 504.1867113278833, 1132.0547468590298, 310.38487933426, 331.923554723897, 400.988702434503, 465.22819264423504, 276.89252303407176, 822.9418648579846, 276.89252303407176, 264.7944135374312, 156.99204274657959, 244.3144232625748, 136.33268352564113, 152.59041788269184, 162.98986257458108, 164.40135634998472, 177.04196676053294, 177.9648834195366, 178.4161168353093, 183.0800499759084, 183.9934968155712, 195.26425236346358, 205.2984834117537, 206.86375726864603, 211.30927566401968, 218.26883194501704, 218.4266004985388, 224.50268279228217, 224.78035949342126, 232.7709991280888, 234.0755265179745, 255.557611298271, 258.8429370418253, 262.7981174524104, 265.1947277185943, 290.3438645535831, 295.53919142604025, 1783.091278292976, 1487.2063416951953, 369.1231669570445, 328.62101495535427, 310.38487933426, 1132.0547468590298, 309.37695021592947, 1959.1063400883513, 341.1943218527065, 628.1311896631104, 373.91651157418056, 308.0258764337104, 465.22819264423504, 318.59896445921345, 504.8294801790612, 401.5070229143635, 400.988702434503, 504.1867113278833, 599.3056110555078], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.736, 1.7332, 1.6229, 1.5795, 1.564, 1.233, 0.5619, 0.395, 0.22, 0.2127, -5.7003, -5.7288, -5.7663, -5.7749, -5.8491, -5.8542, -5.8567, -5.8825, -5.8875, -5.947, -5.9971, -6.0047, -6.0259, -6.0583, -6.059, -6.0865, -6.0877, -6.1227, -6.1711, -6.2439, -6.4674, -6.2515, -6.2962, -7.1153, -6.4071, -7.0684, -6.3614, -6.8968, -6.9511, -6.4104, 2.132, 2.1309, 2.1302, 2.0637, 1.8262, 1.2955, 1.2573, 1.111, 0.9087, 0.9038, 0.8905, 0.348, 0.2904, 0.2207, 0.1434, 0.1049, -0.0913, -0.2454, -0.786, -1.363, -5.0672, -5.1797, -5.2083, -5.2459, -5.3286, -5.3362, -5.362, -5.367, -5.4265, -5.4763, -7.6381, -6.4305, -5.8866, -5.4841, -5.6077, -6.3763, 2.2109, 2.2107, 2.0297, 1.9645, 1.6749, 1.5971, 1.4338, 0.5897, 0.5046, -0.2689, -5.0136, -5.1262, -5.1546, -5.1922, -5.2008, -5.2749, -5.28, -5.2826, -5.3084, -5.3134, -5.4305, -5.4518, -5.4842, -5.4849, -5.5124, -5.5135, -5.5484, -5.5541, -5.5969, -5.6546, -6.3212, -6.0377, -7.403, -7.1302, -6.0923, -5.7872, -5.6789, -6.241, -5.6698, -5.8286, -6.0096, 2.3443, 2.3407, 1.8737, 1.7427, 1.4139, 1.3061, 0.9232, -0.6137, -0.7938, -1.0407, -4.1303, -4.8557, -4.9683, -4.9967, -5.0428, -5.117, -5.1222, -5.1247, -5.1505, -5.1555, -5.215, -5.265, -5.2727, -5.2939, -5.3263, -5.327, -5.3545, -5.3556, -5.3906, -5.3962, -5.6291, -5.6706, -6.3362, -7.5207, -6.6534, -5.9345, -5.484, -6.1648, -5.773, -5.5642, -5.4968, 2.3476, 2.3464, 2.3454, 2.1239, 2.0016, 1.4074, 0.908, 0.8765, 0.5558, 0.3456, -4.8504, -4.963, -4.9914, -5.029, -5.0376, -5.1117, -5.1169, -5.1194, -5.1451, -5.1502, -5.2097, -5.2597, -5.2673, -5.2885, -5.3217, -5.3492, -5.3908, -5.4338, -5.4788, -5.4915, -5.6558, -5.6239, -7.5154, -6.2137, -5.9304, -6.967, -7.4213, -5.8463, -5.6698, -5.8746, -5.9292, -6.0778, -6.0002, 2.3641, 2.3631, 2.3628, 2.3622, 2.3621, 2.0881, 1.7674, 1.136, 0.8011, 0.7483, 0.3297, -0.3502, -4.8413, -4.9824, -5.02, -5.0286, -5.1027, -5.1078, -5.1411, -5.2006, -5.2507, -5.2794, -5.3127, -5.3413, -5.3763, -5.3818, -5.4247, -5.4696, -5.4825, -5.4976, -5.6149, -6.9579, -6.1491, -7.2308, -5.9214, -5.6564, -5.979, -5.5066, -5.6607, -6.0687, -6.322, -5.9201, 2.3869, 2.3822, 2.2692, 2.2399, 2.0908, 1.936, 1.889, 1.815, 0.2938, 0.2723, -4.8117, -4.9244, -4.9904, -5.073, -5.0807, -5.1066, -5.1114, -5.171, -5.2211, -5.2287, -5.2823, -5.283, -5.3105, -5.3467, -5.3523, -5.3951, -5.44, -5.4529, -5.468, -5.4756, -7.2011, -5.8205, -7.3826, -6.1195, -6.2923, -6.175, -6.1208, -5.6311, -6.9284, -5.5202, -5.6268, -5.6605, -5.6344, -5.8918, 2.4145, 2.4108, 2.4106, 1.6077, 1.2923, 0.6425, 0.2034, 0.2002, 0.1907, 0.1779, -3.2853, -4.8188, -4.9599, -4.9974, -5.0061, -5.0853, -5.0879, -5.1136, -5.1781, -5.2282, -5.2358, -5.2894, -5.2901, -5.3176, -5.3188, -5.3537, -5.3594, -5.4021, -5.4472, -5.46, -5.6985, -6.3464, -5.5924, -6.9354, -7.4839, -6.1822, -5.5273, -5.4842, -5.8976, -5.7086, -5.9565, -5.6676, 2.651, 2.6504, 2.5098, 2.4654, 2.3105, 2.2139, -4.4506, -4.5632, -4.5917, -4.6293, -4.6379, -4.712, -4.7172, -4.7197, -4.7454, -4.7504, -4.8098, -4.86, -4.8676, -4.8888, -4.9213, -4.922, -4.9494, -4.9507, -4.9856, -4.9912, -5.034, -5.079, -5.0918, -5.1143, -5.5881, -7.0215, -6.8401, -5.7957, -5.814, -6.2484, -7.1158, -5.9313, -5.7585, -6.5673, -5.2733, -5.3404, -5.5295, -5.6781, -5.1592, 2.7995, 2.7973, 2.6828, 1.4254, 0.0658, -4.3297, -4.4423, -4.5082, -4.5169, -4.591, -4.5961, -4.5987, -4.6245, -4.6294, -4.6889, -4.739, -4.7466, -4.7679, -4.8003, -4.801, -4.8284, -4.8295, -4.8646, -4.8702, -4.958, -4.9707, -4.9859, -4.9951, -5.0856, -5.1033, -6.8941, -6.7191, -5.3256, -5.2093, -5.1522, -6.4462, -5.149, -6.9947, -5.2469, -5.8572, -5.3385, -5.1447, -5.557, -5.1784, -5.6387, -5.4098, -5.4085, -5.6375, -5.8103], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.8492, -3.3926, -2.6131, -1.4296, -2.9207, -1.2277, -2.1743, -3.7218, -4.2775, -2.3421, -10.7134, -10.7135, -10.7135, -10.7135, -10.7136, -10.7135, -10.7135, -10.7135, -10.7135, -10.7136, -10.7135, -10.7135, -10.7135, -10.7135, -10.7134, -10.7135, -10.7135, -10.7135, -10.7135, -10.7134, -10.7134, -10.7134, -10.7135, -10.7135, -10.7135, -10.7135, -10.7135, -10.7135, -10.7135, -10.7135, -1.9696, -2.3295, -2.5243, -2.4787, -2.4198, -3.5638, -2.5234, -3.8276, -2.7364, -2.9141, -3.318, -3.6401, -4.1943, -2.7884, -3.9036, -4.2472, -4.3273, -3.8436, -3.5222, -3.8237, -10.193, -10.1929, -10.193, -10.1931, -10.1931, -10.193, -10.193, -10.193, -10.193, -10.1927, -10.1929, -10.1929, -10.1929, -10.193, -10.193, -10.193, -2.5055, -2.5558, -1.9584, -2.533, -2.1058, -2.048, -2.6831, -1.9651, -1.9561, -4.0313, -10.1394, -10.1393, -10.1393, -10.1394, -10.1394, -10.1394, -10.1393, -10.1393, -10.1394, -10.1394, -10.1393, -10.1394, -10.1394, -10.1393, -10.1394, -10.1392, -10.1392, -10.1394, -10.1393, -10.1393, -10.1392, -10.1392, -10.1393, -10.1393, -10.1393, -10.1393, -10.1393, -10.1393, -10.1393, -10.1393, -10.1393, -1.554, -2.6065, -1.8887, -1.8555, -1.3223, -3.0003, -3.3799, -3.1684, -4.9107, -5.2867, -8.26, -9.9815, -9.9815, -9.9814, -9.9814, -9.9815, -9.9815, -9.9814, -9.9815, -9.9815, -9.9815, -9.9814, -9.9815, -9.9815, -9.9814, -9.9815, -9.9815, -9.9814, -9.9814, -9.9815, -9.9812, -9.9813, -9.9814, -9.9814, -9.9814, -9.9814, -9.9814, -9.9814, -9.9814, -9.9814, -9.9815, -1.4691, -1.9643, -2.2454, -2.5312, -1.8163, -3.2184, -2.6902, -3.3695, -3.0893, -2.3906, -9.9762, -9.9761, -9.9761, -9.9762, -9.9762, -9.9762, -9.9762, -9.9761, -9.9761, -9.9762, -9.9762, -9.9761, -9.9762, -9.9761, -9.9762, -9.9762, -9.9761, -9.9762, -9.9762, -9.9762, -9.7726, -9.976, -9.9761, -9.9761, -9.9761, -9.9761, -9.9761, -9.9761, -9.9761, -9.9761, -9.9761, -9.9761, -9.9762, -2.0058, -2.2639, -2.346, -2.4688, -2.4947, -2.215, -3.2457, -2.6265, -1.7537, -3.9069, -3.7871, -2.8109, -9.9671, -9.9671, -9.9672, -9.9671, -9.9672, -9.9671, -9.9671, -9.9672, -9.9671, -9.967, -9.9671, -9.9671, -9.9671, -9.9671, -9.9671, -9.9671, -9.9672, -9.9671, -9.967, -9.967, -9.967, -9.9671, -9.9671, -9.9671, -9.9671, -9.9671, -9.9671, -9.9671, -9.9671, -9.9671, -1.589, -1.7475, -2.4184, -1.8071, -2.8939, -3.0026, -2.7367, -3.0443, -3.3044, -2.1883, -9.9375, -9.9376, -9.9376, -9.9376, -9.9375, -9.9375, -9.9374, -9.9376, -9.9375, -9.9375, -9.9375, -9.9375, -9.9375, -9.9375, -9.9375, -9.9375, -9.9374, -9.9376, -9.9375, -9.9376, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9375, -9.9375, -9.9375, -9.9375, -9.9375, -9.9375, -1.0544, -2.4152, -2.4539, -3.4054, -1.2625, -3.4032, -2.5328, -4.4874, -4.2713, -3.939, -7.4151, -9.9446, -9.9446, -9.9446, -9.9447, -9.9446, -9.9446, -9.9446, -9.9447, -9.9446, -9.9447, -9.9446, -9.9446, -9.9446, -9.9446, -9.9446, -9.9447, -9.9446, -9.9446, -9.9447, -9.9445, -9.9445, -9.9445, -9.9446, -9.9446, -9.9446, -9.9446, -9.9446, -9.9446, -9.9446, -9.9446, -9.9446, -1.6259, -1.8191, -1.8423, -1.5803, -1.8979, -2.0925, -9.5764, -9.5763, -9.5764, -9.5765, -9.5765, -9.5765, -9.5765, -9.5765, -9.5764, -9.5764, -9.5763, -9.5764, -9.5764, -9.5764, -9.5764, -9.5764, -9.5764, -9.5764, -9.5765, -9.5764, -9.5764, -9.5765, -9.5765, -9.5762, -9.5762, -9.5763, -9.5763, -9.5764, -9.5764, -9.5764, -9.5764, -9.5764, -9.5764, -9.5764, -9.5764, -9.5764, -9.5764, -9.5764, -9.5764, -0.5285, -1.6199, -1.7791, -3.5593, -4.4766, -9.4555, -9.4555, -9.4554, -9.4555, -9.4555, -9.4554, -9.4555, -9.4555, -9.4554, -9.4555, -9.4555, -9.4554, -9.4554, -9.4555, -9.4554, -9.4554, -9.4553, -9.4555, -9.4555, -9.4555, -9.4554, -9.4554, -9.4555, -9.4555, -9.4554, -9.4489, -9.4553, -9.4553, -9.4553, -9.4553, -9.4553, -9.4553, -9.4554, -9.4554, -9.4554, -9.4554, -9.4554, -9.4554, -9.4554, -9.4554, -9.4554, -9.4554, -9.4554, -9.4554]}, \"token.table\": {\"Topic\": [3, 4, 6, 8, 9, 6, 5, 7, 1, 2, 7, 2, 4, 5, 2, 10, 5, 4, 6, 8, 2, 3, 8, 10, 6, 10, 1, 2, 3, 6, 7, 1, 3, 1, 2, 2, 9, 6, 7, 8, 4, 9, 4, 7, 8, 2, 5, 7, 10, 2, 3, 5, 10, 2, 5, 6, 2, 8, 8, 6, 2, 3, 1, 3, 4, 6, 8, 1, 3, 4, 6, 8, 1, 2, 1, 4, 6, 9, 2, 3, 3, 2, 7, 7, 2, 4, 5, 7, 6, 2, 9, 9, 8, 5, 2, 7, 1, 2, 4, 5, 8, 4, 1, 2, 5], \"Freq\": [0.08255446867096758, 0.6229109908809372, 0.29269311619706684, 0.1693619192671097, 0.8293752811168754, 0.9977609051881697, 0.3914932790316831, 0.6050350675944193, 0.995405215855012, 0.4326696285271025, 0.5619086084767565, 0.7333675846407501, 0.033473209257461625, 0.22822642675542018, 0.9332236589035064, 0.06548937957217589, 0.9966877354525401, 0.997360021031283, 0.5504932823801384, 0.44563741906963583, 0.9954949039565293, 0.9936751436728862, 0.10951892682547314, 0.8874809587581444, 0.9953714725274138, 0.9967766445106865, 0.6023154414102834, 0.030115772070514166, 0.180694632423085, 0.06584634910332758, 0.12046308828205667, 0.21912867206541647, 0.7786893882324621, 0.8887588596880056, 0.10845870830090916, 0.13196219361573197, 0.8662133734776253, 0.9958245113593084, 0.8849587857057858, 0.10884519824188808, 0.35232101138731736, 0.6432282684961115, 0.002709122833561871, 0.9942480799172068, 0.002709122833561871, 0.29155865614316595, 0.7060876298433134, 0.7452607020908969, 0.25478998362081945, 0.2936732057122336, 0.5389570763923378, 0.16685977597286, 0.9988554904080046, 0.9980469388913021, 0.7971820733609434, 0.19700476525586533, 0.9981767778585393, 0.9988838191474066, 0.9941145775795504, 0.9941006681173044, 0.4165494193125461, 0.5827870316070025, 0.25941619852953823, 0.45732133967578387, 0.042790300788377436, 0.1310452961644059, 0.1069757519709436, 0.21703880486168406, 0.1968491485954809, 0.051595788235852535, 0.2086264480840994, 0.3252777953999399, 0.8515489225893799, 0.14751936729504816, 0.9902247686235085, 0.24163548224664297, 0.7571245110394813, 0.9969630016373503, 0.1669385160068761, 0.8299900866257361, 0.9935254284992713, 0.1371609715338143, 0.8603733668939261, 0.9988600938441103, 0.09233739854743961, 0.5460642707202031, 0.2372115928201466, 0.12258585669229051, 0.9976677172293049, 0.28722635086027776, 0.7092732337570123, 0.9981200050030604, 0.9946003699436885, 0.9983569101813012, 0.35887781773769706, 0.6386808620755625, 0.30795995630165734, 0.05379213210509298, 0.39335496601849246, 0.13515273191404611, 0.10960146916412696, 0.9939268457623974, 0.8383462283343506, 0.15839721364842568, 0.9966695121670041], \"Term\": [\"'s\", \"'s\", \"'s\", \"amazon\", \"amazon\", \"awesom\", \"babi\", \"babi\", \"bad\", \"bit\", \"bit\", \"buy\", \"buy\", \"buy\", \"color\", \"color\", \"colour\", \"cute\", \"deliv\", \"deliv\", \"differ\", \"doe\", \"excel\", \"excel\", \"expect\", \"gift\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good product\", \"good product\", \"good qualiti\", \"good qualiti\", \"got\", \"got\", \"great\", \"happi\", \"happi\", \"just\", \"just\", \"kid\", \"kid\", \"kid\", \"like\", \"like\", \"littl\", \"littl\", \"look\", \"look\", \"look\", \"love\", \"materi\", \"money\", \"money\", \"n't\", \"nice\", \"nice product\", \"order\", \"pictur\", \"pictur\", \"price\", \"price\", \"price\", \"price\", \"price\", \"product\", \"product\", \"product\", \"product\", \"product\", \"qualiti\", \"qualiti\", \"qualiti product\", \"realli\", \"realli\", \"receiv\", \"shown\", \"shown\", \"shown pictur\", \"size\", \"size\", \"small\", \"soft\", \"soft\", \"soft\", \"soft\", \"stitch\", \"teddi\", \"teddi\", \"thank\", \"time\", \"toy\", \"use\", \"use\", \"veri\", \"veri\", \"veri\", \"veri\", \"veri\", \"veri cute\", \"veri good\", \"veri good\", \"worth\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [10, 8, 9, 6, 5, 1, 3, 7, 4, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el335844995003927893358314\", ldavis_el335844995003927893358314_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el335844995003927893358314\", ldavis_el335844995003927893358314_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el335844995003927893358314\", ldavis_el335844995003927893358314_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "9      17.551897        1       1 -0.188496 -0.097680\n",
       "7      11.831850        1       2  0.131614 -0.255743\n",
       "8      10.910887        1       3 -0.194067 -0.087044\n",
       "5       9.572117        1       4 -0.068558  0.029020\n",
       "4       9.542852        1       5  0.147010 -0.194379\n",
       "0       9.374072        1       6 -0.262166  0.124173\n",
       "2       9.171596        1       7  0.116003 -0.159508\n",
       "6       8.929459        1       8 -0.183030  0.187095\n",
       "3       7.037929        1       9  0.239827  0.212471\n",
       "1       6.077341        1      10  0.261863  0.241595, topic_info=     Category         Freq          Term        Total  loglift  logprob\n",
       "term                                                                   \n",
       "27    Default   822.000000          love   822.000000  30.0000  30.0000\n",
       "31    Default   714.000000          nice   714.000000  29.0000  29.0000\n",
       "37    Default  1132.000000       qualiti  1132.000000  28.0000  28.0000\n",
       "36    Default  1783.000000       product  1783.000000  27.0000  27.0000\n",
       "16    Default  1959.000000          good  1959.000000  26.0000  26.0000\n",
       "52    Default  1487.000000          veri  1487.000000  25.0000  25.0000\n",
       "50    Default   504.000000           toy   504.000000  24.0000  24.0000\n",
       "9     Default   465.000000          cute   465.000000  23.0000  23.0000\n",
       "44    Default   430.000000         small   430.000000  22.0000  22.0000\n",
       "1     Default   401.000000        amazon   401.000000  21.0000  21.0000\n",
       "24    Default   504.000000          like   504.000000  20.0000  20.0000\n",
       "23    Default   369.000000           kid   369.000000  19.0000  19.0000\n",
       "48    Default   318.000000         thank   318.000000  18.0000  18.0000\n",
       "43    Default   400.000000          size   400.000000  17.0000  17.0000\n",
       "30    Default   379.000000           n't   379.000000  16.0000  16.0000\n",
       "0     Default   532.000000            's   532.000000  15.0000  15.0000\n",
       "34    Default   523.000000        pictur   523.000000  14.0000  14.0000\n",
       "15    Default   276.000000          gift   276.000000  13.0000  13.0000\n",
       "45    Default   628.000000          soft   628.000000  12.0000  12.0000\n",
       "41    Default   425.000000         shown   425.000000  11.0000  11.0000\n",
       "26    Default   599.000000          look   599.000000  10.0000  10.0000\n",
       "55    Default   308.000000         worth   308.000000   9.0000   9.0000\n",
       "47    Default   341.000000         teddi   341.000000   8.0000   8.0000\n",
       "40    Default   262.000000        receiv   262.000000   7.0000   7.0000\n",
       "19    Default   295.000000           got   295.000000   6.0000   6.0000\n",
       "14    Default   290.000000        expect   290.000000   5.0000   5.0000\n",
       "13    Default   264.000000         excel   264.000000   4.0000   4.0000\n",
       "22    Default   309.000000          just   309.000000   3.0000   3.0000\n",
       "11    Default   265.000000        differ   265.000000   2.0000   2.0000\n",
       "39    Default   310.000000        realli   310.000000   1.0000   1.0000\n",
       "...       ...          ...           ...          ...      ...      ...\n",
       "28    Topic10     0.109138        materi   218.426600  -4.8010  -9.4554\n",
       "2     Topic10     0.109144        awesom   224.502683  -4.8284  -9.4554\n",
       "3     Topic10     0.109152          babi   224.780359  -4.8295  -9.4553\n",
       "8     Topic10     0.109132        colour   232.770999  -4.8646  -9.4555\n",
       "4     Topic10     0.109132           bad   234.075527  -4.8702  -9.4555\n",
       "17    Topic10     0.109136  good product   255.557611  -4.9580  -9.4555\n",
       "54    Topic10     0.109142     veri good   258.842937  -4.9707  -9.4554\n",
       "40    Topic10     0.109137        receiv   262.798117  -4.9859  -9.4554\n",
       "11    Topic10     0.109132        differ   265.194728  -4.9951  -9.4555\n",
       "14    Topic10     0.109134        expect   290.343865  -5.0856  -9.4555\n",
       "19    Topic10     0.109140           got   295.539191  -5.1033  -9.4554\n",
       "36    Topic10     0.109850       product  1783.091278  -6.8941  -9.4489\n",
       "52    Topic10     0.109152          veri  1487.206342  -6.7191  -9.4553\n",
       "23    Topic10     0.109151           kid   369.123167  -5.3256  -9.4553\n",
       "6     Topic10     0.109150           buy   328.621015  -5.2093  -9.4553\n",
       "39    Topic10     0.109150        realli   310.384879  -5.1522  -9.4553\n",
       "37    Topic10     0.109150       qualiti  1132.054747  -6.4462  -9.4553\n",
       "22    Topic10     0.109149          just   309.376950  -5.1490  -9.4553\n",
       "16    Topic10     0.109145          good  1959.106340  -6.9947  -9.4554\n",
       "47    Topic10     0.109144         teddi   341.194322  -5.2469  -9.4554\n",
       "45    Topic10     0.109143          soft   628.131190  -5.8572  -9.4554\n",
       "35    Topic10     0.109143         price   373.916512  -5.3385  -9.4554\n",
       "55    Topic10     0.109142         worth   308.025876  -5.1447  -9.4554\n",
       "9     Topic10     0.109142          cute   465.228193  -5.5570  -9.4554\n",
       "48    Topic10     0.109141         thank   318.598964  -5.1784  -9.4554\n",
       "50    Topic10     0.109139           toy   504.829480  -5.6387  -9.4554\n",
       "1     Topic10     0.109139        amazon   401.507023  -5.4098  -9.4554\n",
       "43    Topic10     0.109139          size   400.988702  -5.4085  -9.4554\n",
       "24    Topic10     0.109139          like   504.186711  -5.6375  -9.4554\n",
       "26    Topic10     0.109138          look   599.305611  -5.8103  -9.4554\n",
       "\n",
       "[453 rows x 6 columns], token_table=      Topic      Freq          Term\n",
       "term                               \n",
       "0         3  0.082554            's\n",
       "0         4  0.622911            's\n",
       "0         6  0.292693            's\n",
       "1         8  0.169362        amazon\n",
       "1         9  0.829375        amazon\n",
       "2         6  0.997761        awesom\n",
       "3         5  0.391493          babi\n",
       "3         7  0.605035          babi\n",
       "4         1  0.995405           bad\n",
       "5         2  0.432670           bit\n",
       "5         7  0.561909           bit\n",
       "6         2  0.733368           buy\n",
       "6         4  0.033473           buy\n",
       "6         5  0.228226           buy\n",
       "7         2  0.933224         color\n",
       "7        10  0.065489         color\n",
       "8         5  0.996688        colour\n",
       "9         4  0.997360          cute\n",
       "10        6  0.550493         deliv\n",
       "10        8  0.445637         deliv\n",
       "11        2  0.995495        differ\n",
       "12        3  0.993675           doe\n",
       "13        8  0.109519         excel\n",
       "13       10  0.887481         excel\n",
       "14        6  0.995371        expect\n",
       "15       10  0.996777          gift\n",
       "16        1  0.602315          good\n",
       "16        2  0.030116          good\n",
       "16        3  0.180695          good\n",
       "16        6  0.065846          good\n",
       "...     ...       ...           ...\n",
       "39        4  0.241635        realli\n",
       "39        6  0.757125        realli\n",
       "40        9  0.996963        receiv\n",
       "41        2  0.166939         shown\n",
       "41        3  0.829990         shown\n",
       "42        3  0.993525  shown pictur\n",
       "43        2  0.137161          size\n",
       "43        7  0.860373          size\n",
       "44        7  0.998860         small\n",
       "45        2  0.092337          soft\n",
       "45        4  0.546064          soft\n",
       "45        5  0.237212          soft\n",
       "45        7  0.122586          soft\n",
       "46        6  0.997668        stitch\n",
       "47        2  0.287226         teddi\n",
       "47        9  0.709273         teddi\n",
       "48        9  0.998120         thank\n",
       "49        8  0.994600          time\n",
       "50        5  0.998357           toy\n",
       "51        2  0.358878           use\n",
       "51        7  0.638681           use\n",
       "52        1  0.307960          veri\n",
       "52        2  0.053792          veri\n",
       "52        4  0.393355          veri\n",
       "52        5  0.135153          veri\n",
       "52        8  0.109601          veri\n",
       "53        4  0.993927     veri cute\n",
       "54        1  0.838346     veri good\n",
       "54        2  0.158397     veri good\n",
       "55        5  0.996670         worth\n",
       "\n",
       "[105 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[10, 8, 9, 6, 5, 1, 3, 7, 4, 2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2018-03-03 15:00:05.786252. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda, tf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2018-03-03 15:00:07.196266. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# #挑選特定條件(抽樣)\n",
    "# samples = ldaClusterframe[ldaClusterframe.loc[:,'ClusterLabel'] == 4][:441]\n",
    "# Rsamples = samples['review'].values\n",
    "# Rsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2018-03-03 15:00:07.204275. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# with open('../test.csv','w',encoding='utf-8') as f :\n",
    "#     f.write(str(Rsamples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
