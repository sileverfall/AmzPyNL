{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time            \n",
    "import re            \n",
    "import os    \n",
    "import sys  \n",
    "import codecs  \n",
    "import shutil  \n",
    "import nltk\n",
    "import numpy as np  \n",
    "import matplotlib  \n",
    "import scipy  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn import feature_extraction    \n",
    "from sklearn.feature_extraction.text import TfidfTransformer    \n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7080"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#title\n",
    "asins = open('../CategoryCluster/C10/US/pre/ASIN.csv').read().split('\\n')\n",
    "ASINs=[]\n",
    "for item in asins:\n",
    "    a = item.split(',')\n",
    "    ASINs += a\n",
    "# ASINs = ASINs[:-1]\n",
    "len(ASINs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7080"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#synopses\n",
    "review = open('../CategoryCluster/C10/US/pre/review.csv').read().split('\\n')\n",
    "review[0]\n",
    "Reviews=[]\n",
    "for rev in review:\n",
    "    a = rev.split('|')\n",
    "    Reviews += a \n",
    "Reviews = Reviews[:-1]\n",
    "len(Reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7080"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ranks\n",
    "ranks = open('../CategoryCluster/C10/US/pre/ranks.csv').read().split('\\n')\n",
    "ranks[0] = ranks[0].replace('\\ufeff','')\n",
    "Rank =[]\n",
    "for rank in ranks:\n",
    "    a = rank.split('\\t')\n",
    "    Rank += a\n",
    "    \n",
    "Ranks =[float(i) for i in Rank]  \n",
    "Ranks[0]\n",
    "len(Ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 载入 nltk 的英文停用词作为“stopwords”变量\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 载入 nltk 的 SnowballStemmer 作为“stemmer”变量\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 这里我定义了一个分词器（tokenizer）和词干分析器（stemmer），它们会输出给定文本词干化后的词集合\n",
    " \n",
    "def tokenize_and_stem(text):\n",
    "    # 首先分句，接着分词，而标点也会作为词例存在\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # 过滤所有不含字母的词例（例如：数字、纯标点）\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    " \n",
    "def tokenize_only(text):\n",
    "    # 首先分句，接着分词，而标点也会作为词例存在\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # 过滤所有不含字母的词例（例如：数字、纯标点）\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 非常不 pythonic，一点也不！\n",
    "# 扩充列表后变成了非常庞大的二维（flat）词汇表\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in Reviews:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #对每个评价进行分词和词干化\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) # 扩充“totalvocab_stemmed”列表\n",
    " \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf and document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 53.1 ms, total: 10.1 s\n",
      "Wall time: 10.2 s\n",
      "CPU times: user 2.66 ms, sys: 491 µs, total: 3.15 ms\n",
      "Wall time: 2.8 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    " \n",
    "# 定义向量化参数\n",
    "#将文本中的词语转换为词频矩阵 矩阵元素a[i][j] 表示j词在第i类评论下的词频  \n",
    "vectorizer = CountVectorizer(max_df=0.98, max_features=200000,\n",
    "                                 min_df=0.02, stop_words='english',\n",
    "                                 tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "#该类会统计每个词语的tf-idf权值  \n",
    "transformer = TfidfTransformer() \n",
    "\n",
    "#第一个fit_transform是计算tf-idf 第二个fit_transform是将文本转为词频矩阵  \n",
    "%time tf =  vectorizer.fit_transform(Reviews)\n",
    "%time tfidf = transformer.fit_transform(tf) # 向量化\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'m\", \"'s\", 'absolut', 'absolut love', 'actual', 'ador', 'adult', 'amazon', 'ani', 'anim']\n"
     ]
    }
   ],
   "source": [
    "#获取词袋模型中的前10个词语 \n",
    "word = vectorizer.get_feature_names()\n",
    "print(word[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词袋模型中共有几个词语\n",
    "len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.5220487,  0.       ,\n",
       "         0.       ],\n",
       "       ..., \n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         0.       ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将tf-idf矩阵抽取出来，元素w[i][j]表示j词在第i类评论中的tf-idf权重  \n",
    "weight = tfidf.toarray()  \n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7080, 171)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#词频矩阵\n",
    "tfidframe = pd.DataFrame(np.round(weight, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6     7    8    9   ...   161  162  163  164  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.48  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "   165  166  167   168   169  170  \n",
       "0  0.0  0.0  0.0  0.00  0.00  0.0  \n",
       "1  0.0  0.0  0.0  0.00  0.00  0.0  \n",
       "2  0.0  0.0  0.0  0.52  0.00  0.0  \n",
       "3  0.0  0.0  0.0  0.00  0.31  0.0  \n",
       "4  0.0  0.0  0.0  0.00  0.00  0.0  \n",
       "5  0.0  0.0  0.0  0.00  0.00  0.0  \n",
       "6  0.0  0.0  0.0  0.00  0.00  0.0  \n",
       "7  0.0  0.0  0.0  0.00  0.00  0.0  \n",
       "8  0.0  0.0  0.0  0.00  0.00  0.0  \n",
       "9  0.0  0.0  0.0  0.00  0.00  0.0  \n",
       "\n",
       "[10 rows x 171 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidframe[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(tfidf)\n",
    "dist = 1 - similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00   1.00000000e+00   8.37024037e-01 ...,   9.35993117e-01\n",
      "    1.00000000e+00   1.00000000e+00]\n",
      " [  1.00000000e+00  -2.22044605e-16   1.00000000e+00 ...,   1.00000000e+00\n",
      "    1.00000000e+00   1.00000000e+00]\n",
      " [  8.37024037e-01   1.00000000e+00   0.00000000e+00 ...,   1.00000000e+00\n",
      "    1.00000000e+00   1.00000000e+00]\n",
      " ..., \n",
      " [  9.35993117e-01   1.00000000e+00   1.00000000e+00 ...,   0.00000000e+00\n",
      "    1.00000000e+00   1.00000000e+00]\n",
      " [  1.00000000e+00   1.00000000e+00   1.00000000e+00 ...,   1.00000000e+00\n",
      "   -2.22044605e-16   1.00000000e+00]\n",
      " [  1.00000000e+00   1.00000000e+00   1.00000000e+00 ...,   1.00000000e+00\n",
      "    1.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7070</th>\n",
       "      <th>7071</th>\n",
       "      <th>7072</th>\n",
       "      <th>7073</th>\n",
       "      <th>7074</th>\n",
       "      <th>7075</th>\n",
       "      <th>7076</th>\n",
       "      <th>7077</th>\n",
       "      <th>7078</th>\n",
       "      <th>7079</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162976</td>\n",
       "      <td>0.031906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.162976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051154</td>\n",
       "      <td>0.195186</td>\n",
       "      <td>0.243931</td>\n",
       "      <td>0.173158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235526</td>\n",
       "      <td>0.043082</td>\n",
       "      <td>0.060150</td>\n",
       "      <td>0.108867</td>\n",
       "      <td>0.424572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211308</td>\n",
       "      <td>0.277217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.108635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076005</td>\n",
       "      <td>0.187201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.023250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108635</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 7080 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5     6     7     \\\n",
       "0  1.000000  0.000000  0.162976  0.031906  0.000000  0.000000   0.0   0.0   \n",
       "1  0.000000  1.000000  0.000000  0.000000  0.000000  0.211308   0.0   0.0   \n",
       "2  0.162976  0.000000  1.000000  0.000000  0.000000  0.277217   0.0   0.0   \n",
       "3  0.031906  0.000000  0.000000  1.000000  0.000000  0.000000   0.0   0.0   \n",
       "4  0.000000  0.000000  0.000000  0.000000  1.000000  0.274004   0.0   0.0   \n",
       "5  0.000000  0.211308  0.277217  0.000000  0.274004  1.000000   0.0   0.0   \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.0   0.0   \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.0   0.0   \n",
       "8  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.0   0.0   \n",
       "9  0.023250  0.000000  0.000000  0.228822  0.000000  0.000000   0.0   0.0   \n",
       "\n",
       "       8         9       ...         7070      7071      7072      7073  7074  \\\n",
       "0  0.000000  0.023250    ...     0.374002  0.000000  0.000000  0.184261   0.0   \n",
       "1  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   0.0   \n",
       "2  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   0.0   \n",
       "3  0.000000  0.228822    ...     0.051154  0.195186  0.243931  0.173158   0.0   \n",
       "4  0.000000  0.000000    ...     0.000000  0.169468  0.000000  0.000000   0.0   \n",
       "5  0.000000  0.000000    ...     0.000000  0.159283  0.000000  0.000000   0.0   \n",
       "6  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   0.0   \n",
       "7  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   0.0   \n",
       "8  1.000000  0.108635    ...     0.000000  0.000000  0.000000  0.000000   0.0   \n",
       "9  0.108635  1.000000    ...     0.037275  0.000000  0.000000  0.126178   0.0   \n",
       "\n",
       "       7075      7076      7077      7078      7079  \n",
       "0  0.046463  0.000000  0.064007  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.213996  0.000000  0.000000  0.000000  \n",
       "3  0.235526  0.043082  0.060150  0.108867  0.424572  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8  0.000000  0.076005  0.187201  0.000000  0.000000  \n",
       "9  0.031817  0.000000  0.429865  0.000000  0.000000  \n",
       "\n",
       "[10 rows x 7080 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df = pd.DataFrame(similarity)\n",
    "similarity_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 s, sys: 64.8 ms, total: 1.63 s\n",
      "Wall time: 1.46 s\n",
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=10, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans  \n",
    "num_clusters = 10\n",
    "km = KMeans(n_clusters=10)   \n",
    "%time s = km.fit(weight)  \n",
    "clusters = km.labels_.tolist()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "# 注释语句用来存储你的模型\n",
    "# 因为我已经从 pickle 载入过模型了\n",
    " \n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    " \n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "toys = { 'title': ASINs, 'rank': Ranks, 'review': Reviews, 'cluster': clusters}\n",
    " \n",
    "frame = pd.DataFrame(toys , index = [clusters] , columns = ['rank', 'title', 'cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# frame[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frame['cluster'].value_counts() #number of review per cluster (clusters from 0 to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# km.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grouped = frame['rank'].groupby(frame['cluster']) # 为了凝聚（aggregation），由聚类分类。\n",
    " \n",
    "# grouped.mean() # 每个聚类的平均排名（0 到 5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    " \n",
    "# print(\"Top terms per cluster:\")\n",
    "# print()\n",
    "# # 按离质心的距离排列聚类中心，由近到远\n",
    "# order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    " \n",
    "# for i in range(num_clusters):\n",
    "#     print(\"Cluster %d titles:\" % i, end='')\n",
    "#     for title in frame.ix[i]['title'].values.tolist():\n",
    "#         print(' %s,' % title, end='')\n",
    "#     print() # 空行\n",
    "#     print() # 空行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    " \n",
    "# print(\"Top terms per cluster:\")\n",
    "# print()\n",
    "# # 按离质心的距离排列聚类中心，由近到远\n",
    "# order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "# # print(order_centroids)\n",
    "# for i in range(num_clusters):\n",
    "#     print(\"Cluster %d:\" % i, end='')\n",
    "#     time.sleep(1)\n",
    "#     for ind in order_centroids[i, :50]: # 每个聚类选 10 个词\n",
    "#         print(' %s' % word[ind]  , end=',')\n",
    "#     print() # 空行\n",
    "#     print() # 空行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_topics = 10\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=50,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 256 ms, total: 1min 1s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=50, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=1, n_topics=10, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lda.fit(tf) #tf 为向量化后的语料词集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.5 s, sys: 69.9 ms, total: 57.5 s\n",
      "Wall time: 57.6 s\n"
     ]
    }
   ],
   "source": [
    "%time lda_matrix = lda.fit_transform(tf) #tf 为向量化后的语料词集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01430437,  0.0143001 ,  0.01428975, ...,  0.32530623,\n",
       "         0.56034145,  0.0142969 ],\n",
       "       [ 0.01666679,  0.01667058,  0.01666688, ...,  0.01666702,\n",
       "         0.84999046,  0.01666667],\n",
       "       [ 0.01666667,  0.51666288,  0.34999261, ...,  0.01666692,\n",
       "         0.0166676 ,  0.01666719],\n",
       "       ..., \n",
       "       [ 0.7749655 ,  0.02500288,  0.025008  , ...,  0.02500076,\n",
       "         0.02500367,  0.02500664],\n",
       "       [ 0.02      ,  0.02      ,  0.32570468, ...,  0.02000123,\n",
       "         0.3036255 ,  0.02000131],\n",
       "       [ 0.05      ,  0.05      ,  0.05      , ...,  0.05001246,\n",
       "         0.54994683,  0.05003078]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_matrix #表示每一個文檔屬於每一個聚類的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(lda_matrix, columns=['T1', 'T2', 'T3','T4','T5','T6','T7','T8','T9','T10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014304</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.014293</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.014295</td>\n",
       "      <td>0.325306</td>\n",
       "      <td>0.560341</td>\n",
       "      <td>0.014297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016669</td>\n",
       "      <td>0.016668</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016669</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.849990</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.516663</td>\n",
       "      <td>0.349993</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.016668</td>\n",
       "      <td>0.016670</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016668</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.320468</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.137743</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.010003</td>\n",
       "      <td>0.471776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033336</td>\n",
       "      <td>0.699992</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         T1        T2        T3        T4        T5        T6        T7  \\\n",
       "0  0.014304  0.014300  0.014290  0.014293  0.014286  0.014287  0.014295   \n",
       "1  0.016667  0.016671  0.016667  0.016669  0.016668  0.016667  0.016669   \n",
       "2  0.016667  0.516663  0.349993  0.016671  0.016668  0.016670  0.016667   \n",
       "3  0.010001  0.010001  0.010002  0.010002  0.320468  0.010002  0.137743   \n",
       "4  0.033333  0.033336  0.699992  0.033333  0.033334  0.033335  0.033333   \n",
       "\n",
       "         T8        T9       T10  \n",
       "0  0.325306  0.560341  0.014297  \n",
       "1  0.016667  0.849990  0.016667  \n",
       "2  0.016667  0.016668  0.016667  \n",
       "3  0.010001  0.010003  0.471776  \n",
       "4  0.033334  0.033333  0.033336  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 204 ms, sys: 10.7 ms, total: 215 ms\n",
      "Wall time: 206 ms\n"
     ]
    }
   ],
   "source": [
    "%time km_lda =km.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_labels = km.labels_\n",
    "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rank</th>\n",
       "      <th>review</th>\n",
       "      <th>ClusterLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿B0756TN4VV_1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Santa came through! Thank you for a reasonable...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0756TN4VV_2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My great-niece was THRILLED to receive this at...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0756TN4VV_3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ridiculously over priced but my granddaughter ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0756TN4VV_4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Love these! My 6 year and teenagers like them!...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0756TN4VV_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great items onve you dont pay more than $10 fo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title  rank                                             review  \\\n",
       "0  ﻿B0756TN4VV_1   5.0  Santa came through! Thank you for a reasonable...   \n",
       "1   B0756TN4VV_2   5.0  My great-niece was THRILLED to receive this at...   \n",
       "2   B0756TN4VV_3   5.0  ridiculously over priced but my granddaughter ...   \n",
       "3   B0756TN4VV_4   5.0  Love these! My 6 year and teenagers like them!...   \n",
       "4   B0756TN4VV_5   5.0  Great items onve you dont pay more than $10 fo...   \n",
       "\n",
       "   ClusterLabel  \n",
       "0             7  \n",
       "1             7  \n",
       "2             8  \n",
       "3             9  \n",
       "4             5  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaframe = pd.DataFrame({ 'title': ASINs, 'rank': Ranks, 'review': Reviews})\n",
    "ldaframe = ldaframe[['title','rank','review']]\n",
    "ldaClusterframe = pd.concat([ldaframe, cluster_labels], axis=1)\n",
    "ldaClusterframe[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    950\n",
       "2    917\n",
       "3    890\n",
       "0    844\n",
       "7    770\n",
       "8    662\n",
       "9    554\n",
       "1    529\n",
       "5    483\n",
       "6    481\n",
       "Name: ClusterLabel, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaClusterframe['ClusterLabel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClusterLabel\n",
       "0    4.622038\n",
       "1    4.843100\n",
       "2    4.322792\n",
       "3    4.931461\n",
       "4    4.227368\n",
       "5    4.726708\n",
       "6    4.261954\n",
       "7    4.033766\n",
       "8    4.836858\n",
       "9    4.608303\n",
       "Name: rank, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rankgrouped = ldaClusterframe['rank'].groupby(ldaClusterframe['ClusterLabel']) # 为了凝聚（aggregation），由聚类分类。\n",
    " \n",
    "Rankgrouped.mean() # 每个聚类的平均排名（0 到 5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7080.000000\n",
       "mean        4.523446\n",
       "std         1.052923\n",
       "min         0.000000\n",
       "25%         5.000000\n",
       "50%         5.000000\n",
       "75%         5.000000\n",
       "max         5.000000\n",
       "Name: rank, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaClusterframe['rank'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rank</th>\n",
       "      <th>review</th>\n",
       "      <th>ClusterLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>B01F0HKE1M_1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I was nervous buying it after seeing old revie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>1223104834_10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I bought this as a birthday gift. Honestly, I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>B07583WCMJ_9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Pikmi pops are SO fun and really high quality ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5672</th>\n",
       "      <td>B00B4WJ1OO_3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My animal-loving son was over-the-top excited ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>B00SUEEMPC_2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>much bigger than i thought it would be but its...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>B00B4WJ1OO_6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Very cute and well made.  I would highly recom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>B00B4WJ1OO_8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Looks very lifelike. It is a gift for my niece.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>B01N39LX3X_7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Outrageously priced it's obvious to see but my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>B01IO959R2_9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This arrived with nightmare Foxy and is just a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>B00B4WJ1OO_10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This little squirrel is very cute in person.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title  rank                                             review  \\\n",
       "2650   B01F0HKE1M_1   5.0  I was nervous buying it after seeing old revie...   \n",
       "3369  1223104834_10   5.0  I bought this as a birthday gift. Honestly, I ...   \n",
       "698    B07583WCMJ_9   5.0  Pikmi pops are SO fun and really high quality ...   \n",
       "5672   B00B4WJ1OO_3   5.0  My animal-loving son was over-the-top excited ...   \n",
       "701    B00SUEEMPC_2   5.0  much bigger than i thought it would be but its...   \n",
       "5675   B00B4WJ1OO_6   5.0  Very cute and well made.  I would highly recom...   \n",
       "5677   B00B4WJ1OO_8   5.0    Looks very lifelike. It is a gift for my niece.   \n",
       "6516   B01N39LX3X_7   4.0  Outrageously priced it's obvious to see but my...   \n",
       "5378   B01IO959R2_9   5.0  This arrived with nightmare Foxy and is just a...   \n",
       "5679  B00B4WJ1OO_10   5.0       This little squirrel is very cute in person.   \n",
       "\n",
       "      ClusterLabel  \n",
       "2650             0  \n",
       "3369             0  \n",
       "698              0  \n",
       "5672             0  \n",
       "701              0  \n",
       "5675             0  \n",
       "5677             0  \n",
       "6516             0  \n",
       "5378             0  \n",
       "5679             0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#排序\n",
    "ldaClusterframe.sort_values(by = 'ClusterLabel')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love, daughter, perfect, size, daughter love, 's, bear, babi, just, grandson, ador, littl, perfect size, soft, carri, birthday, small, big, plush, bought, use, right, face, sleep, new, thought, nice, real, cudd, present,\n",
      "\n",
      " love, kid, granddaught, gift, cat, christma, got, bought, kid love, great, granddaught love, pretti, want, happi, pusheen, buy, littl, gave, sure, ador, soft, month, onli, just, 'm, open, eye, face, anoth, place,\n",
      "\n",
      " cute, great, realli, price, think, item, littl, ador, girl, like, doll, lot, soft, plush, realli cute, babi, perfect, expect, fun, color, 's, bought, worth, nice, say, cudd, play, place, child, collect,\n",
      "\n",
      " work, son, time, littl, love, use, batteri, guy, t, make, just, long, arriv, christma, son love, did, day, came, awesom, got, tri, new, talk, hold, toy, quick, need, present, ani, worth,\n",
      "\n",
      " 's, n't, like, play, toy, doe, just, onli, littl, doe n't, realli, month, got, make, becaus, thing, sleep, fun, sinc, say, month old, 'm, daughter, look, head, want, actual, feel, cute, face,\n",
      "\n",
      " veri, qualiti, soft, cute, veri soft, good, veri cute, 's, recommend, high, product, happi, plush, nice, great, look, like, good qualiti, bought, fur, size, small, buy, materi, littl, realli, cudd, gund, pictur, want,\n",
      "\n",
      " old, year, year old, love, bought, old love, absolut, doll, christma, absolut love, son, hit, daughter, everi, sleep, night, big, toy, niec, becaus, gave, carri, time, gift, cute, like, play, open, girl, day,\n",
      "\n",
      " anim, stuf, super, 's, cute, stuf anim, purchas, soft, did, gift, friend, birthday, super cute, love, did n't, littl, n't, super soft, bought, buy, best, ador, son, cudd, absolut, collect, quick, know, ani, thing,\n",
      "\n",
      " n't, pusheen, look, order, like, pictur, ca n't, ca, just, amazon, buy, ship, purchas, box, ve, anoth, price, qualiti, product, bought, christma, gund, disappoint, receiv, expect, tail, better, review, differ, color,\n",
      "\n",
      " toy, love, s, cute, niec, expect, smaller, great, gift, nephew, good, child, dog, small, soft, thing, plush, thought, favorit, new, way, come, lot, babi, adult, price, day, hit, differ, cudd,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    " \n",
    "order_centroids =  lda.components_.argsort()[:, ::-1] \n",
    "# print(order_centroids)\n",
    "\n",
    "for i in range(num_clusters):\n",
    "#     print(\"Cluster %d:\" % i, end='\\n')\n",
    "    time.sleep(1)\n",
    "    for ind in order_centroids[i, :30]: # 每个聚类选 30 个词\n",
    "        print(' %s' % word[ind], end=',')\n",
    "        \n",
    "        \n",
    "    print() # 空行\n",
    "    print() # 空行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 89,  37, 106, ..., 128, 142,  82],\n",
       "       [ 89,  81,  67, ...,  91, 107, 140],\n",
       "       [ 36,  70, 122, ...,  26,  82, 102],\n",
       "       ..., \n",
       "       [  9, 144, 146, ..., 128, 102,  68],\n",
       "       [ 94, 118,  87, ...,  93,  68, 102],\n",
       "       [157,  89, 128, ...,  71,  68,  48]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ftf = transformer.fit_transform(order_centroids)\n",
    "ftf = ftf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2     3     4     5     6     7     8     9    ...    161  \\\n",
       "0  0.07  0.03  0.08  0.10  0.03  0.00  0.01  0.01  0.06  0.05  ...   0.13   \n",
       "1  0.07  0.06  0.05  0.05  0.02  0.02  0.05  0.02  0.06  0.05  ...   0.05   \n",
       "2  0.03  0.05  0.09  0.09  0.12  0.06  0.07  0.00  0.05  0.07  ...   0.05   \n",
       "3  0.13  0.11  0.12  0.07  0.07  0.12  0.01  0.06  0.12  0.07  ...   0.06   \n",
       "4  0.00  0.07  0.06  0.09  0.12  0.03  0.06  0.08  0.07  0.04  ...   0.13   \n",
       "\n",
       "    162   163   164   165   166   167   168   169   170  \n",
       "0  0.08  0.09  0.01  0.10  0.11  0.04  0.10  0.11  0.06  \n",
       "1  0.11  0.11  0.13  0.08  0.05  0.04  0.07  0.08  0.11  \n",
       "2  0.03  0.05  0.13  0.13  0.05  0.02  0.02  0.06  0.08  \n",
       "3  0.13  0.09  0.13  0.11  0.04  0.08  0.05  0.07  0.05  \n",
       "4  0.06  0.05  0.06  0.12  0.08  0.11  0.11  0.02  0.05  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#词频矩阵\n",
    "tfidMMframe = pd.DataFrame(np.round(ftf, 2))\n",
    "tfidMMframe[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " love, 0.100010, 0.110000, 1.000000, 0.110000\n",
      " daughter, 0.566175, 0.100000, 0.710000, 0.140845\n",
      " perfect, 0.100017, 0.090000, 1.000000, 0.090000\n",
      " size, 0.100021, 0.010000, 1.000000, 0.010000\n",
      " daughter love, 931.657243, 0.020000, 0.740000, 0.027027\n",
      " 's, 0.100022, 0.030000, 0.830000, 0.036145\n",
      " bear, 0.100004, 0.020000, 0.950000, 0.021053\n",
      " babi, 0.100017, 0.110000, 0.910000, 0.120879\n",
      " just, 0.100008, 0.040000, 1.000000, 0.040000\n",
      " grandson, 0.100005, 0.080000, 1.000000, 0.080000\n",
      " ador, 9.514281, 0.000000, 1.000000, 0.000000\n",
      " littl, 0.100015, 0.130000, 0.840000, 0.154762\n",
      " perfect size, 640.144405, 0.110000, 0.670000, 0.164179\n",
      " soft, 0.100016, 0.040000, 1.000000, 0.040000\n",
      " carri, 0.100016, 0.030000, 1.000000, 0.030000\n",
      " birthday, 103.452143, 0.120000, 0.790000, 0.151899\n",
      " small, 66.257873, 0.120000, 1.000000, 0.120000\n",
      " big, 0.100026, 0.020000, 0.720000, 0.027778\n",
      " plush, 0.115587, 0.080000, 0.840000, 0.095238\n",
      " bought, 14.596378, 0.040000, 0.720000, 0.055556\n",
      " use, 0.100012, 0.110000, 0.660000, 0.166667\n",
      " right, 0.100021, 0.030000, 0.620000, 0.048387\n",
      " face, 0.100079, 0.070000, 0.680000, 0.102941\n",
      " sleep, 540.898063, 0.130000, 0.700000, 0.185714\n",
      " new, 0.100009, 0.090000, 0.690000, 0.130435\n",
      " thought, 0.100011, 0.120000, 0.710000, 0.169014\n",
      " nice, 64.784148, 0.100000, 0.910000, 0.109890\n",
      " real, 0.100004, 0.120000, 0.930000, 0.129032\n",
      " cudd, 0.100006, 0.010000, 0.610000, 0.016393\n",
      " present, 96.962088, 0.090000, 0.650000, 0.138462\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      " love, 0.100007, 0.120000, 1.000000, 0.120000\n",
      " kid, 43.548791, 0.060000, 0.780000, 0.076923\n",
      " granddaught, 314.498353, 0.020000, 1.000000, 0.020000\n",
      " gift, 80.714556, 0.090000, 1.000000, 0.090000\n",
      " cat, 0.100016, 0.080000, 0.900000, 0.088889\n",
      " christma, 0.100010, 0.100000, 0.660000, 0.151515\n",
      " got, 0.100003, 0.040000, 0.820000, 0.048780\n",
      " bought, 0.100021, 0.080000, 0.720000, 0.111111\n",
      " kid love, 523.533533, 0.100000, 0.760000, 0.131579\n",
      " great, 16.056979, 0.060000, 1.000000, 0.060000\n",
      " granddaught love, 493.881919, 0.090000, 0.750000, 0.120000\n",
      " pretti, 0.100031, 0.000000, 0.760000, 0.000000\n",
      " want, 0.100009, 0.080000, 0.710000, 0.112676\n",
      " happi, 0.100020, 0.070000, 1.000000, 0.070000\n",
      " pusheen, 0.100026, 0.100000, 0.920000, 0.108696\n",
      " buy, 0.100007, 0.000000, 0.900000, 0.000000\n",
      " littl, 0.105816, 0.100000, 0.840000, 0.119048\n",
      " gave, 0.100005, 0.040000, 0.700000, 0.057143\n",
      " sure, 0.100007, 0.020000, 0.620000, 0.032258\n",
      " ador, 0.100006, 0.020000, 1.000000, 0.020000\n",
      " soft, 0.100009, 0.120000, 1.000000, 0.120000\n",
      " month, 0.100001, 0.010000, 0.730000, 0.013699\n",
      " onli, 0.100003, 0.080000, 0.750000, 0.106667\n",
      " just, 0.100009, 0.050000, 1.000000, 0.050000\n",
      " 'm, 0.100004, 0.070000, 1.000000, 0.070000\n",
      " open, 47.199577, 0.040000, 0.680000, 0.058824\n",
      " eye, 0.101837, 0.060000, 0.700000, 0.085714\n",
      " face, 38.275690, 0.070000, 0.680000, 0.102941\n",
      " anoth, 0.100008, 0.050000, 0.690000, 0.072464\n",
      " place, 27.512343, 0.010000, 0.640000, 0.015625\n",
      "\n",
      "\n",
      "Cluster 2:\n",
      " cute, 55.180516, 0.010000, 1.000000, 0.010000\n",
      " great, 0.100010, 0.030000, 1.000000, 0.030000\n",
      " realli, 8.644232, 0.020000, 0.790000, 0.025316\n",
      " price, 0.100019, 0.000000, 0.640000, 0.000000\n",
      " think, 0.100012, 0.110000, 0.640000, 0.171875\n",
      " item, 0.100011, 0.060000, 1.000000, 0.060000\n",
      " littl, 206.948477, 0.110000, 0.840000, 0.130952\n",
      " ador, 0.100016, 0.060000, 1.000000, 0.060000\n",
      " girl, 0.155260, 0.010000, 0.930000, 0.010753\n",
      " like, 0.100026, 0.000000, 1.000000, 0.000000\n",
      " doll, 0.100010, 0.090000, 1.000000, 0.090000\n",
      " lot, 0.100028, 0.130000, 0.740000, 0.175676\n",
      " soft, 0.100016, 0.120000, 1.000000, 0.120000\n",
      " plush, 50.764057, 0.010000, 0.840000, 0.011905\n",
      " realli cute, 391.015824, 0.050000, 0.700000, 0.071429\n",
      " babi, 0.100010, 0.090000, 0.910000, 0.098901\n",
      " perfect, 0.100022, 0.120000, 1.000000, 0.120000\n",
      " expect, 0.100013, 0.070000, 1.000000, 0.070000\n",
      " fun, 0.100018, 0.070000, 1.000000, 0.070000\n",
      " color, 38.659972, 0.030000, 0.630000, 0.047619\n",
      " 's, 0.100008, 0.050000, 0.830000, 0.060241\n",
      " bought, 0.100011, 0.130000, 0.720000, 0.180556\n",
      " worth, 0.100026, 0.020000, 0.890000, 0.022472\n",
      " nice, 0.100017, 0.120000, 0.910000, 0.131868\n",
      " say, 0.100020, 0.010000, 0.700000, 0.014286\n",
      " cudd, 0.100020, 0.050000, 0.610000, 0.081967\n",
      " play, 0.100021, 0.060000, 0.790000, 0.075949\n",
      " place, 0.111855, 0.110000, 0.640000, 0.171875\n",
      " child, 0.100013, 0.010000, 0.920000, 0.010870\n",
      " collect, 0.100014, 0.060000, 0.870000, 0.068966\n",
      "\n",
      "\n",
      "Cluster 3:\n",
      " work, 0.100012, 0.080000, 1.000000, 0.080000\n",
      " son, 0.100020, 0.100000, 0.640000, 0.156250\n",
      " time, 52.307819, 0.100000, 0.650000, 0.153846\n",
      " littl, 0.100023, 0.060000, 0.840000, 0.071429\n",
      " love, 0.100027, 0.080000, 1.000000, 0.080000\n",
      " use, 111.876051, 0.030000, 0.660000, 0.045455\n",
      " batteri, 0.100019, 0.110000, 1.000000, 0.110000\n",
      " guy, 0.100022, 0.090000, 0.860000, 0.104651\n",
      " t, 42.563965, 0.110000, 0.770000, 0.142857\n",
      " make, 315.320752, 0.010000, 1.000000, 0.010000\n",
      " just, 0.100016, 0.010000, 1.000000, 0.010000\n",
      " long, 327.051525, 0.030000, 0.680000, 0.044118\n",
      " arriv, 0.100025, 0.070000, 1.000000, 0.070000\n",
      " christma, 0.100020, 0.130000, 0.660000, 0.196970\n",
      " son love, 417.419515, 0.090000, 0.780000, 0.115385\n",
      " did, 25.166675, 0.120000, 0.730000, 0.164384\n",
      " day, 0.100006, 0.120000, 0.570000, 0.210526\n",
      " came, 0.100007, 0.090000, 0.720000, 0.125000\n",
      " awesom, 170.771785, 0.010000, 1.000000, 0.010000\n",
      " got, 0.100010, 0.080000, 0.820000, 0.097561\n",
      " tri, 85.242771, 0.070000, 0.600000, 0.116667\n",
      " new, 0.100006, 0.060000, 0.690000, 0.086957\n",
      " talk, 0.100027, 0.130000, 0.860000, 0.151163\n",
      " hold, 0.100024, 0.120000, 0.640000, 0.187500\n",
      " toy, 329.318568, 0.080000, 1.000000, 0.080000\n",
      " quick, 0.100011, 0.090000, 0.690000, 0.130435\n",
      " need, 0.100015, 0.020000, 0.880000, 0.022727\n",
      " present, 0.100017, 0.060000, 0.650000, 0.092308\n",
      " ani, 0.100017, 0.120000, 1.000000, 0.120000\n",
      " worth, 422.377017, 0.050000, 0.890000, 0.056180\n",
      "\n",
      "\n",
      "Cluster 4:\n",
      " 's, 189.028994, 0.070000, 0.830000, 0.084337\n",
      " n't, 194.411915, 0.040000, 0.630000, 0.063492\n",
      " like, 92.984017, 0.030000, 1.000000, 0.030000\n",
      " play, 53.128045, 0.010000, 0.790000, 0.012658\n",
      " toy, 98.516011, 0.080000, 1.000000, 0.080000\n",
      " doe, 0.100071, 0.080000, 0.630000, 0.126984\n",
      " just, 0.100005, 0.060000, 1.000000, 0.060000\n",
      " onli, 0.100015, 0.020000, 0.750000, 0.026667\n",
      " littl, 705.077338, 0.090000, 0.840000, 0.107143\n",
      " doe n't, 573.017772, 0.060000, 0.570000, 0.105263\n",
      " realli, 54.293309, 0.020000, 0.790000, 0.025316\n",
      " month, 0.100025, 0.120000, 0.730000, 0.164384\n",
      " got, 0.100005, 0.050000, 0.820000, 0.060976\n",
      " make, 62.527270, 0.050000, 1.000000, 0.050000\n",
      " becaus, 0.100012, 0.100000, 0.630000, 0.158730\n",
      " thing, 83.352855, 0.050000, 1.000000, 0.050000\n",
      " sleep, 0.100064, 0.130000, 0.700000, 0.185714\n",
      " fun, 34.376539, 0.100000, 1.000000, 0.100000\n",
      " sinc, 0.100011, 0.040000, 0.700000, 0.057143\n",
      " say, 61.245192, 0.110000, 0.700000, 0.157143\n",
      " month old, 263.296850, 0.040000, 0.540000, 0.074074\n",
      " 'm, 0.100006, 0.000000, 1.000000, 0.000000\n",
      " daughter, 154.019526, 0.040000, 0.710000, 0.056338\n",
      " look, 0.100019, 0.090000, 0.820000, 0.109756\n",
      " head, 11.688868, 0.080000, 0.700000, 0.114286\n",
      " want, 0.100036, 0.120000, 0.710000, 0.169014\n",
      " actual, 0.100018, 0.120000, 0.710000, 0.169014\n",
      " feel, 0.100017, 0.050000, 0.660000, 0.075758\n",
      " cute, 0.100011, 0.020000, 1.000000, 0.020000\n",
      " face, 105.545166, 0.050000, 0.680000, 0.073529\n",
      "\n",
      "\n",
      "Cluster 5:\n",
      " veri, 0.100026, 0.080000, 1.000000, 0.080000\n",
      " qualiti, 0.100010, 0.080000, 0.620000, 0.129032\n",
      " soft, 61.179723, 0.060000, 1.000000, 0.060000\n",
      " cute, 95.713737, 0.020000, 1.000000, 0.020000\n",
      " veri soft, 333.610837, 0.110000, 0.570000, 0.192982\n",
      " good, 0.100014, 0.040000, 1.000000, 0.040000\n",
      " veri cute, 1832.453689, 0.050000, 0.760000, 0.065789\n",
      " 's, 23.081515, 0.090000, 0.830000, 0.108434\n",
      " recommend, 0.100020, 0.040000, 1.000000, 0.040000\n",
      " high, 0.100015, 0.070000, 0.650000, 0.107692\n",
      " product, 20.401130, 0.010000, 0.910000, 0.010989\n",
      " happi, 0.100019, 0.040000, 1.000000, 0.040000\n",
      " plush, 0.100019, 0.030000, 0.840000, 0.035714\n",
      " nice, 0.100014, 0.040000, 0.910000, 0.043956\n",
      " great, 0.100006, 0.020000, 1.000000, 0.020000\n",
      " look, 0.100014, 0.060000, 0.820000, 0.073171\n",
      " like, 0.100016, 0.010000, 1.000000, 0.010000\n",
      " good qualiti, 346.371951, 0.050000, 0.700000, 0.071429\n",
      " bought, 0.100014, 0.020000, 0.720000, 0.027778\n",
      " fur, 0.100010, 0.010000, 0.540000, 0.018519\n",
      " size, 45.947369, 0.020000, 1.000000, 0.020000\n",
      " small, 0.100021, 0.130000, 1.000000, 0.130000\n",
      " buy, 0.100011, 0.070000, 0.900000, 0.077778\n",
      " materi, 73.301774, 0.120000, 0.720000, 0.166667\n",
      " littl, 159.120239, 0.100000, 0.840000, 0.119048\n",
      " realli, 6.730258, 0.000000, 0.790000, 0.000000\n",
      " cudd, 0.100009, 0.130000, 0.610000, 0.213115\n",
      " gund, 189.662043, 0.060000, 0.730000, 0.082192\n",
      " pictur, 0.301172, 0.030000, 0.870000, 0.034483\n",
      " want, 0.100012, 0.100000, 0.710000, 0.140845\n",
      "\n",
      "\n",
      "Cluster 6:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " old, 79.583734, 0.040000, 0.640000, 0.062500\n",
      " year, 12.805072, 0.030000, 0.580000, 0.051724\n",
      " year old, 923.185259, 0.110000, 0.610000, 0.180328\n",
      " love, 0.100008, 0.120000, 1.000000, 0.120000\n",
      " bought, 0.100017, 0.120000, 0.720000, 0.166667\n",
      " old love, 1075.172029, 0.030000, 0.720000, 0.041667\n",
      " absolut, 0.100026, 0.130000, 0.880000, 0.147727\n",
      " doll, 22.116459, 0.120000, 1.000000, 0.120000\n",
      " christma, 0.100020, 0.050000, 0.660000, 0.075758\n",
      " absolut love, 148.385247, 0.070000, 0.640000, 0.109375\n",
      " son, 0.100022, 0.060000, 0.640000, 0.093750\n",
      " hit, 0.100009, 0.050000, 0.850000, 0.058824\n",
      " daughter, 50.435867, 0.040000, 0.710000, 0.056338\n",
      " everi, 7.040484, 0.040000, 0.600000, 0.066667\n",
      " sleep, 0.100015, 0.050000, 0.700000, 0.071429\n",
      " night, 67.251921, 0.020000, 0.620000, 0.032258\n",
      " big, 0.100014, 0.010000, 0.720000, 0.013889\n",
      " toy, 61.955810, 0.090000, 1.000000, 0.090000\n",
      " niec, 21.743814, 0.020000, 0.920000, 0.021739\n",
      " becaus, 0.100018, 0.010000, 0.630000, 0.015873\n",
      " gave, 0.100012, 0.070000, 0.700000, 0.100000\n",
      " carri, 20.785225, 0.050000, 1.000000, 0.050000\n",
      " time, 0.100016, 0.100000, 0.650000, 0.153846\n",
      " gift, 66.698895, 0.110000, 1.000000, 0.110000\n",
      " cute, 3.847499, 0.080000, 1.000000, 0.080000\n",
      " like, 0.100011, 0.030000, 1.000000, 0.030000\n",
      " play, 0.100007, 0.070000, 0.790000, 0.088608\n",
      " open, 0.100012, 0.010000, 0.680000, 0.014706\n",
      " girl, 57.128105, 0.010000, 0.930000, 0.010753\n",
      " day, 0.100008, 0.020000, 0.570000, 0.035088\n",
      "\n",
      "\n",
      "Cluster 7:\n",
      " anim, 65.784305, 0.050000, 0.650000, 0.076923\n",
      " stuf, 0.100008, 0.050000, 0.670000, 0.074627\n",
      " super, 445.556120, 0.140000, 0.900000, 0.155556\n",
      " 's, 0.100039, 0.110000, 0.830000, 0.132530\n",
      " cute, 87.066640, 0.010000, 1.000000, 0.010000\n",
      " stuf anim, 604.767973, 0.030000, 0.530000, 0.056604\n",
      " purchas, 48.304435, 0.080000, 1.000000, 0.080000\n",
      " soft, 0.100015, 0.020000, 1.000000, 0.020000\n",
      " did, 17.504133, 0.050000, 0.730000, 0.068493\n",
      " gift, 47.912854, 0.130000, 1.000000, 0.130000\n",
      " friend, 0.100013, 0.120000, 0.920000, 0.130435\n",
      " birthday, 46.100026, 0.010000, 0.790000, 0.012658\n",
      " super cute, 560.074788, 0.040000, 0.720000, 0.055556\n",
      " love, 0.100014, 0.100000, 1.000000, 0.100000\n",
      " did n't, 317.519448, 0.010000, 0.540000, 0.018519\n",
      " littl, 56.357053, 0.040000, 0.840000, 0.047619\n",
      " n't, 0.100005, 0.110000, 0.630000, 0.174603\n",
      " super soft, 232.863765, 0.020000, 0.590000, 0.033898\n",
      " bought, 0.100030, 0.110000, 0.720000, 0.152778\n",
      " buy, 0.100009, 0.000000, 0.900000, 0.000000\n",
      " best, 54.411840, 0.110000, 1.000000, 0.110000\n",
      " ador, 0.100026, 0.110000, 1.000000, 0.110000\n",
      " son, 0.100010, 0.060000, 0.640000, 0.093750\n",
      " cudd, 63.192010, 0.120000, 0.610000, 0.196721\n",
      " absolut, 458.940305, 0.110000, 0.880000, 0.125000\n",
      " collect, 0.100022, 0.040000, 0.870000, 0.045977\n",
      " quick, 0.100016, 0.080000, 0.690000, 0.115942\n",
      " know, 0.100009, 0.100000, 0.620000, 0.161290\n",
      " ani, 0.100010, 0.030000, 1.000000, 0.030000\n",
      " thing, 0.100012, 0.110000, 1.000000, 0.110000\n",
      "\n",
      "\n",
      "Cluster 8:\n",
      " n't, 0.100002, 0.110000, 0.630000, 0.174603\n",
      " pusheen, 180.741934, 0.060000, 0.920000, 0.065217\n",
      " look, 0.100012, 0.060000, 0.820000, 0.073171\n",
      " order, 117.284650, 0.080000, 0.790000, 0.101266\n",
      " like, 86.026808, 0.070000, 1.000000, 0.070000\n",
      " pictur, 0.100008, 0.010000, 0.870000, 0.011494\n",
      " ca n't, 238.002123, 0.010000, 0.550000, 0.018182\n",
      " ca, 181.026416, 0.120000, 0.550000, 0.218182\n",
      " just, 0.100019, 0.000000, 1.000000, 0.000000\n",
      " amazon, 0.100009, 0.020000, 0.560000, 0.035714\n",
      " buy, 162.391185, 0.040000, 0.900000, 0.044444\n",
      " ship, 37.860040, 0.050000, 1.000000, 0.050000\n",
      " purchas, 149.776843, 0.020000, 1.000000, 0.020000\n",
      " box, 147.288918, 0.100000, 0.780000, 0.128205\n",
      " ve, 0.100024, 0.110000, 0.710000, 0.154930\n",
      " anoth, 0.100010, 0.020000, 0.690000, 0.028986\n",
      " price, 0.100017, 0.040000, 0.640000, 0.062500\n",
      " qualiti, 378.815661, 0.090000, 0.620000, 0.145161\n",
      " product, 158.236515, 0.130000, 0.910000, 0.142857\n",
      " bought, 0.100022, 0.030000, 0.720000, 0.041667\n",
      " christma, 0.100017, 0.030000, 0.660000, 0.045455\n",
      " gund, 0.100021, 0.070000, 0.730000, 0.095890\n",
      " disappoint, 121.334023, 0.080000, 0.870000, 0.091954\n",
      " receiv, 0.100005, 0.100000, 0.840000, 0.119048\n",
      " expect, 119.396535, 0.100000, 1.000000, 0.100000\n",
      " tail, 0.100006, 0.050000, 0.790000, 0.063291\n",
      " better, 0.100014, 0.090000, 1.000000, 0.090000\n",
      " review, 0.100016, 0.050000, 0.600000, 0.083333\n",
      " differ, 0.100027, 0.110000, 0.580000, 0.189655\n",
      " color, 4.877784, 0.130000, 0.630000, 0.206349\n",
      "\n",
      "\n",
      "Cluster 9:\n",
      " toy, 0.100013, 0.030000, 1.000000, 0.030000\n",
      " love, 61.279266, 0.130000, 1.000000, 0.130000\n",
      " s, 0.100017, 0.000000, 0.890000, 0.000000\n",
      " cute, 30.505984, 0.020000, 1.000000, 0.020000\n",
      " niec, 0.100015, 0.070000, 0.920000, 0.076087\n",
      " expect, 9.327370, 0.060000, 1.000000, 0.060000\n",
      " smaller, 134.663438, 0.060000, 0.880000, 0.068182\n",
      " great, 0.100020, 0.010000, 1.000000, 0.010000\n",
      " gift, 20.884931, 0.020000, 1.000000, 0.020000\n",
      " nephew, 0.100021, 0.010000, 0.940000, 0.010638\n",
      " good, 0.100016, 0.120000, 1.000000, 0.120000\n",
      " child, 0.100007, 0.010000, 0.920000, 0.010870\n",
      " dog, 0.100006, 0.030000, 0.860000, 0.034884\n",
      " small, 0.100027, 0.080000, 1.000000, 0.080000\n",
      " soft, 208.839262, 0.080000, 1.000000, 0.080000\n",
      " thing, 21.313536, 0.130000, 1.000000, 0.130000\n",
      " plush, 0.100016, 0.120000, 0.840000, 0.142857\n",
      " thought, 0.100012, 0.040000, 0.710000, 0.056338\n",
      " favorit, 13.398713, 0.100000, 0.950000, 0.105263\n",
      " new, 174.218507, 0.080000, 0.690000, 0.115942\n",
      " way, 0.100017, 0.100000, 1.000000, 0.100000\n",
      " come, 9.444086, 0.120000, 1.000000, 0.120000\n",
      " lot, 0.100028, 0.080000, 0.740000, 0.108108\n",
      " babi, 0.100007, 0.100000, 0.910000, 0.109890\n",
      " adult, 0.100013, 0.110000, 0.600000, 0.183333\n",
      " price, 0.100012, 0.120000, 0.640000, 0.187500\n",
      " day, 0.100005, 0.070000, 0.570000, 0.122807\n",
      " hit, 0.100027, 0.070000, 0.850000, 0.082353\n",
      " differ, 0.100006, 0.090000, 0.580000, 0.155172\n",
      " cudd, 65.872857, 0.060000, 0.610000, 0.098361\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    " \n",
    "order_centroids =  lda.components_.argsort()[:, ::-1] \n",
    "# print(order_centroids)\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d:\" % i, end='\\n')\n",
    "    time.sleep(1)\n",
    "    for ind in order_centroids[i, :30]: # 每个聚类选 30 个词\n",
    "        print(' %s' % word[ind], end=',')\n",
    "        print(' %f' % lda.components_[i][ind-1], end=',')\n",
    "        print(' %f' % (tfidMMframe[i:i+1][ind]), end=',')#a词在所属群中出现的频率\n",
    "        print(' %f' % max(tfidframe[:][ind]), end=',') #a词与所有顾客评论中出现最高词频的相对指数\n",
    "        print(' %f' % (tfidMMframe[i:i+1][ind]/max(tfidframe[:][ind])), end='\\n')\n",
    "        \n",
    "    print('') # 空行\n",
    "    print() # 空行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pyLDAvis/_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el270446177791448509285390\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el270446177791448509285390_data = {\"mdsDat\": {\"Freq\": [17.271449222592487, 12.028632970594964, 11.104687466852132, 10.750270820963992, 10.36921183279689, 8.93537871261382, 7.967981334799408, 7.559646599614857, 7.199959510616974, 6.81278152855446], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"x\": [0.06028141753666795, 0.26404447299602885, 0.14079452823453562, 0.06405081432752756, -0.1256444337809463, -0.15265219679785466, -0.2562207287460316, -0.1509478599694462, 0.17685085706819645, -0.020556870868677517], \"y\": [-0.10807852438432274, 0.04505405934221915, -0.29864119566297537, 0.047349853254791484, 0.1711129375161791, -0.14176360113274494, 0.0068885077936485135, -0.04468608642797071, 0.17804111587461052, 0.1447229338265655]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"Freq\": [1816.0, 3987.0, 1187.0, 957.0, 1506.0, 794.0, 2114.0, 1282.0, 1509.0, 648.0, 676.0, 1145.0, 680.0, 496.0, 563.0, 855.0, 1124.0, 802.0, 740.0, 509.0, 2213.0, 687.0, 425.0, 572.0, 448.0, 495.0, 782.0, 560.0, 721.0, 390.0, 571.3887590285395, 319.81529077597867, 193.85922755265537, 422.0046735450443, 594.0282788766264, 262.54833211814633, 163.784053687264, 202.12331382043968, 160.06022615432713, 130.03959633459928, 168.43601391589152, 119.89492813294231, 188.49160971598758, 99.82654209887431, 210.78595876006958, 225.12235222493038, 102.34454422646475, 204.19189360575692, 804.7370066289568, 88.19271051819987, 106.68792081824242, 86.27683926023934, 145.54817667436274, 129.3823067125217, 194.09257737055268, 703.0728971275844, 241.70461150493324, 252.47164937069016, 961.8150068034707, 63.147502546615776, 575.8137307543773, 435.4691841217418, 287.99790542910625, 259.33868671460755, 326.301330346834, 167.38079493888281, 174.70711412858046, 182.90190824678587, 153.58166929661735, 1815.3920442688805, 368.93892729630426, 330.50464693939756, 251.01533460148107, 155.52860930444552, 261.2491725864951, 581.1893473796019, 113.26549594943037, 137.9710667081081, 226.5239190470707, 245.84401331476465, 343.146944171467, 188.70420896468005, 76.91967733782943, 92.00382312541257, 571.6818623969278, 198.30442569304432, 94.82256325545946, 57.37672624520303, 44.20416562988435, 124.52125936228451, 490.5088092908045, 47.04416686924247, 179.64141757958797, 60.610090032627085, 115.76243297092653, 83.37249482351979, 36.798132530809845, 137.78999449535473, 57.017525861929236, 187.8961342046961, 273.17112164231315, 139.38857092360107, 157.6386994982204, 81.18807225665854, 100.22301367864891, 103.11663385748108, 300.3023153008699, 239.61364444364008, 239.61364444314756, 182.0660203828219, 213.07417909280323, 163.49074190332348, 160.06043320736666, 132.98425959259447, 381.3806364363787, 130.30699189304045, 112.09223647519855, 136.4404959798241, 120.20497394560091, 162.7381270787255, 256.1482958950354, 108.66758957062976, 138.91833210238954, 135.6446234993574, 132.05945246671806, 118.07878934899561, 99.21281521037919, 122.15558089749761, 76.82961664786045, 80.26872958399088, 375.8257680171118, 97.95734502459139, 80.26979920937849, 119.96838579074219, 76.21726061088542, 81.8996945791139, 532.3347114185568, 181.9657451386679, 182.25215279196013, 150.79098815628336, 287.88092786004006, 159.30794094246406, 238.20855159637907, 158.84574047402438, 133.51597534062995, 148.28621665522118, 138.96228728610504, 121.65814638710465, 647.4678313593572, 562.2231197678593, 447.26518178795783, 233.75698268086254, 165.17231788981087, 607.087739061742, 284.0452296443797, 192.39570043160796, 272.8243325594815, 361.8187273666001, 121.4410470531391, 318.73738697897363, 80.52968078014914, 75.5495064300705, 86.2848631704121, 59.847147066482535, 305.09479697166705, 87.40061008373328, 66.03663961900274, 70.79175548898971, 124.48041206392584, 329.5570166765282, 48.09663751460269, 63.434401149732004, 450.87435976584857, 460.70070532393703, 56.39825623625255, 29.115204321735348, 54.72260990707815, 65.57908626616914, 135.404685054076, 180.37092843584315, 171.47161522387802, 96.92444900856961, 98.91452599494697, 194.07577073955494, 508.46714352383236, 195.67175643477307, 236.495066126309, 349.090162425141, 531.0218999375318, 628.4561203730456, 914.6462764862351, 156.54446022011723, 273.04326569931584, 1474.3309694787902, 101.56322800827115, 231.51395266336044, 75.94228873420343, 103.34946479769302, 58.49982931001057, 63.601265715939746, 67.08660619775337, 46.02192994899468, 46.44955462523021, 39.850339448820606, 62.27072064165931, 33.44697491186165, 103.26002464010806, 254.51569974582878, 37.859811635152916, 65.04808220085508, 391.6300267894764, 75.94529754361726, 36.096345580052834, 57.908422460791, 229.73085563350375, 95.1916743898188, 168.22167205657706, 60.54691868851327, 77.6262794478826, 266.68108537591434, 225.48839372725763, 177.29384449623782, 199.26181464347994, 150.74312502726153, 431.41555081834605, 120.68966043231214, 174.42616602218575, 295.6261590333291, 114.27010952333347, 426.35196218140635, 336.36572476023684, 78.68419976150088, 143.38120249330638, 106.90024565381617, 133.80218648735624, 108.15085805216557, 70.96170377738676, 66.61286682007788, 76.11367757409793, 101.48516520240516, 191.91749676147842, 74.78332458821382, 77.19638257865326, 75.40051567173455, 57.423316955768044, 143.6622488910799, 55.53180012961866, 47.81864777810069, 334.0501683964304, 159.3651889453922, 178.1173160821014, 322.06836591417334, 119.06939678881899, 87.06689846937354, 956.2633246981823, 794.0067212173964, 159.1621495729958, 1113.6958359322848, 138.50381279689057, 111.7374121265291, 153.70194451131027, 82.43524856903015, 94.05634313118692, 145.78718722623876, 69.08874035540317, 66.88152675868031, 86.40018520345049, 73.87337530156786, 69.66158151348108, 144.62968204438167, 164.57665676049547, 119.26290283444177, 32.3139724811433, 536.9592375961514, 69.17471660960483, 27.758342352274187, 32.30338159210389, 30.15553903659197, 64.17570922064813, 18.285028823084303, 30.853266350386935, 22.908899357923257, 29.679538059439064, 25.130973217688815, 109.30517209849755, 71.44261063720556, 59.17502577423083, 40.08752439687384, 52.243002696596804, 43.14192001420124, 496.05763218893446, 201.50040502220764, 182.49824555446503, 395.9181224312919, 179.03181030424673, 525.8398715569756, 338.6990233819188, 491.22378643675717, 315.8838223071458, 81.07013057907814, 147.7595388668973, 160.09542764169566, 77.39101327250616, 128.65734167727737, 125.09922140790138, 213.59994801033136, 33.75952451060993, 836.3694636174239, 40.403962744588604, 34.01829036224873, 189.68398266320582, 49.43047380650325, 27.342324092009232, 40.93446352418987, 38.444306774333945, 35.402237418236446, 47.40750723480364, 16.035486973382515, 73.14721056425466, 14.023771215862162, 85.81504203814183, 62.06826255381879, 43.740637868372396, 249.2166857678609, 154.777412845335, 225.46907379100742, 295.40524976637727, 174.7005722728565, 336.1903889401175, 204.63771181661699, 395.7038090025837, 441.853559049288, 680.8348312558525, 235.67224289703992, 45.12134641367872, 166.4826584007491, 100.40681524064304, 59.24080322792377, 144.44013648373715, 39.123475511636755, 112.13170499070783, 77.09064741932079, 38.0077367061645, 55.842089165610275, 248.8032672561096, 130.84801711195848, 58.992568909309604, 56.49746993329415, 22.33661189256943, 209.4296330501162, 37.53984344098786, 41.70187693301113, 166.88612712860333, 51.37267952964884, 61.478859606372886, 66.69082721194562, 178.6857962890797, 322.4493701156994, 246.9575194534223, 214.19429214194986, 160.32161880482914, 741.6785460966163, 234.39473043502753, 166.919097403518, 83.93485161181509, 74.67471257232357, 89.64921051386531, 78.30223374554332, 138.11646126930108, 175.33896158327659, 62.85058080771793, 103.84030647896536, 45.325132158194776, 67.56196011284726, 37.5059197073415, 204.0736352363769, 197.05739253481389, 94.89216001087568, 30.100748327068633, 27.206747058752168, 42.94511165192435, 558.6586474916522, 28.52892790690509, 22.14783212018354, 32.09031803488736, 251.03517684376132, 127.90388523360038, 54.99933494940377, 43.92073254928823, 31.288214535900725], \"Term\": [\"veri\", \"love\", \"old\", \"year\", \"toy\", \"year old\", \"cute\", \"daughter\", \"n't\", \"anim\", \"kid\", \"gift\", \"stuf\", \"granddaught\", \"super\", \"perfect\", \"great\", \"realli\", \"qualiti\", \"daughter love\", \"'s\", \"size\", \"cat\", \"doe\", \"stuf anim\", \"work\", \"christma\", \"price\", \"son\", \"s\", \"doe\", \"doe n't\", \"month old\", \"onli\", \"play\", \"month\", \"actual\", \"sinc\", \"feel\", \"adult\", \"head\", \"star\", \"'m\", \"sound\", \"sleep\", \"thing\", \"hand\", \"fun\", \"n't\", \"someth\", \"bit\", \"night\", \"face\", \"right\", \"say\", \"like\", \"becaus\", \"make\", \"'s\", \"goe\", \"toy\", \"just\", \"realli\", \"got\", \"littl\", \"want\", \"look\", \"daughter\", \"cute\", \"veri\", \"veri soft\", \"veri cute\", \"high\", \"good qualiti\", \"recommend\", \"qualiti\", \"materi\", \"fur\", \"happi\", \"product\", \"good\", \"nice\", \"definit\", \"gund\", \"soft\", \"plush\", \"cudd\", \"worth\", \"review\", \"small\", \"cute\", \"feel\", \"look\", \"smaller\", \"buy\", \"pictur\", \"exact\", \"size\", \"came\", \"great\", \"'s\", \"bought\", \"like\", \"want\", \"realli\", \"littl\", \"order\", \"ca n't\", \"ca\", \"ship\", \"amazon\", \"box\", \"anoth\", \"tail\", \"pusheen\", \"review\", \"wait\", \"disappoint\", \"exact\", \"ve\", \"pictur\", \"store\", \"gund\", \"receiv\", \"better\", \"open\", \"plastic\", \"differ\", \"place\", \"someth\", \"look\", \"real\", \"way\", \"come\", \"said\", \"present\", \"n't\", \"purchas\", \"buy\", \"product\", \"like\", \"price\", \"just\", \"qualiti\", \"expect\", \"bought\", \"christma\", \"color\", \"anim\", \"super\", \"stuf anim\", \"super cute\", \"super soft\", \"stuf\", \"friend\", \"did n't\", \"birthday\", \"purchas\", \"best\", \"did\", \"collect\", \"quick\", \"absolut\", \"favorit\", \"gift\", \"cudd\", \"ani\", \"know\", \"buy\", \"soft\", \"gave\", \"come\", \"cute\", \"'s\", \"day\", \"wait\", \"thought\", \"thing\", \"bought\", \"littl\", \"n't\", \"son\", \"ador\", \"love\", \"daughter love\", \"perfect size\", \"grandson\", \"bear\", \"size\", \"perfect\", \"daughter\", \"carri\", \"babi\", \"love\", \"big\", \"ador\", \"right\", \"birthday\", \"real\", \"new\", \"face\", \"easi\", \"present\", \"hand\", \"thought\", \"goe\", \"small\", \"just\", \"favorit\", \"sleep\", \"'s\", \"use\", \"everi\", \"cudd\", \"littl\", \"plush\", \"soft\", \"nice\", \"bought\", \"batteri\", \"guy\", \"long\", \"t\", \"son love\", \"work\", \"awesom\", \"arriv\", \"use\", \"tri\", \"son\", \"time\", \"quick\", \"day\", \"talk\", \"came\", \"new\", \"sound\", \"store\", \"present\", \"hold\", \"make\", \"worth\", \"need\", \"ani\", \"disappoint\", \"did\", \"bit\", \"easi\", \"littl\", \"christma\", \"just\", \"love\", \"got\", \"toy\", \"year\", \"year old\", \"old love\", \"old\", \"absolut love\", \"hit\", \"absolut\", \"night\", \"everi\", \"doll\", \"gave\", \"carri\", \"sleep\", \"big\", \"niec\", \"christma\", \"bought\", \"son\", \"open\", \"love\", \"becaus\", \"did n't\", \"girl\", \"receiv\", \"time\", \"son love\", \"day\", \"dog\", \"grandson\", \"face\", \"daughter\", \"toy\", \"gift\", \"play\", \"cute\", \"like\", \"granddaught\", \"kid love\", \"granddaught love\", \"cat\", \"pretti\", \"kid\", \"christma\", \"gift\", \"got\", \"gave\", \"happi\", \"want\", \"sure\", \"pusheen\", \"buy\", \"bought\", \"place\", \"love\", \"open\", \"anoth\", \"great\", \"month\", \"said\", \"'m\", \"eye\", \"face\", \"onli\", \"collect\", \"ador\", \"goe\", \"littl\", \"soft\", \"just\", \"item\", \"realli cute\", \"girl\", \"think\", \"lot\", \"price\", \"doll\", \"realli\", \"great\", \"cute\", \"ador\", \"place\", \"plush\", \"fun\", \"worth\", \"babi\", \"collect\", \"expect\", \"color\", \"best\", \"cudd\", \"littl\", \"perfect\", \"nice\", \"say\", \"goe\", \"like\", \"absolut\", \"child\", \"soft\", \"play\", \"bought\", \"'s\", \"nephew\", \"s\", \"niec\", \"smaller\", \"dog\", \"toy\", \"expect\", \"child\", \"favorit\", \"way\", \"thought\", \"new\", \"small\", \"good\", \"lot\", \"thing\", \"adult\", \"come\", \"hit\", \"great\", \"gift\", \"plush\", \"best\", \"hand\", \"day\", \"love\", \"bit\", \"collect\", \"differ\", \"cute\", \"soft\", \"babi\", \"price\", \"cudd\"], \"Total\": [1816.0, 3987.0, 1187.0, 957.0, 1506.0, 794.0, 2114.0, 1282.0, 1509.0, 648.0, 676.0, 1145.0, 680.0, 496.0, 563.0, 855.0, 1124.0, 802.0, 740.0, 509.0, 2213.0, 687.0, 425.0, 572.0, 448.0, 495.0, 782.0, 560.0, 721.0, 390.0, 572.2970842164875, 320.7235777881766, 194.76755269992796, 470.22013738346635, 686.3665663948842, 312.7867258551245, 200.69056520715026, 248.4521984023975, 207.91396971100764, 176.17050186440773, 228.5539364657795, 193.91560661515155, 315.4329344968688, 171.5944069817022, 362.9408139405118, 395.2471854497114, 181.0559503315135, 369.1799990369949, 1509.250698053775, 169.2691248347957, 205.68398244859242, 169.51684781529508, 287.4138629549388, 259.14506548902403, 389.27243272244726, 1458.1465246585174, 526.6279840474388, 559.5104050453803, 2213.568001344535, 154.91222024325603, 1506.1919368881724, 1253.0871008345239, 802.725170797664, 771.9963932807912, 1508.7436086256796, 483.39234109828226, 806.3222563689199, 1282.6180214589986, 2114.012416192567, 1816.861123326479, 369.8478818695768, 331.41359513329274, 251.92434809991238, 160.76289519092458, 316.5909476877437, 740.8434002325396, 159.6277933711969, 202.75454161070792, 419.6972041340647, 460.2961197520774, 662.0564613533346, 396.2876799307709, 190.74160151836324, 231.73042368712086, 1482.285813049453, 597.9788657848147, 332.61934095036304, 220.95860183987494, 175.3194805134502, 495.0767941499978, 2114.012416192567, 207.91396971100764, 806.3222563689199, 275.6107989137723, 548.2017255170625, 398.06306658781494, 179.75443687881528, 687.254269302686, 299.9339653072576, 1124.213705120037, 2213.568001344535, 968.0176458243617, 1458.1465246585174, 483.39234109828226, 802.725170797664, 1508.7436086256796, 301.2097032130157, 240.52099564737236, 240.52099564737034, 197.04784341226073, 233.5819741593002, 192.26579297593145, 194.88572779115415, 169.85977805913595, 510.84488561769035, 175.3194805134502, 152.61292423086812, 194.66916617155275, 179.75443687881528, 243.96371213409728, 398.06306658781494, 176.08568743825055, 231.73042368712086, 246.71449230343808, 245.61342210678336, 225.34244281274684, 189.70192178745484, 247.86555481081544, 159.86164358791547, 169.2691248347957, 806.3222563689199, 226.52078883188955, 193.10105534106938, 294.5034617079773, 190.00584718650452, 205.17000365838737, 1509.250698053775, 544.5915469005454, 548.2017255170625, 460.2961197520774, 1458.1465246585174, 560.2347569717011, 1253.0871008345239, 740.8434002325396, 480.74828747304923, 968.0176458243617, 782.2574053391763, 368.6736689721199, 648.3754997828925, 563.1307780248601, 448.17280637965507, 234.66459204841507, 166.07995587231053, 680.1266027942536, 319.1320287441189, 220.9581440004988, 376.98331366438634, 544.5915469005454, 190.2534568728079, 499.96959817806743, 163.25003746859122, 155.10121492451984, 295.3106995341967, 205.24295576192287, 1145.1046678692635, 332.61934095036304, 255.25051456621372, 289.32644305118197, 548.2017255170625, 1482.285813049453, 220.2770535405828, 294.5034617079773, 2114.012416192567, 2213.568001344535, 291.46571283492426, 152.61292423086812, 286.97243317700213, 395.2471854497114, 968.0176458243617, 1508.7436086256796, 1509.250698053775, 721.0306879580162, 782.1205901851771, 3987.3678261114737, 509.37697452102844, 196.78088495321086, 283.00816198764625, 422.9721873274074, 687.254269302686, 855.6611589151609, 1282.6180214589986, 224.2322947518737, 551.7706260406817, 3987.3678261114737, 322.17294486812733, 782.1205901851771, 259.14506548902403, 376.98331366438634, 226.52078883188955, 250.7595668444348, 287.4138629549388, 202.7770922625851, 205.17000365838737, 181.0559503315135, 286.97243317700213, 154.91222024325603, 495.0767941499978, 1253.0871008345239, 205.24295576192287, 362.9408139405118, 2213.568001344535, 433.3548627193915, 206.39362797164983, 332.61934095036304, 1508.7436086256796, 597.9788657848147, 1482.285813049453, 396.2876799307709, 968.0176458243617, 267.5869558819049, 226.39434374789295, 178.1997745557452, 224.1230435896602, 169.83042222326264, 495.2300188417465, 157.66735549529056, 241.6518874596001, 433.3548627193915, 190.36150883323958, 721.0306879580162, 587.5100317563932, 155.10121492451984, 291.46571283492426, 222.7741202142234, 299.9339653072576, 250.7595668444348, 171.5944069817022, 176.08568743825055, 205.17000365838737, 281.06054172819853, 559.5104050453803, 220.95860183987494, 242.99198652929047, 255.25051456621372, 194.66916617155275, 499.96959817806743, 205.68398244859242, 202.7770922625851, 1508.7436086256796, 782.2574053391763, 1253.0871008345239, 3987.3678261114737, 771.9963932807912, 1506.1919368881724, 957.1677660681456, 794.9111282166645, 160.06655917050003, 1187.9071617062139, 152.2906863476184, 179.9047633932562, 295.3106995341967, 169.51684781529508, 206.39362797164983, 351.3826076579677, 220.2770535405828, 224.2322947518737, 362.9408139405118, 322.17294486812733, 317.42098964214694, 782.2574053391763, 968.0176458243617, 721.0306879580162, 225.34244281274684, 3987.3678261114737, 526.6279840474388, 220.9581440004988, 258.5760044730684, 246.71449230343808, 587.5100317563932, 169.83042222326264, 291.46571283492426, 217.32138296669956, 283.00816198764625, 287.4138629549388, 1282.6180214589986, 1506.1919368881724, 1145.1046678692635, 686.3665663948842, 2114.012416192567, 1458.1465246585174, 496.96520576310866, 202.40795177517978, 183.40577825899214, 425.5577791886392, 227.68965102536086, 676.0294808328654, 782.2574053391763, 1145.1046678692635, 771.9963932807912, 220.2770535405828, 419.6972041340647, 483.39234109828226, 274.65933721371283, 510.84488561769035, 548.2017255170625, 968.0176458243617, 159.86164358791547, 3987.3678261114737, 225.34244281274684, 194.88572779115415, 1124.213705120037, 312.7867258551245, 190.00584718650452, 315.4329344968688, 302.12706692431107, 287.4138629549388, 470.22013738346635, 163.25003746859122, 782.1205901851771, 154.91222024325603, 1508.7436086256796, 1482.285813049453, 1253.0871008345239, 250.12353270555127, 155.68423377063044, 258.5760044730684, 352.8079176320336, 238.35549329638408, 560.2347569717011, 351.3826076579677, 802.725170797664, 1124.213705120037, 2114.012416192567, 782.1205901851771, 159.86164358791547, 597.9788657848147, 369.1799990369949, 220.95860183987494, 551.7706260406817, 163.25003746859122, 480.74828747304923, 368.6736689721199, 190.2534568728079, 332.61934095036304, 1508.7436086256796, 855.6611589151609, 396.2876799307709, 389.27243272244726, 154.91222024325603, 1458.1465246585174, 295.3106995341967, 356.16432012768576, 1482.285813049453, 686.3665663948842, 968.0176458243617, 2213.568001344535, 179.59127696379252, 390.7558165422686, 317.42098964214694, 275.6107989137723, 217.32138296669956, 1506.1919368881724, 480.74828747304923, 356.16432012768576, 205.24295576192287, 193.10105534106938, 286.97243317700213, 250.7595668444348, 495.0767941499978, 662.0564613533346, 238.35549329638408, 395.2471854497114, 176.17050186440773, 294.5034617079773, 179.9047633932562, 1124.213705120037, 1145.1046678692635, 597.9788657848147, 190.2534568728079, 181.0559503315135, 291.46571283492426, 3987.3678261114737, 205.68398244859242, 163.25003746859122, 247.86555481081544, 2114.012416192567, 1482.285813049453, 551.7706260406817, 560.2347569717011, 332.61934095036304], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.7545, 1.7533, 1.7514, 1.6479, 1.6116, 1.581, 1.5529, 1.5497, 1.4945, 1.4525, 1.4509, 1.2753, 1.2412, 1.2144, 1.2127, 1.1932, 1.1857, 1.1639, 1.1273, 1.1041, 1.0997, 1.0807, 1.0757, 1.0615, 1.0602, 1.0267, 0.9773, 0.9604, 0.9226, 0.8587, 0.7946, 0.6992, 0.7311, 0.6653, 0.2249, 0.6956, 0.2267, -0.1916, -0.866, 2.1171, 2.1154, 2.1151, 2.1143, 2.0848, 1.9257, 1.8752, 1.7748, 1.7329, 1.5012, 1.4907, 1.4607, 1.3759, 1.2097, 1.1941, 1.1651, 1.0141, 0.8629, 0.7695, 0.7401, 0.7376, 0.657, 0.6318, 0.6164, 0.6034, 0.5628, 0.5546, 0.5317, 0.5109, 0.4577, 0.3289, 0.0256, 0.1799, -0.1067, 0.3338, 0.0373, -0.5653, 2.1948, 2.194, 2.194, 2.1187, 2.1059, 2.0357, 2.0009, 1.9531, 1.9055, 1.9011, 1.8892, 1.8424, 1.7954, 1.7929, 1.7569, 1.7151, 1.6861, 1.5996, 1.5773, 1.5515, 1.5496, 1.4902, 1.4651, 1.4517, 1.4344, 1.3595, 1.32, 1.2997, 1.2843, 1.2795, 1.1557, 1.1016, 1.0966, 1.0818, 0.5754, 0.9403, 0.5376, 0.6579, 0.9167, 0.3217, 0.4698, 1.0891, 2.2288, 2.2286, 2.2282, 2.2264, 2.2248, 2.1166, 2.1138, 2.0918, 1.9069, 1.8213, 1.7813, 1.7801, 1.5236, 1.5109, 0.9999, 0.9978, 0.9076, 0.8937, 0.8782, 0.8224, 0.7477, 0.7266, 0.7086, 0.695, 0.6851, 0.6606, 0.5878, 0.5736, 0.5731, 0.434, 0.2633, 0.1062, 0.0553, 0.2235, 0.1625, -0.7924, 2.2645, 2.2607, 2.0868, 2.0744, 2.0084, 1.9577, 1.9282, 1.907, 1.5628, 1.2714, 1.1119, 1.049, 1.0389, 0.9722, 0.9125, 0.8945, 0.8114, 0.7833, 0.7809, 0.7527, 0.7384, 0.7334, 0.6989, 0.6723, 0.576, 0.5472, 0.5343, 0.5248, 0.5227, 0.5182, 0.3842, 0.4287, 0.0903, 0.3876, -0.257, 2.4118, 2.4111, 2.4101, 2.2976, 2.2959, 2.2772, 2.1479, 2.0892, 2.0327, 1.9048, 1.8897, 1.8575, 1.7365, 1.7057, 1.6809, 1.608, 1.5742, 1.5322, 1.4431, 1.4235, 1.3965, 1.3452, 1.3318, 1.2685, 1.1957, 1.1943, 1.1681, 1.1058, 0.9705, 0.9074, 0.8242, 0.4642, -0.101, 0.5459, -0.4355, 2.5288, 2.5286, 2.5241, 2.4652, 2.4348, 2.0535, 1.8767, 1.8088, 1.7438, 1.65, 1.3702, 1.32, 1.0945, 1.057, 1.0132, 0.8417, 0.7579, 0.7304, 0.5876, 0.5248, 0.4999, 0.4553, 0.4497, 0.4279, 0.3155, 0.301, 0.2841, 0.2799, 0.2747, 0.0929, 0.0672, -0.5187, -0.433, -0.3106, -1.1707, -0.9907, 2.5805, 2.5779, 2.5774, 2.5102, 2.3419, 2.3311, 1.7453, 1.736, 1.6887, 1.5828, 1.5384, 1.4773, 1.3157, 1.2034, 1.1048, 1.0712, 1.0273, 1.0205, 0.8637, 0.8368, 0.8029, 0.7374, 0.6437, 0.5404, 0.5207, 0.4882, 0.2879, 0.2619, 0.2128, 0.1802, -0.2845, -0.5908, -0.7727, 2.6275, 2.6253, 2.4941, 2.4535, 2.3204, 2.1204, 2.0905, 1.9237, 1.6972, 1.4981, 1.4315, 1.3661, 1.3524, 1.329, 1.3147, 1.2908, 1.2025, 1.1754, 1.0662, 1.0205, 0.8466, 0.8287, 0.7533, 0.7264, 0.701, 0.6945, 0.6906, 0.5685, 0.4862, 0.4471, 0.0388, -0.1255, -0.8712, 2.6813, 2.4942, 2.4354, 2.4343, 2.3822, 1.9779, 1.968, 1.9285, 1.7922, 1.7363, 1.5229, 1.5225, 1.4098, 1.3577, 1.3534, 1.3497, 1.3288, 1.2141, 1.1184, 0.98, 0.9266, 0.8456, 0.8426, 0.791, 0.7714, 0.721, 0.7109, 0.6888, 0.642, 0.5556, 0.2363, 0.3806, 0.1404, 0.3226], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.149, -3.7293, -4.2299, -3.4521, -3.1101, -3.9266, -4.3985, -4.1882, -4.4215, -4.6292, -4.3705, -4.7105, -4.258, -4.8936, -4.1462, -4.0804, -4.8687, -4.178, -2.8066, -5.0175, -4.8272, -5.0395, -4.5166, -4.6343, -4.2287, -2.9416, -4.0094, -3.9658, -2.6282, -5.3516, -3.1413, -3.4206, -3.8341, -3.9389, -3.7092, -4.3768, -4.334, -4.2881, -4.4628, -1.6312, -3.2247, -3.3347, -3.6098, -4.0885, -3.5698, -2.7702, -4.4056, -4.2083, -3.7125, -3.6306, -3.2971, -3.8951, -4.7925, -4.6135, -2.7867, -3.8455, -4.5833, -5.0857, -5.3465, -4.3108, -2.9399, -5.2842, -3.9443, -5.0308, -4.3838, -4.712, -5.5299, -4.2096, -5.0919, -3.8994, -3.5252, -4.198, -4.075, -4.7385, -4.5279, -4.4994, -3.3506, -3.5764, -3.5764, -3.851, -3.6937, -3.9586, -3.9798, -4.1651, -3.1116, -4.1855, -4.3361, -4.1395, -4.2662, -3.9632, -3.5096, -4.3671, -4.1215, -4.1453, -4.1721, -4.284, -4.4581, -4.2501, -4.7138, -4.67, -3.1263, -4.4708, -4.67, -4.2682, -4.7218, -4.6499, -2.7781, -3.8516, -3.85, -4.0395, -3.3928, -3.9845, -3.5822, -3.9874, -4.1612, -4.0562, -4.1212, -4.2542, -2.5499, -2.691, -2.9198, -3.5687, -3.916, -2.6143, -3.3738, -3.7634, -3.4141, -3.1318, -4.2235, -3.2586, -4.6343, -4.6982, -4.5653, -4.9311, -3.3023, -4.5524, -4.8327, -4.7632, -4.1988, -3.2252, -5.1497, -4.8729, -2.9118, -2.8902, -4.9905, -5.6517, -5.0207, -4.8397, -4.1147, -3.8279, -3.8785, -4.449, -4.4287, -3.7547, -2.7555, -3.7104, -3.5209, -3.1315, -2.7121, -2.5436, -2.1683, -3.9335, -3.3772, -1.6909, -4.3662, -3.5422, -4.6569, -4.3487, -4.9178, -4.8342, -4.7809, -5.1577, -5.1485, -5.3017, -4.8554, -5.4769, -4.3496, -3.4475, -5.353, -4.8117, -3.0165, -4.6568, -5.4007, -4.928, -3.5499, -4.431, -3.8616, -4.8834, -4.6349, -3.252, -3.4198, -3.6602, -3.5434, -3.8225, -2.771, -4.0448, -3.6765, -3.1489, -4.0995, -2.7828, -3.0198, -4.4726, -3.8725, -4.1661, -3.9417, -4.1545, -4.5759, -4.6391, -4.5058, -4.2181, -3.581, -4.5234, -4.4917, -4.5152, -4.7876, -3.8706, -4.8211, -4.9706, -3.0267, -3.7668, -3.6556, -3.0633, -4.0583, -4.3714, -1.8604, -2.0464, -3.6535, -1.708, -3.7925, -4.0073, -3.6884, -4.3114, -4.1795, -3.7413, -4.4881, -4.5205, -4.2645, -4.4211, -4.4798, -3.7493, -3.6201, -3.9421, -5.2479, -2.4375, -4.4868, -5.3999, -5.2483, -5.3171, -4.5618, -5.8174, -5.2942, -5.5919, -5.333, -5.4993, -4.0293, -4.4545, -4.6429, -5.0324, -4.7675, -4.9589, -2.4641, -3.365, -3.4641, -2.6896, -3.4833, -2.4058, -2.8457, -2.4739, -2.9155, -4.2755, -3.6753, -3.5951, -4.322, -3.8137, -3.8417, -3.3067, -5.1516, -1.9418, -4.9719, -5.1439, -3.4255, -4.7703, -5.3624, -4.9589, -5.0216, -5.1041, -4.8121, -5.896, -4.3784, -6.0301, -4.2186, -4.5426, -4.8926, -3.1038, -3.5801, -3.2039, -2.9337, -3.459, -2.8044, -3.3008, -2.6414, -2.5311, -2.0988, -3.1596, -4.8127, -3.5072, -4.0129, -4.5405, -3.6492, -4.9554, -3.9024, -4.2771, -4.9843, -4.5996, -3.1054, -3.7481, -4.5447, -4.5879, -5.5159, -3.2777, -4.9967, -4.8915, -3.5048, -4.683, -4.5034, -4.422, -3.3812, -2.7909, -3.0576, -3.1999, -3.4896, -1.9579, -3.1098, -3.4493, -4.1368, -4.2537, -4.0709, -4.2062, -3.6387, -3.4001, -4.4261, -3.924, -4.753, -4.3538, -4.9423, -3.2483, -3.2833, -4.0141, -5.1623, -5.2633, -4.8069, -2.2413, -5.2159, -5.4691, -5.0983, -3.0412, -3.7155, -4.5595, -4.7844, -5.1236]}, \"token.table\": {\"Topic\": [1, 2, 3, 8, 1, 2, 4, 5, 6, 9, 3, 4, 7, 9, 3, 7, 9, 1, 5, 6, 1, 2, 4, 5, 6, 7, 8, 9, 1, 10, 2, 3, 1, 2, 4, 6, 9, 4, 3, 8, 3, 4, 6, 1, 2, 6, 1, 5, 9, 10, 6, 2, 4, 5, 1, 3, 4, 5, 6, 7, 9, 10, 4, 9, 10, 1, 3, 6, 1, 3, 4, 5, 6, 7, 4, 5, 1, 5, 6, 10, 2, 3, 4, 5, 6, 7, 8, 9, 3, 6, 2, 3, 4, 8, 3, 3, 2, 3, 4, 6, 7, 5, 7, 1, 8, 1, 5, 9, 10, 3, 6, 7, 8, 3, 4, 8, 9, 10, 1, 3, 7, 9, 10, 1, 3, 4, 6, 10, 2, 4, 5, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 10, 1, 5, 6, 7, 8, 5, 4, 6, 7, 8, 10, 1, 2, 3, 4, 6, 4, 6, 7, 10, 4, 7, 1, 3, 5, 9, 10, 3, 6, 1, 1, 6, 7, 10, 7, 9, 1, 2, 5, 6, 7, 1, 5, 6, 7, 2, 3, 6, 10, 3, 9, 10, 1, 2, 3, 6, 7, 8, 1, 5, 7, 8, 10, 4, 5, 6, 10, 1, 2, 1, 4, 1, 6, 7, 9, 1, 2, 4, 7, 8, 10, 3, 4, 5, 7, 8, 10, 7, 9, 1, 4, 5, 7, 8, 9, 1, 2, 3, 5, 10, 2, 3, 1, 4, 6, 8, 10, 8, 8, 5, 7, 8, 1, 2, 4, 8, 9, 10, 2, 3, 6, 1, 5, 6, 10, 1, 2, 6, 8, 1, 3, 5, 7, 2, 1, 7, 9, 10, 1, 3, 6, 9, 1, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 8, 8, 1, 3, 4, 6, 10, 1, 2, 3, 4, 7, 9, 1, 2, 4, 5, 6, 8, 9, 6, 1, 2, 3, 4, 6, 9, 10, 1, 3, 4, 5, 6, 7, 8, 10, 1, 2, 4, 6, 7, 10, 2, 3, 6, 1, 8, 1, 1, 3, 4, 1, 2, 3, 4, 5, 6, 10, 5, 6, 10, 1, 2, 5, 7, 9, 7, 10, 1, 7, 1, 7, 7, 1, 8, 1, 3, 7, 8, 3, 2, 5, 7, 9, 5, 1, 2, 3, 8, 3, 6, 8, 9, 1, 2, 3, 10, 1, 7, 9, 2, 3, 5, 9, 10, 3, 5, 6, 1, 6, 8, 2, 3, 9, 10, 2, 3, 4, 10, 3, 4, 3, 8, 2, 3, 4, 6, 1, 2, 3, 5, 9, 1, 2, 3, 9, 9, 3, 5, 6, 7, 9, 1, 2, 2, 3, 1, 3, 5, 6, 10, 1, 3, 6, 7, 8, 1, 3, 4, 6, 9, 10, 2, 3, 1, 2, 2, 4, 5, 9, 1, 5, 7, 1, 2, 4, 5, 10, 2, 10, 1, 2, 3, 4, 5, 8, 9, 10, 1, 3, 2, 3, 4, 6, 7, 6, 7, 1, 6, 1, 2, 3, 4, 8, 3, 6, 2, 4, 4, 4, 4, 4, 1, 3, 6, 8, 6, 10, 1, 3, 1, 6, 7, 10, 1, 4, 10, 6, 9, 1, 4, 5, 6, 10, 1, 3, 6, 7, 1, 2, 6, 7, 10, 1, 6, 10, 2, 5, 6, 10, 1, 3, 4, 2, 7, 2, 2, 3, 4, 10, 1, 2, 6, 8, 1, 3, 10, 1, 3, 6, 7, 1, 2, 6, 7, 9, 7, 7], \"Freq\": [0.5960062486812587, 0.07291565808334548, 0.19972549822829416, 0.12998008614857237, 0.4345924766782296, 0.12333029743571379, 0.20826105171378775, 0.17708965785640954, 0.026653800544714702, 0.03026787519484551, 0.057566488538392475, 0.29121870672363254, 0.5214846608772025, 0.12867803320346555, 0.04596472816480592, 0.9127281735582891, 0.03939833842697651, 0.8171784250581051, 0.04484515747270089, 0.13453547241810268, 0.016621477765880174, 0.054978734148680576, 0.12657894606324133, 0.2966294493603231, 0.08438596404216088, 0.025571504255200266, 0.09333599053148098, 0.3017437502113631, 0.737921494371722, 0.25543436343636533, 0.08562304549391399, 0.9118854345101839, 0.2507340684847002, 0.09794299550183602, 0.2585695081248471, 0.29382898650550804, 0.09402527568176258, 0.9978785444802386, 0.8209939322568617, 0.1744612106045831, 0.27312015103144616, 0.004138184106537063, 0.7200440345374489, 0.10147947208055957, 0.13319180710573444, 0.7674385076092318, 0.14317543608088948, 0.4947708107605422, 0.2609780100714948, 0.0996791010689737, 0.9978064854470562, 0.08511197917638426, 0.0874762008201727, 0.8251133536821695, 0.4595274222613293, 0.11583129238818632, 0.10443805051393848, 0.06266283030836309, 0.08165156676544282, 0.1310222815538501, 0.03987634655986742, 0.003797747291415945, 0.6359937001349383, 0.19973355872006326, 0.15768438846320784, 0.3827152408598109, 0.5374299126967558, 0.07735733591847242, 0.15830007085441472, 0.11484514944339891, 0.14278045606476622, 0.31660014170882944, 0.0372470754951564, 0.22969029888679782, 0.7241699834042027, 0.2732216420902303, 0.5202155205583061, 0.06806558212912417, 0.2722623285164967, 0.14099299155318576, 0.1435924237534202, 0.15288977493169922, 0.13946026767418512, 0.08057704354508473, 0.027892053534837022, 0.17045143826844847, 0.22107035023907862, 0.0630153802083355, 0.8477847123872158, 0.14563172973522723, 0.2116009392173822, 0.33199457704796176, 0.22619410743927065, 0.22801825346700672, 0.9978338870335703, 0.997833887033562, 0.1900418311797672, 0.20004403282080757, 0.09001981476936341, 0.4467650066331369, 0.07334947870096277, 0.7001667631048855, 0.29879728107023773, 0.06814585802024552, 0.9305434405523182, 0.3734231434308725, 0.0393076993085129, 0.11792309792553869, 0.4688846988944039, 0.17769087138233158, 0.20325790323590445, 0.18536098093840345, 0.43336118991806044, 0.03062786433333581, 0.4961714022000402, 0.0980091658666746, 0.23889734180001934, 0.1347626030666776, 0.3661774934358251, 0.3309159570308938, 0.06781064693256021, 0.20885679255228543, 0.027124258773024084, 0.0033955458255073975, 0.4074654990608877, 0.21391938700696606, 0.1426129246713107, 0.23089711613450303, 0.285611773893139, 0.2615602560916115, 0.17437350406107435, 0.012025758900763748, 0.003006439725190937, 0.16836062461069246, 0.09319963148091905, 0.07284725426417364, 0.2322597522318783, 0.006149443541780892, 0.2133383874879371, 0.0004730341185985302, 0.024597774167123568, 0.009933716490569134, 0.32213623476559905, 0.11873156376823107, 0.1426769287023073, 0.7133846435115365, 0.058474151107502995, 0.08498243294290435, 0.00077965534810004, 0.9972967476154115, 0.19213237624185453, 0.4906237464747357, 0.10635899399102662, 0.05832589993056299, 0.14753021747142403, 0.17825162276791895, 0.40368749862146347, 0.18873701234250242, 0.09436850617125121, 0.13631006446958507, 0.6380387950836685, 0.28801751251425783, 0.058003526825788035, 0.016000972917458767, 0.8689428528127325, 0.12672083270185683, 0.2461011577286668, 0.4922023154573336, 0.032275561669333354, 0.09682668500800005, 0.12910224667733342, 0.6986211667447613, 0.2928044595915544, 0.9977335473965182, 0.9977439208144077, 0.1518488404109624, 0.10583404028642833, 0.7362368019925449, 0.41550149841825673, 0.583409638190018, 0.3106859818189842, 0.1873978937955778, 0.22685008196306786, 0.23671312900494038, 0.0345206646465538, 0.21318487606625058, 0.1744239895087505, 0.1550435462300004, 0.45544041705062627, 0.20583636566892766, 0.6675774021694951, 0.07232088523502864, 0.05563145018079126, 0.2787321421452012, 0.23297014865867563, 0.48674120344759014, 0.3475358929900333, 0.15887355108115808, 0.2482399235643095, 0.0496479847128619, 0.06619731295048253, 0.12577489460591681, 0.507978280862848, 0.2331133206699371, 0.08698258233952877, 0.12177561527534027, 0.04871024611013611, 0.29233646425165805, 0.18514642735938344, 0.11206231129646892, 0.4092710499523213, 0.7695490602309879, 0.22605503644285269, 0.1065389774063114, 0.8899138112762481, 0.5525759806385326, 0.12460046622241423, 0.048756704173988176, 0.27087057874437875, 0.3156526087730309, 0.6806259376668479, 0.21790739992423544, 0.31324188739108844, 0.3677187373721473, 0.095334487466853, 0.07946871805991927, 0.26635119789313605, 0.000873282616043069, 0.051523674346541065, 0.42878176447714683, 0.1720366753604846, 0.1237547160078147, 0.8701503469299471, 0.40668192542248877, 0.08391849254749768, 0.2130238656974941, 0.058097417917498395, 0.0903737612049975, 0.14201591046499606, 0.1087520539454023, 0.5180827014343471, 0.10573116355803001, 0.001510445193686143, 0.264327908895075, 0.970373168601697, 0.02488136329747941, 0.33549379537812984, 0.07901591319716572, 0.15414579787643803, 0.40932833721810435, 0.02072548542876478, 0.9980578001197759, 0.9923351473855584, 0.8338982110710353, 0.10600400988191128, 0.05653547193701935, 0.040917487298456644, 0.16722799156760543, 0.04803357204601432, 0.16900701275449484, 0.39316368230256166, 0.18146016106272078, 0.3970130401358826, 0.5998349193357357, 0.99384108399172, 0.5633617664221362, 0.22092618291064167, 0.060754700300426456, 0.14912517346468313, 0.02859204179060201, 0.5408661238722213, 0.07862811492415553, 0.35263518208409145, 0.7350562523571061, 0.15313671924106376, 0.030627343848212755, 0.07875602703826137, 0.9963308504839485, 0.08337744769554158, 0.6225516094600437, 0.08337744769554158, 0.21122286749537197, 0.30242594523353555, 0.33088956360845656, 0.3593531819833775, 0.9955080887695845, 0.34714266846279174, 0.18993093125090674, 0.029527077547409873, 0.20349742634025722, 0.14204918387672857, 0.0039901456145148475, 0.03511328140773066, 0.028729048424506902, 0.01995072807257424, 0.20117465858507916, 0.01922993060004433, 0.778072576586409, 0.9979845071717691, 0.32143622621990436, 0.3006984051734589, 0.2453975490496044, 0.05184455261611361, 0.08295128418578177, 0.48211890102377414, 0.10835673735669461, 0.19751101492865855, 0.039090721704630335, 0.02948949181226499, 0.14333264625031122, 0.21607382336946876, 0.06826872333452541, 0.11930456505062692, 0.1524447220091344, 0.22137624848282997, 0.05700106996863286, 0.16503798165336725, 0.9932672498675363, 0.21703481284030382, 0.22323580749288394, 0.46631479787402424, 0.06200994652580109, 0.03224517219341657, 0.7341974694176465, 0.2643110889903527, 0.015549104748749277, 0.0005015840241532025, 0.04865365034286064, 0.3696674258009102, 0.0807550278886656, 0.13467531048513487, 0.20966212209603866, 0.14019273475082009, 0.4503937687799765, 0.13047121079737414, 0.005361830580714006, 0.3431571571656964, 0.03395826034452204, 0.03574553720476004, 0.7078967741991579, 0.2631120753660587, 0.025058292892005587, 0.8408285207148319, 0.15665626431569113, 0.9960591346490321, 0.5333772586874216, 0.3524927970456004, 0.11330125619322869, 0.23457563689298522, 0.02880753435527889, 0.20988346458846047, 0.08230724101508254, 0.12757622357337794, 0.31688287790806774, 0.9967076520987613, 0.2552245595467313, 0.4306914442351091, 0.31105493194757877, 0.16402225779856472, 0.47692625729121124, 0.1539285803955761, 0.05803864506718444, 0.1488817416940818, 0.22052731950371768, 0.7781463988202609, 0.5073242046932425, 0.4837277300563475, 0.061452613767517573, 0.9377837224248572, 0.9933367770505771, 0.8974519941834336, 0.09995318418630658, 0.150881474326845, 0.5236474697225797, 0.1420060934840894, 0.17750761685511177, 0.9959838504533163, 0.0829767709568779, 0.7339353825481594, 0.0280484859572545, 0.15309798585001413, 0.9960317032144838, 0.07536494218657142, 0.20850967338284757, 0.6431141733254094, 0.07034061270746665, 0.48166651031367674, 0.025021636899411778, 0.2126839136450001, 0.2814934151183825, 0.2793856778076401, 0.12124284131274948, 0.5218713604331391, 0.0737999903642823, 0.8654267691387763, 0.058277896911702105, 0.07430431856242019, 0.3311153810430002, 0.0719088958830758, 0.15886849090446978, 0.27760178410675773, 0.15886849090446978, 0.39966856040287363, 0.22420431437234375, 0.3704245193977853, 0.004391943136179767, 0.20642132740044902, 0.7861578213761782, 0.03569932024230023, 0.28380959592628685, 0.5997485800706439, 0.07853850453306051, 0.5344385699633953, 0.3280496913189947, 0.10428069657822348, 0.032587717680694836, 0.3341954186322273, 0.6647183601366279, 0.7458232640213519, 0.2525228374245522, 0.7842413117504089, 0.21462025571138557, 0.49000260917998273, 0.5093448174370874, 0.238388716013503, 0.030902240964713352, 0.4326313735059869, 0.25604713942191065, 0.039731452668917165, 0.35877783639675315, 0.1245756376377615, 0.02242361477479707, 0.49331952504553556, 0.9956049899591084, 0.5512444718193994, 0.06079902262713964, 0.1905036042317042, 0.12159804525427928, 0.07295882715256757, 0.17372575053613648, 0.8244076525442113, 0.2509703991315694, 0.7415034519796369, 0.4977906862959879, 0.2045186540595919, 0.293272032236396, 0.17402172180498904, 0.8240440356059776, 0.32104275159555523, 0.39998769051249505, 0.09999692262812376, 0.031577975566775926, 0.14210089005049167, 0.4983656269806363, 0.09761800940857825, 0.053946794673161665, 0.17468485894166633, 0.1438581191284311, 0.028257844828798968, 0.07104873495473582, 0.9236335544115657, 0.813033659186373, 0.18514627882461962, 0.20079904362037646, 0.02473611406917681, 0.7726397982784051, 0.001455065533480989, 0.5813620069595815, 0.17909256138565308, 0.23695323506409482, 0.15149164914661015, 0.2524860819110169, 0.1090739873855593, 0.20804853149467795, 0.27874463442976266, 0.2213265962016404, 0.7764572391336237, 0.020913645483946728, 0.3858904908650816, 0.0161912094069265, 0.22262912934523937, 0.1133384658484855, 0.041827290967893456, 0.1126638321231969, 0.08635311683694133, 0.5198821703951431, 0.4726201549046755, 0.05270233380442837, 0.055476140846766706, 0.13452964155340927, 0.5908209000180654, 0.16504151901913094, 0.8891222080428689, 0.10598807777994464, 0.5827695771614713, 0.4137663997846446, 0.6188259010949758, 0.15470647527374395, 0.18564777032849272, 0.010313765018249595, 0.02578441254562399, 0.6190168070202977, 0.38049656945284355, 0.10586264337285577, 0.8924808962128258, 0.9973831380151575, 0.9979919797159263, 0.9971679065741714, 0.9934973738002384, 0.36772825939433385, 0.18932544048025107, 0.1565575757817461, 0.28034728686498717, 0.8879051293107674, 0.10708403569577095, 0.21193952100577193, 0.7829987859379907, 0.37257469548161964, 0.48030713754859394, 0.04488851752790598, 0.09875473856139315, 0.5692640157424409, 0.16698411128444934, 0.26312647838761716, 0.16156100005513205, 0.8361490353730517, 0.09060103687368265, 0.19165603954048252, 0.2160486263910894, 0.18468672901173772, 0.3136189737935169, 0.16680566237656175, 0.14978467641976972, 0.5719051281482117, 0.1089343101234689, 0.38242138063096354, 0.019917780241196018, 0.05776156269946845, 0.04713874657083057, 0.4926330979655815, 0.30468344338880576, 0.5988605611435147, 0.09455693070687075, 0.11999403831236422, 0.17537590214884, 0.6830429873165348, 0.02076819893867842, 0.16805778056641435, 0.66813215200794, 0.1598598400509795, 0.9989756380922107, 0.0005503998006017689, 0.9987520272572813, 0.9977074848575832, 0.7338827990122898, 0.19002322474425362, 0.07207777490299275, 0.3454750640454312, 0.1675657496268259, 0.15308475891833478, 0.3309940733369401, 0.19160951727916692, 0.4142908481711717, 0.3883976701604735, 0.010096318498006433, 0.07269349318564632, 0.8703026545281546, 0.04240453769162702, 0.07241175435928462, 0.25796687490495146, 0.3394300985591467, 0.058834550416918756, 0.26701834419986203, 0.9987799776491194, 0.9988537986394674], \"Term\": [\"'m\", \"'m\", \"'m\", \"'m\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \"absolut\", \"absolut\", \"absolut\", \"absolut\", \"absolut love\", \"absolut love\", \"absolut love\", \"actual\", \"actual\", \"actual\", \"ador\", \"ador\", \"ador\", \"ador\", \"ador\", \"ador\", \"ador\", \"ador\", \"adult\", \"adult\", \"amazon\", \"amazon\", \"ani\", \"ani\", \"ani\", \"ani\", \"ani\", \"anim\", \"anoth\", \"anoth\", \"arriv\", \"arriv\", \"arriv\", \"awesom\", \"awesom\", \"awesom\", \"babi\", \"babi\", \"babi\", \"babi\", \"batteri\", \"bear\", \"bear\", \"bear\", \"becaus\", \"becaus\", \"becaus\", \"becaus\", \"becaus\", \"becaus\", \"becaus\", \"becaus\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"birthday\", \"birthday\", \"bit\", \"bit\", \"bit\", \"bit\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"box\", \"box\", \"buy\", \"buy\", \"buy\", \"buy\", \"ca\", \"ca n't\", \"came\", \"came\", \"came\", \"came\", \"came\", \"carri\", \"carri\", \"cat\", \"cat\", \"child\", \"child\", \"child\", \"child\", \"christma\", \"christma\", \"christma\", \"christma\", \"collect\", \"collect\", \"collect\", \"collect\", \"collect\", \"color\", \"color\", \"color\", \"color\", \"color\", \"come\", \"come\", \"come\", \"come\", \"come\", \"cudd\", \"cudd\", \"cudd\", \"cudd\", \"cudd\", \"cudd\", \"cudd\", \"cute\", \"cute\", \"cute\", \"cute\", \"cute\", \"cute\", \"cute\", \"cute\", \"cute\", \"daughter\", \"daughter\", \"daughter\", \"daughter\", \"daughter\", \"daughter love\", \"day\", \"day\", \"day\", \"day\", \"day\", \"definit\", \"definit\", \"definit\", \"definit\", \"definit\", \"did\", \"did\", \"did\", \"did\", \"did n't\", \"did n't\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"disappoint\", \"disappoint\", \"doe\", \"doe n't\", \"dog\", \"dog\", \"dog\", \"doll\", \"doll\", \"easi\", \"easi\", \"easi\", \"easi\", \"easi\", \"everi\", \"everi\", \"everi\", \"everi\", \"exact\", \"exact\", \"exact\", \"exact\", \"expect\", \"expect\", \"expect\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"face\", \"face\", \"face\", \"face\", \"face\", \"favorit\", \"favorit\", \"favorit\", \"favorit\", \"feel\", \"feel\", \"friend\", \"friend\", \"fun\", \"fun\", \"fun\", \"fun\", \"fur\", \"fur\", \"gave\", \"gave\", \"gave\", \"gave\", \"gift\", \"gift\", \"gift\", \"gift\", \"gift\", \"gift\", \"girl\", \"girl\", \"goe\", \"goe\", \"goe\", \"goe\", \"goe\", \"goe\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good qualiti\", \"good qualiti\", \"got\", \"got\", \"got\", \"got\", \"got\", \"granddaught\", \"granddaught love\", \"grandson\", \"grandson\", \"grandson\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"gund\", \"gund\", \"guy\", \"hand\", \"hand\", \"hand\", \"hand\", \"happi\", \"happi\", \"happi\", \"happi\", \"head\", \"head\", \"head\", \"head\", \"high\", \"hit\", \"hit\", \"hit\", \"hit\", \"hold\", \"hold\", \"hold\", \"item\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"kid\", \"kid\", \"kid\", \"kid love\", \"know\", \"know\", \"know\", \"know\", \"know\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"long\", \"look\", \"look\", \"look\", \"look\", \"look\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"materi\", \"materi\", \"materi\", \"month\", \"month\", \"month old\", \"n't\", \"n't\", \"n't\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"nephew\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"niec\", \"niec\", \"night\", \"night\", \"old\", \"old\", \"old love\", \"onli\", \"onli\", \"open\", \"open\", \"open\", \"open\", \"order\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect size\", \"pictur\", \"pictur\", \"pictur\", \"pictur\", \"place\", \"place\", \"place\", \"place\", \"plastic\", \"plastic\", \"plastic\", \"plastic\", \"play\", \"play\", \"play\", \"plush\", \"plush\", \"plush\", \"plush\", \"plush\", \"present\", \"present\", \"present\", \"pretti\", \"pretti\", \"pretti\", \"price\", \"price\", \"price\", \"price\", \"product\", \"product\", \"product\", \"product\", \"purchas\", \"purchas\", \"pusheen\", \"pusheen\", \"qualiti\", \"qualiti\", \"quick\", \"quick\", \"real\", \"real\", \"real\", \"real\", \"real\", \"realli\", \"realli\", \"realli\", \"realli\", \"realli cute\", \"receiv\", \"receiv\", \"receiv\", \"receiv\", \"receiv\", \"recommend\", \"recommend\", \"review\", \"review\", \"right\", \"right\", \"right\", \"s\", \"s\", \"said\", \"said\", \"said\", \"said\", \"said\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"ship\", \"ship\", \"sinc\", \"sinc\", \"size\", \"size\", \"size\", \"size\", \"sleep\", \"sleep\", \"sleep\", \"small\", \"small\", \"small\", \"small\", \"small\", \"smaller\", \"smaller\", \"soft\", \"soft\", \"soft\", \"soft\", \"soft\", \"soft\", \"soft\", \"soft\", \"someth\", \"someth\", \"son\", \"son\", \"son\", \"son\", \"son\", \"son love\", \"son love\", \"sound\", \"sound\", \"star\", \"star\", \"star\", \"star\", \"star\", \"store\", \"store\", \"stuf\", \"stuf\", \"stuf anim\", \"super\", \"super cute\", \"super soft\", \"sure\", \"sure\", \"sure\", \"sure\", \"t\", \"t\", \"tail\", \"tail\", \"talk\", \"talk\", \"talk\", \"talk\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"time\", \"time\", \"time\", \"time\", \"toy\", \"toy\", \"toy\", \"toy\", \"toy\", \"tri\", \"tri\", \"tri\", \"use\", \"use\", \"use\", \"use\", \"ve\", \"ve\", \"ve\", \"veri\", \"veri\", \"veri cute\", \"veri soft\", \"wait\", \"wait\", \"wait\", \"want\", \"want\", \"want\", \"want\", \"way\", \"way\", \"way\", \"work\", \"work\", \"work\", \"work\", \"worth\", \"worth\", \"worth\", \"worth\", \"worth\", \"year\", \"year old\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 6, 9, 8, 1, 4, 7, 2, 3, 10]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el270446177791448509285390\", ldavis_el270446177791448509285390_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el270446177791448509285390\", ldavis_el270446177791448509285390_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el270446177791448509285390\", ldavis_el270446177791448509285390_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "4      17.271449        1       1  0.060281 -0.108079\n",
       "5      12.028633        1       2  0.264044  0.045054\n",
       "8      11.104687        1       3  0.140795 -0.298641\n",
       "7      10.750271        1       4  0.064051  0.047350\n",
       "0      10.369212        1       5 -0.125644  0.171113\n",
       "3       8.935379        1       6 -0.152652 -0.141764\n",
       "6       7.967981        1       7 -0.256221  0.006889\n",
       "1       7.559647        1       8 -0.150948 -0.044686\n",
       "2       7.199960        1       9  0.176851  0.178041\n",
       "9       6.812782        1      10 -0.020557  0.144723, topic_info=     Category         Freq           Term        Total  loglift  logprob\n",
       "term                                                                    \n",
       "161   Default  1816.000000           veri  1816.000000  30.0000  30.0000\n",
       "89    Default  3987.000000           love  3987.000000  29.0000  29.0000\n",
       "101   Default  1187.000000            old  1187.000000  28.0000  28.0000\n",
       "169   Default   957.000000           year   957.000000  27.0000  27.0000\n",
       "157   Default  1506.000000            toy  1506.000000  26.0000  26.0000\n",
       "170   Default   794.000000       year old   794.000000  25.0000  25.0000\n",
       "36    Default  2114.000000           cute  2114.000000  24.0000  24.0000\n",
       "37    Default  1282.000000       daughter  1282.000000  23.0000  23.0000\n",
       "94    Default  1509.000000            n't  1509.000000  22.0000  22.0000\n",
       "9     Default   648.000000           anim   648.000000  21.0000  21.0000\n",
       "81    Default   676.000000            kid   676.000000  20.0000  20.0000\n",
       "61    Default  1145.000000           gift  1145.000000  19.0000  19.0000\n",
       "144   Default   680.000000           stuf   680.000000  18.0000  18.0000\n",
       "67    Default   496.000000    granddaught   496.000000  17.0000  17.0000\n",
       "146   Default   563.000000          super   563.000000  16.0000  16.0000\n",
       "106   Default   855.000000        perfect   855.000000  15.0000  15.0000\n",
       "70    Default  1124.000000          great  1124.000000  14.0000  14.0000\n",
       "122   Default   802.000000         realli   802.000000  13.0000  13.0000\n",
       "119   Default   740.000000        qualiti   740.000000  12.0000  12.0000\n",
       "38    Default   509.000000  daughter love   509.000000  11.0000  11.0000\n",
       "1     Default  2213.000000             's  2213.000000  10.0000  10.0000\n",
       "133   Default   687.000000           size   687.000000   9.0000   9.0000\n",
       "29    Default   425.000000            cat   425.000000   8.0000   8.0000\n",
       "45    Default   572.000000            doe   572.000000   7.0000   7.0000\n",
       "145   Default   448.000000      stuf anim   448.000000   6.0000   6.0000\n",
       "167   Default   495.000000           work   495.000000   5.0000   5.0000\n",
       "31    Default   782.000000       christma   782.000000   4.0000   4.0000\n",
       "115   Default   560.000000          price   560.000000   3.0000   3.0000\n",
       "139   Default   721.000000            son   721.000000   2.0000   2.0000\n",
       "128   Default   390.000000              s   390.000000   1.0000   1.0000\n",
       "...       ...          ...            ...          ...      ...      ...\n",
       "47    Topic10   160.321619            dog   217.321383   2.3822  -3.4896\n",
       "157   Topic10   741.678546            toy  1506.191937   1.9779  -1.9579\n",
       "52    Topic10   234.394730         expect   480.748287   1.9680  -3.1098\n",
       "30    Topic10   166.919097          child   356.164320   1.9285  -3.4493\n",
       "55    Topic10    83.934852        favorit   205.242956   1.7922  -4.1368\n",
       "166   Topic10    74.674713            way   193.101055   1.7363  -4.2537\n",
       "155   Topic10    89.649211        thought   286.972433   1.5229  -4.0709\n",
       "97    Topic10    78.302234            new   250.759567   1.5225  -4.2062\n",
       "135   Topic10   138.116461          small   495.076794   1.4098  -3.6387\n",
       "64    Topic10   175.338962           good   662.056461   1.3577  -3.4001\n",
       "88    Topic10    62.850581            lot   238.355493   1.3534  -4.4261\n",
       "153   Topic10   103.840306          thing   395.247185   1.3497  -3.9240\n",
       "6     Topic10    45.325132          adult   176.170502   1.3288  -4.7530\n",
       "34    Topic10    67.561960           come   294.503462   1.2141  -4.3538\n",
       "77    Topic10    37.505920            hit   179.904763   1.1184  -4.9423\n",
       "70    Topic10   204.073635          great  1124.213705   0.9800  -3.2483\n",
       "61    Topic10   197.057393           gift  1145.104668   0.9266  -3.2833\n",
       "112   Topic10    94.892160          plush   597.978866   0.8456  -4.0141\n",
       "17    Topic10    30.100748           best   190.253457   0.8426  -5.1623\n",
       "73    Topic10    27.206747           hand   181.055950   0.7910  -5.2633\n",
       "39    Topic10    42.945112            day   291.465713   0.7714  -4.8069\n",
       "89    Topic10   558.658647           love  3987.367826   0.7210  -2.2413\n",
       "21    Topic10    28.528928            bit   205.683982   0.7109  -5.2159\n",
       "32    Topic10    22.147832        collect   163.250037   0.6888  -5.4691\n",
       "43    Topic10    32.090318         differ   247.865555   0.6420  -5.0983\n",
       "36    Topic10   251.035177           cute  2114.012416   0.5556  -3.0412\n",
       "137   Topic10   127.903885           soft  1482.285813   0.2363  -3.7155\n",
       "13    Topic10    54.999335           babi   551.770626   0.3806  -4.5595\n",
       "115   Topic10    43.920733          price   560.234757   0.1404  -4.7844\n",
       "35    Topic10    31.288215           cudd   332.619341   0.3226  -5.1236\n",
       "\n",
       "[390 rows x 6 columns], token_table=      Topic      Freq          Term\n",
       "term                               \n",
       "0         1  0.596006            'm\n",
       "0         2  0.072916            'm\n",
       "0         3  0.199725            'm\n",
       "0         8  0.129980            'm\n",
       "1         1  0.434592            's\n",
       "1         2  0.123330            's\n",
       "1         4  0.208261            's\n",
       "1         5  0.177090            's\n",
       "1         6  0.026654            's\n",
       "1         9  0.030268            's\n",
       "2         3  0.057566       absolut\n",
       "2         4  0.291219       absolut\n",
       "2         7  0.521485       absolut\n",
       "2         9  0.128678       absolut\n",
       "3         3  0.045965  absolut love\n",
       "3         7  0.912728  absolut love\n",
       "3         9  0.039398  absolut love\n",
       "4         1  0.817178        actual\n",
       "4         5  0.044845        actual\n",
       "4         6  0.134535        actual\n",
       "5         1  0.016621          ador\n",
       "5         2  0.054979          ador\n",
       "5         4  0.126579          ador\n",
       "5         5  0.296629          ador\n",
       "5         6  0.084386          ador\n",
       "5         7  0.025572          ador\n",
       "5         8  0.093336          ador\n",
       "5         9  0.301744          ador\n",
       "6         1  0.737921         adult\n",
       "6        10  0.255434         adult\n",
       "...     ...       ...           ...\n",
       "159       6  0.683043           use\n",
       "159      10  0.020768           use\n",
       "160       1  0.168058            ve\n",
       "160       3  0.668132            ve\n",
       "160       4  0.159860            ve\n",
       "161       2  0.998976          veri\n",
       "161       7  0.000550          veri\n",
       "162       2  0.998752     veri cute\n",
       "163       2  0.997707     veri soft\n",
       "164       3  0.733883          wait\n",
       "164       4  0.190023          wait\n",
       "164      10  0.072078          wait\n",
       "165       1  0.345475          want\n",
       "165       2  0.167566          want\n",
       "165       6  0.153085          want\n",
       "165       8  0.330994          want\n",
       "166       1  0.191610           way\n",
       "166       3  0.414291           way\n",
       "166      10  0.388398           way\n",
       "167       1  0.010096          work\n",
       "167       3  0.072693          work\n",
       "167       6  0.870303          work\n",
       "167       7  0.042405          work\n",
       "168       1  0.072412         worth\n",
       "168       2  0.257967         worth\n",
       "168       6  0.339430         worth\n",
       "168       7  0.058835         worth\n",
       "168       9  0.267018         worth\n",
       "169       7  0.998780          year\n",
       "170       7  0.998854      year old\n",
       "\n",
       "[575 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 6, 9, 8, 1, 4, 7, 2, 3, 10])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2018-03-03 14:08:20.385662. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda, tf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2018-03-03 14:08:22.237155. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# #挑選特定條件(抽樣)\n",
    "# samples = ldaClusterframe[ldaClusterframe.loc[:,'ClusterLabel'] == 4][:441]\n",
    "# Rsamples = samples['review'].values\n",
    "# Rsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2018-03-03 14:08:22.245023. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# with open('../test.csv','w',encoding='utf-8') as f :\n",
    "#     f.write(str(Rsamples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
